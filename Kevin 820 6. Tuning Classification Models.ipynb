{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f379970c",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a36765e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# math and dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "import tensorflow as tf\n",
    "\n",
    "# Pipeline and Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, RandomizedSearchCV \n",
    "from sklearn.tree import plot_tree\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "# Undersampling \n",
    "# Note: undersampling was used in at least 1 paper predicting popularity (Gao 2021)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# jupyter notebook full-width display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cbcb793",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10M = pd.read_pickle('df_10M_clustered.pickle')\n",
    "X_all = pd.read_pickle('X_clustered.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed65dd3",
   "metadata": {},
   "source": [
    "# Create Datasets for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "065df1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = 'in_B100'\n",
    "X_columns = [\n",
    "    'mode', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
    "    'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence'\n",
    "]\n",
    "genre_columns = [\n",
    "    'is_Adult_Standard', 'is_Rock', 'is_R&B', 'is_Country', 'is_Pop',\n",
    "    'is_Rap', 'is_Alternative', 'is_EDM', 'is_Metal'\n",
    "]\n",
    "cluster_columns = ['cluster', 'cluster2']\n",
    "other_columns = ['key', 'time_signature', 'genre', 'release_date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64aee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict with all 'name': (X, y) key match pairs\n",
    "clusters = {}\n",
    "\n",
    "# entire predictive dataset\n",
    "clusters['All'] = (X_all[X_columns], X_all[y_column])\n",
    "\n",
    "# add genres\n",
    "for genre in genre_columns:\n",
    "    title = genre[3:]\n",
    "    clusters[title] = (X_all[X_all[genre]][X_columns], X_all[X_all[genre]][y_column])\n",
    "    \n",
    "# add clusters\n",
    "for n in sorted(X_all['cluster'].unique()):\n",
    "    title = genre[3:]\n",
    "    clusters['cluster1_' + str(n)] = (X_all[X_all['cluster'] == n][X_columns], X_all[X_all['cluster'] == n][y_column])\n",
    "    \n",
    "for n in sorted(X_all['cluster2'].unique()):\n",
    "    title = genre[3:]\n",
    "    clusters['cluster2_' + str(n)] = (X_all[X_all['cluster2'] == n][X_columns], X_all[X_all['cluster2'] == n][y_column])\n",
    "    \n",
    "# OPTIONAL IF TIME PERMITS: consider adding decades or eras of music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b6014b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main non-clustered predictive dataset, with genre data (all data)\n",
    "X, y = X_all[X_columns+genre_columns], X_all[y_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a98d9ab",
   "metadata": {},
   "source": [
    "# Tune Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a9f9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_keys = [\n",
    "    'All', \n",
    "    'Adult_Standard', 'Rock', 'R&B', 'Country', 'Pop', 'Rap', 'Alternative', 'EDM', 'Metal', \n",
    "    'cluster1_0', 'cluster1_1', 'cluster1_2', 'cluster1_3', \n",
    "    'cluster2_0', 'cluster2_1', 'cluster2_2', 'cluster2_3', 'cluster2_4', \n",
    "    'cluster2_5', 'cluster2_6', 'cluster2_7', 'cluster2_8', 'cluster2_9'\n",
    "]\n",
    "\n",
    "ML_algorithms = [\n",
    "    LogisticRegression,\n",
    "    DecisionTreeClassifier,\n",
    "    KNeighborsClassifier,\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "383a5a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup tuning algorithm with a small dataset\n",
    "small = X_all.sample(10_000)\n",
    "X_small = small[X_columns]\n",
    "y_small = small[y_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fd3de4",
   "metadata": {},
   "source": [
    "### try different metric and defaults to try to improve tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87c01369",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For multi-metric scoring, the parameter refit must be set to a scorer key or a callable to refit an estimator with the best parameter setting on the whole data and make the best_* attributes available for that metric. If this is not needed, refit should be set to False explicitly. True was passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_multimetric_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_refit_for_multimetric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_check_refit_for_multimetric\u001b[1;34m(self, scores)\u001b[0m\n\u001b[0;32m    719\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m         ):\n\u001b[1;32m--> 721\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmultimetric_refit_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: For multi-metric scoring, the parameter refit must be set to a scorer key or a callable to refit an estimator with the best parameter setting on the whole data and make the best_* attributes available for that metric. If this is not needed, refit should be set to False explicitly. True was passed."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LOGISTIC REGRESSION\n",
    "\n",
    "# choose dataset\n",
    "am_testing = True\n",
    "use_best_cluster = True\n",
    "\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    if use_best_cluster:\n",
    "        X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "    else:\n",
    "        X_, y_ = X, y\n",
    "\n",
    "# huge list of orders of magnitude for gridsearch\n",
    "# formatted a bit funny to avoid rounding errors\n",
    "orders_of_magnitude = []\n",
    "for lst in [[int(x)/10000 for x in range(1, 11)],\n",
    "            [int(x)/1000 for x in range(1, 11)],\n",
    "            [int(x)/100 for x in range(1, 11)],\n",
    "            [int(x)/10 for x in range(1, 11)],\n",
    "            [1 * x for x in range(1, 11)],\n",
    "            [10 * x for x in range(1, 11)],\n",
    "            [100 * x for x in range(1, 11)],\n",
    "            [1000 * x for x in range(1, 11)]]:\n",
    "    orders_of_magnitude += lst\n",
    "\n",
    "# params\n",
    "scoring = 'roc_auc'\n",
    "param_grid = {}\n",
    "param_grid['logisticregression__penalty'] = ['l1', 'l2']\n",
    "param_grid['logisticregression__C'] = orders_of_magnitude\n",
    "\n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    LogisticRegression(solver='liblinear')\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "lr_grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "lr_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "(\n",
    "    lr_grid.best_params_,\n",
    "    lr_grid.cv_results_['mean_test_score'].mean(), \n",
    "    lr_grid.cv_results_['mean_test_score'].min(), \n",
    "    lr_grid.cv_results_['mean_test_score'].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afee4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "883a2ed3",
   "metadata": {},
   "source": [
    "undersampling works well with 'roc_auc'\n",
    "\n",
    "* class_weight='balanced'\n",
    "    * using f1:  \n",
    "    \n",
    "            ({'logisticregression__C': 0.004, 'logisticregression__penalty': 'l1'},\n",
    "            0.005316525852647807,\n",
    "            0.0,\n",
    "            0.0070552754062038455)\n",
    "    * using roc_auc:\n",
    "    \n",
    "            ({'logisticregression__C': 80, 'logisticregression__penalty': 'l2'},\n",
    "            0.623583014878386,\n",
    "            0.49373747494989983,\n",
    "            0.6465445602003069)\n",
    "            \n",
    "* class_weight='balanced' AND undersampling\n",
    "    * using f1:  \n",
    "    \n",
    "            ({'logisticregression__C': 600, 'logisticregression__penalty': 'l2'},\n",
    "             0.004878589794697396,\n",
    "             0.0,\n",
    "             0.008488896668204493)\n",
    "    * using roc_auc:\n",
    "    \n",
    "            ({'logisticregression__C': 5000, 'logisticregression__penalty': 'l1'},\n",
    "             0.5972014561030285,\n",
    "             0.5,\n",
    "             0.7154501078385457)\n",
    "            \n",
    "* undersampling\n",
    "    * using f1:  \n",
    "    \n",
    "            ({'logisticregression__C': 800, 'logisticregression__penalty': 'l2'},\n",
    "             0.004876113860622892,\n",
    "             0.0,\n",
    "             0.008267908667468979)\n",
    "    * using roc_auc:\n",
    "    \n",
    "            ({'logisticregression__C': 9, 'logisticregression__penalty': 'l1'},\n",
    "             0.5835509599523353,\n",
    "             0.5,\n",
    "             0.7081368856067198)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8960916b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a0a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c6245d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2369ac3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd88c388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b28bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b29b5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b91d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a6d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b15b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294715f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c296f579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6035930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c3083a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab2aec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30755135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3cc1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153a039b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0677d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff68519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b12a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00a3fe64",
   "metadata": {},
   "source": [
    "# OLD METHOD: no meaningful results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a602d0f",
   "metadata": {},
   "source": [
    "### Which ML models did well with default settings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "8dd92ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('default_results.pickle', 'rb') as f:\n",
    "    default_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "de167432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_results_by_metric(class_type='True', metric='f1-score'):\n",
    "    \"\"\"convert default results into readable form\"\"\"\n",
    "    output_ = []\n",
    "\n",
    "    for algo in ML_algorithms:\n",
    "        algo_ = str(algo())[:-2]\n",
    "        temp_ = [algo_]\n",
    "        for cluster in cluster_keys:\n",
    "            if class_type == 'accuracy':\n",
    "                metric_ = default_results[algo_][cluster][1][class_type]\n",
    "            else:\n",
    "                metric_ = default_results[algo_][cluster][1][class_type][metric]\n",
    "            temp_.append(metric_)\n",
    "        output_.append(temp_)\n",
    "\n",
    "    df_default_results = pd.DataFrame(output_, columns=['Model']+list(default_results['LogisticRegression'].keys()))\n",
    "    df_default_results['min'] = df_default_results.iloc[:, 1:].min(axis=1)\n",
    "    df_default_results['max'] = df_default_results.iloc[:, 1:].max(axis=1)\n",
    "    df_default_results['mean'] = df_default_results.iloc[:, 1:].mean(axis=1)\n",
    "\n",
    "    return df_default_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "a1bdc6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adult_Standard</th>\n",
       "      <td>0.077</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R&amp;B</th>\n",
       "      <td>0.072</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rock</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pop</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rap</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_7</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_1</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_5</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster1_1</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster1_2</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_6</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alternative</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_8</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_0</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metal</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_9</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster1_3</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster1_0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model           LogisticRegression  DecisionTreeClassifier  \\\n",
       "Adult_Standard               0.077                   0.060   \n",
       "R&B                          0.072                   0.063   \n",
       "Country                      0.038                   0.030   \n",
       "Rock                         0.032                   0.029   \n",
       "Pop                          0.021                   0.019   \n",
       "Rap                          0.017                   0.013   \n",
       "cluster2_7                   0.014                   0.012   \n",
       "cluster2_1                   0.012                   0.011   \n",
       "cluster2_5                   0.011                   0.010   \n",
       "cluster1_1                   0.011                   0.010   \n",
       "cluster1_2                   0.010                   0.009   \n",
       "cluster2_6                   0.009                   0.007   \n",
       "All                          0.009                   0.009   \n",
       "Alternative                  0.009                   0.007   \n",
       "cluster2_8                   0.008                   0.007   \n",
       "cluster2_0                   0.008                   0.007   \n",
       "Metal                        0.003                   0.003   \n",
       "cluster2_9                   0.003                   0.003   \n",
       "EDM                          0.003                   0.002   \n",
       "cluster1_3                   0.002                   0.002   \n",
       "cluster2_4                   0.001                   0.001   \n",
       "cluster1_0                   0.001                   0.001   \n",
       "cluster2_3                   0.001                   0.000   \n",
       "cluster2_2                   0.000                   0.000   \n",
       "\n",
       "Model           KNeighborsClassifier  RandomForestClassifier  \\\n",
       "Adult_Standard                 0.065                   0.080   \n",
       "R&B                            0.065                   0.081   \n",
       "Country                        0.033                   0.042   \n",
       "Rock                           0.030                   0.039   \n",
       "Pop                            0.019                   0.026   \n",
       "Rap                            0.014                   0.018   \n",
       "cluster2_7                     0.013                   0.017   \n",
       "cluster2_1                     0.011                   0.016   \n",
       "cluster2_5                     0.010                   0.014   \n",
       "cluster1_1                     0.011                   0.014   \n",
       "cluster1_2                     0.009                   0.013   \n",
       "cluster2_6                     0.008                   0.011   \n",
       "All                            0.009                   0.012   \n",
       "Alternative                    0.007                   0.012   \n",
       "cluster2_8                     0.007                   0.010   \n",
       "cluster2_0                     0.007                   0.009   \n",
       "Metal                          0.003                   0.005   \n",
       "cluster2_9                     0.003                   0.004   \n",
       "EDM                            0.003                   0.004   \n",
       "cluster1_3                     0.002                   0.003   \n",
       "cluster2_4                     0.001                   0.002   \n",
       "cluster1_0                     0.001                   0.001   \n",
       "cluster2_3                     0.000                   0.001   \n",
       "cluster2_2                     0.000                   0.000   \n",
       "\n",
       "Model           AdaBoostClassifier  \n",
       "Adult_Standard               0.077  \n",
       "R&B                          0.076  \n",
       "Country                      0.038  \n",
       "Rock                         0.036  \n",
       "Pop                          0.022  \n",
       "Rap                          0.017  \n",
       "cluster2_7                   0.015  \n",
       "cluster2_1                   0.014  \n",
       "cluster2_5                   0.012  \n",
       "cluster1_1                   0.012  \n",
       "cluster1_2                   0.011  \n",
       "cluster2_6                   0.009  \n",
       "All                          0.010  \n",
       "Alternative                  0.009  \n",
       "cluster2_8                   0.009  \n",
       "cluster2_0                   0.009  \n",
       "Metal                        0.004  \n",
       "cluster2_9                   0.003  \n",
       "EDM                          0.003  \n",
       "cluster1_3                   0.002  \n",
       "cluster2_4                   0.001  \n",
       "cluster1_0                   0.001  \n",
       "cluster2_3                   0.000  \n",
       "cluster2_2                   0.000  "
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best performing classification by cluster = Adult_Standard (1st or 2nd for all ML models)\n",
    "sortbyfeature = 'LogisticRegression'\n",
    "pd.DataFrame(default_results_by_metric().iloc[:, :-3].set_index('Model').T).sort_values(sortbyfeature, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da576a88",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "f612e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huge list of orders of magnitude for gridsearch\n",
    "# formatted a bit funny to avoid rounding errors\n",
    "orders_of_magnitude = []\n",
    "for lst in [[int(x)/10000 for x in range(1, 11)],\n",
    "            [int(x)/1000 for x in range(1, 11)],\n",
    "            [int(x)/100 for x in range(1, 11)],\n",
    "            [int(x)/10 for x in range(1, 11)],\n",
    "            [1 * x for x in range(1, 11)],\n",
    "            [10 * x for x in range(1, 11)],\n",
    "            [100 * x for x in range(1, 11)],\n",
    "            [1000 * x for x in range(1, 11)]]:\n",
    "    orders_of_magnitude += lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "d2122121",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'logisticregression__C': 400, 'logisticregression__penalty': 'l2'},\n",
       " 0.07800708796711779)"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# LOGISTIC REGRESSION\n",
    "\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning setup with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'f1'\n",
    "param_grid = {}\n",
    "param_grid['logisticregression__penalty'] = ['l1', 'l2']\n",
    "param_grid['logisticregression__C'] = orders_of_magnitude\n",
    "\n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    LogisticRegression(solver='liblinear')\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "lr_grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "lr_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "lr_grid.best_params_, lr_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "5dd8ebdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06897831928043999, 0.0, 0.07800708796711779)"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doesn't seem like tuning is doing anything\n",
    "(\n",
    "    lr_grid.cv_results_['mean_test_score'].mean(), \n",
    "    lr_grid.cv_results_['mean_test_score'].min(), \n",
    "    lr_grid.cv_results_['mean_test_score'].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "65432a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'decisiontreeclassifier__criterion': 'gini',\n",
       "  'decisiontreeclassifier__max_depth': None,\n",
       "  'decisiontreeclassifier__min_samples_leaf': 50},\n",
       " 0.07456561474305215)"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# DECISION TREE\n",
    "\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning setup with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'f1'\n",
    "param_grid = {}\n",
    "param_grid['decisiontreeclassifier__max_depth'] = [3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 40, 50, 100, None]\n",
    "param_grid['decisiontreeclassifier__min_samples_leaf'] = [5, 10, 50, 100, 1000]\n",
    "param_grid['decisiontreeclassifier__criterion'] = ['gini', 'entropy']\n",
    "\n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    DecisionTreeClassifier()\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "dt_grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "dt_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "dt_grid.best_params_, dt_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "44700709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06785197229329681, 0.05958234706712688, 0.07456561474305215)"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuning isn't useful here either...\n",
    "(\n",
    "    dt_grid.cv_results_['mean_test_score'].mean(), \n",
    "    dt_grid.cv_results_['mean_test_score'].min(), \n",
    "    dt_grid.cv_results_['mean_test_score'].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "065a4489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'kneighborsclassifier__metric': 'manhattan',\n",
       "  'kneighborsclassifier__n_neighbors': 6,\n",
       "  'kneighborsclassifier__weights': 'uniform'},\n",
       " 0.07027638389807941)"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# KNN\n",
    "\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning setup with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'f1'\n",
    "param_grid = {}\n",
    "param_grid['kneighborsclassifier__n_neighbors'] = [x for x in range(2,20)]+[x for x in range(20,101,5)]\n",
    "param_grid['kneighborsclassifier__weights'] = ['uniform', 'distance']\n",
    "param_grid['kneighborsclassifier__metric'] = ['minkowski', 'euclidean', 'manhattan']\n",
    "\n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    KNeighborsClassifier()\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "knn_grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "knn_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "knn_grid.best_params_, knn_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "0f89a1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06621236939350202, 0.05683753654031316, 0.07027638389807941)"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check min mean and max\n",
    "(\n",
    "    knn_grid.cv_results_['mean_test_score'].mean(), \n",
    "    knn_grid.cv_results_['mean_test_score'].min(), \n",
    "    knn_grid.cv_results_['mean_test_score'].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "e3bd6dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3h 59min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'randomforestclassifier__bootstrap': False,\n",
       "  'randomforestclassifier__max_depth': 30,\n",
       "  'randomforestclassifier__max_features': 'sqrt',\n",
       "  'randomforestclassifier__min_samples_leaf': 5,\n",
       "  'randomforestclassifier__n_estimators': 1000},\n",
       " 0.08028160782282248)"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# random forest\n",
    "\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning setup with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'f1'\n",
    "param_grid = {}\n",
    "param_grid['randomforestclassifier__n_estimators'] = [5, 10, 20, 50, 100, 200, 500, 1000, 2000]\n",
    "param_grid['randomforestclassifier__max_features'] = ['sqrt', 'log2']\n",
    "param_grid['randomforestclassifier__max_depth'] = [3, 5, 7, 10, 15, 20, 30, 50, 100, None]\n",
    "param_grid['randomforestclassifier__min_samples_leaf'] = [5, 10, 50, 100, 1000]\n",
    "param_grid['randomforestclassifier__bootstrap'] = [True, False]\n",
    "\n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    RandomForestClassifier()\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "rf_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "rf_grid.best_params_, rf_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "4b30af1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07444941625954442, 0.0638043296032271, 0.08028160782282248)"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also didn't do great...\n",
    "(\n",
    "    rf_grid.cv_results_['mean_test_score'].mean(), \n",
    "    rf_grid.cv_results_['mean_test_score'].min(), \n",
    "    rf_grid.cv_results_['mean_test_score'].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca9c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# adaboost\n",
    "\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning setup with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'f1'\n",
    "param_grid = {}\n",
    "param_grid['adaboostclassifier__n_estimators'] = [10, 50, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "param_grid['adaboostclassifier__n_learning_rate'] = [0.0001, 0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 1.5, 2.0]\n",
    "param_grid['adaboostclassifier__n_algorithm'] = ['SAMME', 'SAMME.R']\n",
    "        \n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    AdaBoostClassifier()\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "ab_grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "ab_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "ab_grid.best_params_, ab_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b255a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check min mean and max\n",
    "(\n",
    "    ab_grid.cv_results_['mean_test_score'].mean(), \n",
    "    ab_grid.cv_results_['mean_test_score'].min(), \n",
    "    ab_grid.cv_results_['mean_test_score'].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893ad126",
   "metadata": {},
   "source": [
    "### Test Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059b7339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a65e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12613bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7548d980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8bdf80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
