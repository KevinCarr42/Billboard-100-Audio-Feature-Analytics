{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f379970c",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a36765e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# math and dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "import tensorflow as tf\n",
    "\n",
    "# Pipeline and Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.tree import plot_tree\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "# Undersampling \n",
    "# Note: undersampling was used in at least 1 paper predicting popularity (Gao 2021)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# jupyter notebook full-width display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cbcb793",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10M = pd.read_pickle('df_10M_clustered.pickle')\n",
    "X_all = pd.read_pickle('X_clustered.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed65dd3",
   "metadata": {},
   "source": [
    "# Create Datasets for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "065df1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = 'in_B100'\n",
    "X_columns = [\n",
    "    'mode', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
    "    'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence'\n",
    "]\n",
    "genre_columns = [\n",
    "    'is_Adult_Standard', 'is_Rock', 'is_R&B', 'is_Country', 'is_Pop',\n",
    "    'is_Rap', 'is_Alternative', 'is_EDM', 'is_Metal'\n",
    "]\n",
    "cluster_columns = ['cluster', 'cluster2']\n",
    "other_columns = ['key', 'time_signature', 'genre', 'release_date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64aee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict with all 'name': (X, y) key match pairs\n",
    "clusters = {}\n",
    "\n",
    "# entire predictive dataset\n",
    "clusters['All'] = (X_all[X_columns+genre_columns], X_all[y_column])\n",
    "# clusters['All'] = (X_all[X_columns], X_all[y_column])\n",
    "\n",
    "# add genres\n",
    "for genre in genre_columns:\n",
    "    title = genre[3:]\n",
    "    clusters[title] = (X_all[X_all[genre]][X_columns], X_all[X_all[genre]][y_column])\n",
    "    \n",
    "# add clusters\n",
    "for n in sorted(X_all['cluster'].unique()):\n",
    "    title = genre[3:]\n",
    "    clusters['cluster1_' + str(n)] = (X_all[X_all['cluster'] == n][X_columns], X_all[X_all['cluster'] == n][y_column])\n",
    "    \n",
    "for n in sorted(X_all['cluster2'].unique()):\n",
    "    title = genre[3:]\n",
    "    clusters['cluster2_' + str(n)] = (X_all[X_all['cluster2'] == n][X_columns], X_all[X_all['cluster2'] == n][y_column])\n",
    "    \n",
    "# OPTIONAL IF TIME PERMITS: consider adding decades or eras of music"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a98d9ab",
   "metadata": {},
   "source": [
    "# Tune Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a9f9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_keys = [\n",
    "    'All', \n",
    "    'Adult_Standard', 'Rock', 'R&B', 'Country', 'Pop', 'Rap', 'Alternative', 'EDM', 'Metal', \n",
    "    'cluster1_0', 'cluster1_1', 'cluster1_2', 'cluster1_3', \n",
    "    'cluster2_0', 'cluster2_1', 'cluster2_2', 'cluster2_3', 'cluster2_4', \n",
    "    'cluster2_5', 'cluster2_6', 'cluster2_7', 'cluster2_8', 'cluster2_9'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a98d7345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: (167088, 11) (41772, 11) (167088,) (41772,)\n",
      "how many True in y_train: 2942\n"
     ]
    }
   ],
   "source": [
    "# choose dataset\n",
    "am_testing = False\n",
    "use_best_cluster = True  # y_train has ~17k when using 'All'\n",
    "\n",
    "# setup tuning algorithm with a small dataset\n",
    "small = X_all.sample(10_000, random_state=42)\n",
    "X_small = small[X_columns]\n",
    "y_small = small[y_column]\n",
    "\n",
    "# Setup a train test split to check predictions\n",
    "\n",
    "## NOTE: can't figure out how to get out of fold predictions \n",
    "## for classification report / confusion matrix\n",
    "\n",
    "# which dataset\n",
    "if am_testing:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_small, y_small, test_size=0.2, random_state=42, stratify=y_small)\n",
    "else:\n",
    "    if use_best_cluster:\n",
    "        X_, y_ = clusters['Adult_Standard']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=42, stratify=y_)\n",
    "    else:\n",
    "        X_, y_ = clusters['All']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=42, stratify=y_)\n",
    "        \n",
    "print('shapes:', X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print('how many True in y_train:', sum(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fd3de4",
   "metadata": {},
   "source": [
    "### try different metric and defaults to try to improve tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "87c01369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crossvalidation Results\n",
      "------------------------------\n",
      "{'logisticregression__C': 70, 'logisticregression__penalty': 'l1'}\n",
      "0.7431221950844644\n",
      "0.5\n",
      "0.7764689172491757\n",
      "\n",
      "Classification Report\n",
      "------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.69      0.81     41036\n",
      "        True       0.04      0.74      0.08       736\n",
      "\n",
      "    accuracy                           0.69     41772\n",
      "   macro avg       0.52      0.71      0.44     41772\n",
      "weighted avg       0.98      0.69      0.80     41772\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LOGISTIC REGRESSION\n",
    "\n",
    "# huge list of orders of magnitude for gridsearch\n",
    "# formatted a bit funny to avoid rounding errors\n",
    "orders_of_magnitude = []\n",
    "for lst in [[int(x)/10000 for x in range(1, 11)],\n",
    "            [int(x)/1000 for x in range(1, 11)],\n",
    "            [int(x)/100 for x in range(1, 11)],\n",
    "            [int(x)/10 for x in range(1, 11)],\n",
    "            [1 * x for x in range(1, 11)],\n",
    "            [10 * x for x in range(1, 11)],\n",
    "            [100 * x for x in range(1, 11)],\n",
    "            [1000 * x for x in range(1, 11)]]:\n",
    "    orders_of_magnitude += lst\n",
    "\n",
    "# params\n",
    "scoring = 'roc_auc'\n",
    "param_grid = {}\n",
    "param_grid['logisticregression__penalty'] = ['l1', 'l2']\n",
    "param_grid['logisticregression__C'] = orders_of_magnitude\n",
    "\n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    LogisticRegression(solver='liblinear')\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# results\n",
    "cv_results = (\n",
    "    grid.best_params_,\n",
    "    grid.cv_results_['mean_test_score'].mean(), \n",
    "    grid.cv_results_['mean_test_score'].min(), \n",
    "    grid.cv_results_['mean_test_score'].max()\n",
    ")\n",
    "\n",
    "# print cv results\n",
    "print('\\nCrossvalidation Results\\n------------------------------')\n",
    "for i in cv_results:\n",
    "    print(i)\n",
    "\n",
    "# print predictions\n",
    "y_pred = grid.predict(X_test)\n",
    "print('\\nClassification Report\\n------------------------------\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "print('\\nConfusion Matrix\\n------------------------------')\n",
    "plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), vmin=0, cmap='Blues', annot=True, fmt='.0f', cbar=False,\n",
    "           xticklabels=['Not Popular', 'Billboard Hit'], yticklabels=['Not Popular', 'Billboard Hit'])\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab2aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# DECISION TREE\n",
    "\n",
    "# params\n",
    "scoring = 'roc_auc'\n",
    "param_grid = {}\n",
    "param_grid['decisiontreeclassifier__max_depth'] = [3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 40, 50, 100, None]\n",
    "param_grid['decisiontreeclassifier__min_samples_leaf'] = [5, 10, 50, 100, 1000]\n",
    "param_grid['decisiontreeclassifier__criterion'] = ['gini', 'entropy']\n",
    "\n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    DecisionTreeClassifier()\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# results\n",
    "cv_results = (\n",
    "    grid.best_params_,\n",
    "    grid.cv_results_['mean_test_score'].mean(), \n",
    "    grid.cv_results_['mean_test_score'].min(), \n",
    "    grid.cv_results_['mean_test_score'].max()\n",
    ")\n",
    "\n",
    "# print cv results\n",
    "print('\\nCrossvalidation Results\\n------------------------------')\n",
    "for i in cv_results:\n",
    "    print(i)\n",
    "\n",
    "# print predictions\n",
    "y_pred = grid.predict(X_test)\n",
    "print('\\nClassification Report\\n------------------------------\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "print('\\nConfusion Matrix\\n------------------------------')\n",
    "plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), vmin=0, cmap='Blues', annot=True, fmt='.0f', cbar=False,\n",
    "           xticklabels=['Not Popular', 'Billboard Hit'], yticklabels=['Not Popular', 'Billboard Hit'])\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e02a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# KNN\n",
    "\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning setup with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'roc_auc'\n",
    "param_grid = {}\n",
    "param_grid['kneighborsclassifier__n_neighbors'] = [x for x in range(2,20)]+[x for x in range(20,101,5)]\n",
    "param_grid['kneighborsclassifier__weights'] = ['uniform', 'distance']\n",
    "param_grid['kneighborsclassifier__metric'] = ['minkowski', 'euclidean', 'manhattan']\n",
    "\n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    KNeighborsClassifier()\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# results\n",
    "cv_results = (\n",
    "    grid.best_params_,\n",
    "    grid.cv_results_['mean_test_score'].mean(), \n",
    "    grid.cv_results_['mean_test_score'].min(), \n",
    "    grid.cv_results_['mean_test_score'].max()\n",
    ")\n",
    "\n",
    "# print cv results\n",
    "print('\\nCrossvalidation Results\\n------------------------------')\n",
    "for i in cv_results:\n",
    "    print(i)\n",
    "\n",
    "# print predictions\n",
    "y_pred = grid.predict(X_test)\n",
    "print('\\nClassification Report\\n------------------------------\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "print('\\nConfusion Matrix\\n------------------------------')\n",
    "plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), vmin=0, cmap='Blues', annot=True, fmt='.0f', cbar=False,\n",
    "           xticklabels=['Not Popular', 'Billboard Hit'], yticklabels=['Not Popular', 'Billboard Hit'])\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db8dd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# random forest\n",
    "\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning setup with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'roc_auc'\n",
    "param_grid = {}\n",
    "param_grid['randomforestclassifier__n_estimators'] = [5, 10, 20, 50, 100, 200, 500, 1000, 2000]\n",
    "param_grid['randomforestclassifier__max_features'] = ['sqrt', 'log2']\n",
    "param_grid['randomforestclassifier__max_depth'] = [3, 5, 7, 10, 15, 20, 30, 50, 100, None]\n",
    "param_grid['randomforestclassifier__min_samples_leaf'] = [5, 10, 50, 100, 1000]\n",
    "param_grid['randomforestclassifier__bootstrap'] = [True, False]\n",
    "\n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    RandomForestClassifier()\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# results\n",
    "cv_results = (\n",
    "    grid.best_params_,\n",
    "    grid.cv_results_['mean_test_score'].mean(), \n",
    "    grid.cv_results_['mean_test_score'].min(), \n",
    "    grid.cv_results_['mean_test_score'].max()\n",
    ")\n",
    "\n",
    "# print cv results\n",
    "print('\\nCrossvalidation Results\\n------------------------------')\n",
    "for i in cv_results:\n",
    "    print(i)\n",
    "\n",
    "# print predictions\n",
    "y_pred = grid.predict(X_test)\n",
    "print('\\nClassification Report\\n------------------------------\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "print('\\nConfusion Matrix\\n------------------------------')\n",
    "plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), vmin=0, cmap='Blues', annot=True, fmt='.0f', cbar=False,\n",
    "           xticklabels=['Not Popular', 'Billboard Hit'], yticklabels=['Not Popular', 'Billboard Hit'])\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795b92f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# adaboost\n",
    "\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning setup with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'roc_auc'\n",
    "param_grid = {}\n",
    "param_grid['adaboostclassifier__n_estimators'] = [10, 50, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "param_grid['adaboostclassifier__n_learning_rate'] = [0.0001, 0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 1.5, 2.0]\n",
    "param_grid['adaboostclassifier__n_algorithm'] = ['SAMME', 'SAMME.R']\n",
    "        \n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    AdaBoostClassifier()\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# results\n",
    "cv_results = (\n",
    "    grid.best_params_,\n",
    "    grid.cv_results_['mean_test_score'].mean(), \n",
    "    grid.cv_results_['mean_test_score'].min(), \n",
    "    grid.cv_results_['mean_test_score'].max()\n",
    ")\n",
    "\n",
    "# print cv results\n",
    "print('\\nCrossvalidation Results\\n------------------------------')\n",
    "for i in cv_results:\n",
    "    print(i)\n",
    "\n",
    "# print predictions\n",
    "y_pred = grid.predict(X_test)\n",
    "print('\\nClassification Report\\n------------------------------\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "print('\\nConfusion Matrix\\n------------------------------')\n",
    "plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), vmin=0, cmap='Blues', annot=True, fmt='.0f', cbar=False,\n",
    "           xticklabels=['Not Popular', 'Billboard Hit'], yticklabels=['Not Popular', 'Billboard Hit'])\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c301e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a31aeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30755135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3cc1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153a039b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0677d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff68519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b12a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00a3fe64",
   "metadata": {},
   "source": [
    "# OLD METHOD: no meaningful results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a602d0f",
   "metadata": {},
   "source": [
    "### Which ML models did well with default settings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "8dd92ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('default_results.pickle', 'rb') as f:\n",
    "    default_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "de167432",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_algorithms = [\n",
    "    LogisticRegression,\n",
    "    DecisionTreeClassifier,\n",
    "    KNeighborsClassifier,\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier\n",
    "]\n",
    "\n",
    "def default_results_by_metric(class_type='True', metric='f1-score'):\n",
    "    \"\"\"convert default results into readable form\"\"\"\n",
    "    output_ = []\n",
    "\n",
    "    for algo in ML_algorithms:\n",
    "        algo_ = str(algo())[:-2]\n",
    "        temp_ = [algo_]\n",
    "        for cluster in cluster_keys:\n",
    "            if class_type == 'accuracy':\n",
    "                metric_ = default_results[algo_][cluster][1][class_type]\n",
    "            else:\n",
    "                metric_ = default_results[algo_][cluster][1][class_type][metric]\n",
    "            temp_.append(metric_)\n",
    "        output_.append(temp_)\n",
    "\n",
    "    df_default_results = pd.DataFrame(output_, columns=['Model']+list(default_results['LogisticRegression'].keys()))\n",
    "    df_default_results['min'] = df_default_results.iloc[:, 1:].min(axis=1)\n",
    "    df_default_results['max'] = df_default_results.iloc[:, 1:].max(axis=1)\n",
    "    df_default_results['mean'] = df_default_results.iloc[:, 1:].mean(axis=1)\n",
    "\n",
    "    return df_default_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "a1bdc6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adult_Standard</th>\n",
       "      <td>0.077</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R&amp;B</th>\n",
       "      <td>0.072</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rock</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pop</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rap</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_7</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_1</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_5</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster1_1</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster1_2</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_6</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alternative</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_8</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_0</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metal</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_9</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster1_3</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster1_0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model           LogisticRegression  DecisionTreeClassifier  \\\n",
       "Adult_Standard               0.077                   0.060   \n",
       "R&B                          0.072                   0.063   \n",
       "Country                      0.038                   0.030   \n",
       "Rock                         0.032                   0.029   \n",
       "Pop                          0.021                   0.019   \n",
       "Rap                          0.017                   0.013   \n",
       "cluster2_7                   0.014                   0.012   \n",
       "cluster2_1                   0.012                   0.011   \n",
       "cluster2_5                   0.011                   0.010   \n",
       "cluster1_1                   0.011                   0.010   \n",
       "cluster1_2                   0.010                   0.009   \n",
       "cluster2_6                   0.009                   0.007   \n",
       "All                          0.009                   0.009   \n",
       "Alternative                  0.009                   0.007   \n",
       "cluster2_8                   0.008                   0.007   \n",
       "cluster2_0                   0.008                   0.007   \n",
       "Metal                        0.003                   0.003   \n",
       "cluster2_9                   0.003                   0.003   \n",
       "EDM                          0.003                   0.002   \n",
       "cluster1_3                   0.002                   0.002   \n",
       "cluster2_4                   0.001                   0.001   \n",
       "cluster1_0                   0.001                   0.001   \n",
       "cluster2_3                   0.001                   0.000   \n",
       "cluster2_2                   0.000                   0.000   \n",
       "\n",
       "Model           KNeighborsClassifier  RandomForestClassifier  \\\n",
       "Adult_Standard                 0.065                   0.080   \n",
       "R&B                            0.065                   0.081   \n",
       "Country                        0.033                   0.042   \n",
       "Rock                           0.030                   0.039   \n",
       "Pop                            0.019                   0.026   \n",
       "Rap                            0.014                   0.018   \n",
       "cluster2_7                     0.013                   0.017   \n",
       "cluster2_1                     0.011                   0.016   \n",
       "cluster2_5                     0.010                   0.014   \n",
       "cluster1_1                     0.011                   0.014   \n",
       "cluster1_2                     0.009                   0.013   \n",
       "cluster2_6                     0.008                   0.011   \n",
       "All                            0.009                   0.012   \n",
       "Alternative                    0.007                   0.012   \n",
       "cluster2_8                     0.007                   0.010   \n",
       "cluster2_0                     0.007                   0.009   \n",
       "Metal                          0.003                   0.005   \n",
       "cluster2_9                     0.003                   0.004   \n",
       "EDM                            0.003                   0.004   \n",
       "cluster1_3                     0.002                   0.003   \n",
       "cluster2_4                     0.001                   0.002   \n",
       "cluster1_0                     0.001                   0.001   \n",
       "cluster2_3                     0.000                   0.001   \n",
       "cluster2_2                     0.000                   0.000   \n",
       "\n",
       "Model           AdaBoostClassifier  \n",
       "Adult_Standard               0.077  \n",
       "R&B                          0.076  \n",
       "Country                      0.038  \n",
       "Rock                         0.036  \n",
       "Pop                          0.022  \n",
       "Rap                          0.017  \n",
       "cluster2_7                   0.015  \n",
       "cluster2_1                   0.014  \n",
       "cluster2_5                   0.012  \n",
       "cluster1_1                   0.012  \n",
       "cluster1_2                   0.011  \n",
       "cluster2_6                   0.009  \n",
       "All                          0.010  \n",
       "Alternative                  0.009  \n",
       "cluster2_8                   0.009  \n",
       "cluster2_0                   0.009  \n",
       "Metal                        0.004  \n",
       "cluster2_9                   0.003  \n",
       "EDM                          0.003  \n",
       "cluster1_3                   0.002  \n",
       "cluster2_4                   0.001  \n",
       "cluster1_0                   0.001  \n",
       "cluster2_3                   0.000  \n",
       "cluster2_2                   0.000  "
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best performing classification by cluster = Adult_Standard (1st or 2nd for all ML models)\n",
    "sortbyfeature = 'LogisticRegression'\n",
    "pd.DataFrame(default_results_by_metric().iloc[:, :-3].set_index('Model').T).sort_values(sortbyfeature, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da576a88",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "f612e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huge list of orders of magnitude for gridsearch\n",
    "# formatted a bit funny to avoid rounding errors\n",
    "orders_of_magnitude = []\n",
    "for lst in [[int(x)/10000 for x in range(1, 11)],\n",
    "            [int(x)/1000 for x in range(1, 11)],\n",
    "            [int(x)/100 for x in range(1, 11)],\n",
    "            [int(x)/10 for x in range(1, 11)],\n",
    "            [1 * x for x in range(1, 11)],\n",
    "            [10 * x for x in range(1, 11)],\n",
    "            [100 * x for x in range(1, 11)],\n",
    "            [1000 * x for x in range(1, 11)]]:\n",
    "    orders_of_magnitude += lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "d2122121",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'logisticregression__C': 400, 'logisticregression__penalty': 'l2'},\n",
       " 0.07800708796711779)"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# LOGISTIC REGRESSION\n",
    "\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning setup with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'f1'\n",
    "param_grid = {}\n",
    "param_grid['logisticregression__penalty'] = ['l1', 'l2']\n",
    "param_grid['logisticregression__C'] = orders_of_magnitude\n",
    "\n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    LogisticRegression(solver='liblinear')\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "lr_grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "lr_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "lr_grid.best_params_, lr_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "5dd8ebdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06897831928043999, 0.0, 0.07800708796711779)"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doesn't seem like tuning is doing anything\n",
    "(\n",
    "    lr_grid.cv_results_['mean_test_score'].mean(), \n",
    "    lr_grid.cv_results_['mean_test_score'].min(), \n",
    "    lr_grid.cv_results_['mean_test_score'].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "65432a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'decisiontreeclassifier__criterion': 'gini',\n",
       "  'decisiontreeclassifier__max_depth': None,\n",
       "  'decisiontreeclassifier__min_samples_leaf': 50},\n",
       " 0.07456561474305215)"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# DECISION TREE\n",
    "\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning setup with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'f1'\n",
    "param_grid = {}\n",
    "param_grid['decisiontreeclassifier__max_depth'] = [3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 40, 50, 100, None]\n",
    "param_grid['decisiontreeclassifier__min_samples_leaf'] = [5, 10, 50, 100, 1000]\n",
    "param_grid['decisiontreeclassifier__criterion'] = ['gini', 'entropy']\n",
    "\n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    DecisionTreeClassifier()\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "dt_grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "dt_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "dt_grid.best_params_, dt_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "44700709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06785197229329681, 0.05958234706712688, 0.07456561474305215)"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuning isn't useful here either...\n",
    "(\n",
    "    dt_grid.cv_results_['mean_test_score'].mean(), \n",
    "    dt_grid.cv_results_['mean_test_score'].min(), \n",
    "    dt_grid.cv_results_['mean_test_score'].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "065a4489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'kneighborsclassifier__metric': 'manhattan',\n",
       "  'kneighborsclassifier__n_neighbors': 6,\n",
       "  'kneighborsclassifier__weights': 'uniform'},\n",
       " 0.07027638389807941)"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# KNN\n",
    "\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning setup with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'f1'\n",
    "param_grid = {}\n",
    "param_grid['kneighborsclassifier__n_neighbors'] = [x for x in range(2,20)]+[x for x in range(20,101,5)]\n",
    "param_grid['kneighborsclassifier__weights'] = ['uniform', 'distance']\n",
    "param_grid['kneighborsclassifier__metric'] = ['minkowski', 'euclidean', 'manhattan']\n",
    "\n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    KNeighborsClassifier()\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "knn_grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "knn_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "knn_grid.best_params_, knn_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "0f89a1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06621236939350202, 0.05683753654031316, 0.07027638389807941)"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check min mean and max\n",
    "(\n",
    "    knn_grid.cv_results_['mean_test_score'].mean(), \n",
    "    knn_grid.cv_results_['mean_test_score'].min(), \n",
    "    knn_grid.cv_results_['mean_test_score'].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "e3bd6dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3h 59min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'randomforestclassifier__bootstrap': False,\n",
       "  'randomforestclassifier__max_depth': 30,\n",
       "  'randomforestclassifier__max_features': 'sqrt',\n",
       "  'randomforestclassifier__min_samples_leaf': 5,\n",
       "  'randomforestclassifier__n_estimators': 1000},\n",
       " 0.08028160782282248)"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# random forest\n",
    "\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning setup with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'f1'\n",
    "param_grid = {}\n",
    "param_grid['randomforestclassifier__n_estimators'] = [5, 10, 20, 50, 100, 200, 500, 1000, 2000]\n",
    "param_grid['randomforestclassifier__max_features'] = ['sqrt', 'log2']\n",
    "param_grid['randomforestclassifier__max_depth'] = [3, 5, 7, 10, 15, 20, 30, 50, 100, None]\n",
    "param_grid['randomforestclassifier__min_samples_leaf'] = [5, 10, 50, 100, 1000]\n",
    "param_grid['randomforestclassifier__bootstrap'] = [True, False]\n",
    "\n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    RandomForestClassifier()\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "rf_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "rf_grid.best_params_, rf_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "4b30af1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07444941625954442, 0.0638043296032271, 0.08028160782282248)"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also didn't do great...\n",
    "(\n",
    "    rf_grid.cv_results_['mean_test_score'].mean(), \n",
    "    rf_grid.cv_results_['mean_test_score'].min(), \n",
    "    rf_grid.cv_results_['mean_test_score'].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca9c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# adaboost\n",
    "\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning setup with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'f1'\n",
    "param_grid = {}\n",
    "param_grid['adaboostclassifier__n_estimators'] = [10, 50, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "param_grid['adaboostclassifier__n_learning_rate'] = [0.0001, 0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 1.5, 2.0]\n",
    "param_grid['adaboostclassifier__n_algorithm'] = ['SAMME', 'SAMME.R']\n",
    "        \n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    AdaBoostClassifier()\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "ab_grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "ab_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "ab_grid.best_params_, ab_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b255a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check min mean and max\n",
    "(\n",
    "    ab_grid.cv_results_['mean_test_score'].mean(), \n",
    "    ab_grid.cv_results_['mean_test_score'].min(), \n",
    "    ab_grid.cv_results_['mean_test_score'].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893ad126",
   "metadata": {},
   "source": [
    "### Test Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059b7339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a65e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12613bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7548d980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8bdf80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
