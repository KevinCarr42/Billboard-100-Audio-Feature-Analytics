{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f379970c",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a36765e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# math and dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "\n",
    "# Pipeline and Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, RandomizedSearchCV \n",
    "from sklearn.tree import plot_tree\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "# Undersampling \n",
    "# Note: undersampling was used in at least 1 paper predicting popularity (Gao 2021)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# jupyter notebook full-width display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cbcb793",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10M = pd.read_pickle('df_10M_clustered.pickle')\n",
    "X_all = pd.read_pickle('X_clustered.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed65dd3",
   "metadata": {},
   "source": [
    "# Create Datasets for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "065df1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = 'in_B100'\n",
    "X_columns = [\n",
    "    'mode', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
    "    'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence'\n",
    "]\n",
    "genre_columns = [\n",
    "    'is_Adult_Standard', 'is_Rock', 'is_R&B', 'is_Country', 'is_Pop',\n",
    "    'is_Rap', 'is_Alternative', 'is_EDM', 'is_Metal'\n",
    "]\n",
    "cluster_columns = ['cluster', 'cluster2']\n",
    "other_columns = ['key', 'time_signature', 'genre', 'release_date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64aee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict with all 'name': (X, y) key match pairs\n",
    "clusters = {}\n",
    "\n",
    "# entire predictive dataset\n",
    "clusters['All'] = (X_all[X_columns], X_all[y_column])\n",
    "\n",
    "# add genres\n",
    "for genre in genre_columns:\n",
    "    title = genre[3:]\n",
    "    clusters[title] = (X_all[X_all[genre]][X_columns], X_all[X_all[genre]][y_column])\n",
    "    \n",
    "# add clusters\n",
    "for n in sorted(X_all['cluster'].unique()):\n",
    "    title = genre[3:]\n",
    "    clusters['cluster1_' + str(n)] = (X_all[X_all['cluster'] == n][X_columns], X_all[X_all['cluster'] == n][y_column])\n",
    "    \n",
    "for n in sorted(X_all['cluster2'].unique()):\n",
    "    title = genre[3:]\n",
    "    clusters['cluster2_' + str(n)] = (X_all[X_all['cluster2'] == n][X_columns], X_all[X_all['cluster2'] == n][y_column])\n",
    "    \n",
    "# OPTIONAL IF TIME PERMITS: consider adding decades or eras of music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b6014b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main non-clustered predictive dataset (all data)\n",
    "X, y = clusters['All']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a98d9ab",
   "metadata": {},
   "source": [
    "# Tune Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a9f9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_keys = [\n",
    "    'All', \n",
    "    'Adult_Standard', 'Rock', 'R&B', 'Country', 'Pop', 'Rap', 'Alternative', 'EDM', 'Metal', \n",
    "    'cluster1_0', 'cluster1_1', 'cluster1_2', 'cluster1_3', \n",
    "    'cluster2_0', 'cluster2_1', 'cluster2_2', 'cluster2_3', 'cluster2_4', \n",
    "    'cluster2_5', 'cluster2_6', 'cluster2_7', 'cluster2_8', 'cluster2_9'\n",
    "]\n",
    "\n",
    "ML_algorithms = [\n",
    "    LogisticRegression,\n",
    "    DecisionTreeClassifier,\n",
    "    KNeighborsClassifier,\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cef056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "c49168f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('default_results.pickle', 'rb') as f:\n",
    "    default_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "4277ff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_results_by_metric(class_type='True', metric='f1-score'):\n",
    "    \"\"\"convert default results into readable form\"\"\"\n",
    "    output_ = []\n",
    "\n",
    "    for algo in ML_algorithms:\n",
    "        algo_ = str(algo())[:-2]\n",
    "        temp_ = [algo_]\n",
    "        for cluster in cluster_keys:\n",
    "            if class_type == 'accuracy':\n",
    "                metric_ = default_results[algo_][cluster][1][class_type]\n",
    "            else:\n",
    "                metric_ = default_results[algo_][cluster][1][class_type][metric]\n",
    "            temp_.append(metric_)\n",
    "        output_.append(temp_)\n",
    "\n",
    "    df_default_results = pd.DataFrame(output_, columns=['Model']+list(default_results['LogisticRegression'].keys()))\n",
    "    df_default_results['min'] = df_default_results.iloc[:, 1:].min(axis=1)\n",
    "    df_default_results['max'] = df_default_results.iloc[:, 1:].max(axis=1)\n",
    "    df_default_results['mean'] = df_default_results.iloc[:, 1:].mean(axis=1)\n",
    "\n",
    "    return df_default_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "d0f09c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adult_Standard</th>\n",
       "      <td>0.077</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R&amp;B</th>\n",
       "      <td>0.072</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rock</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pop</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rap</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_7</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_1</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_5</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster1_1</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster1_2</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_6</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alternative</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_8</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_0</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metal</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_9</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster1_3</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster1_0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster2_2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model           LogisticRegression  DecisionTreeClassifier  \\\n",
       "Adult_Standard               0.077                   0.060   \n",
       "R&B                          0.072                   0.063   \n",
       "Country                      0.038                   0.030   \n",
       "Rock                         0.032                   0.029   \n",
       "Pop                          0.021                   0.019   \n",
       "Rap                          0.017                   0.013   \n",
       "cluster2_7                   0.014                   0.012   \n",
       "cluster2_1                   0.012                   0.011   \n",
       "cluster2_5                   0.011                   0.010   \n",
       "cluster1_1                   0.011                   0.010   \n",
       "cluster1_2                   0.010                   0.009   \n",
       "cluster2_6                   0.009                   0.007   \n",
       "All                          0.009                   0.009   \n",
       "Alternative                  0.009                   0.007   \n",
       "cluster2_8                   0.008                   0.007   \n",
       "cluster2_0                   0.008                   0.007   \n",
       "Metal                        0.003                   0.003   \n",
       "cluster2_9                   0.003                   0.003   \n",
       "EDM                          0.003                   0.002   \n",
       "cluster1_3                   0.002                   0.002   \n",
       "cluster2_4                   0.001                   0.001   \n",
       "cluster1_0                   0.001                   0.001   \n",
       "cluster2_3                   0.001                   0.000   \n",
       "cluster2_2                   0.000                   0.000   \n",
       "\n",
       "Model           KNeighborsClassifier  RandomForestClassifier  \\\n",
       "Adult_Standard                 0.065                   0.080   \n",
       "R&B                            0.065                   0.081   \n",
       "Country                        0.033                   0.042   \n",
       "Rock                           0.030                   0.039   \n",
       "Pop                            0.019                   0.026   \n",
       "Rap                            0.014                   0.018   \n",
       "cluster2_7                     0.013                   0.017   \n",
       "cluster2_1                     0.011                   0.016   \n",
       "cluster2_5                     0.010                   0.014   \n",
       "cluster1_1                     0.011                   0.014   \n",
       "cluster1_2                     0.009                   0.013   \n",
       "cluster2_6                     0.008                   0.011   \n",
       "All                            0.009                   0.012   \n",
       "Alternative                    0.007                   0.012   \n",
       "cluster2_8                     0.007                   0.010   \n",
       "cluster2_0                     0.007                   0.009   \n",
       "Metal                          0.003                   0.005   \n",
       "cluster2_9                     0.003                   0.004   \n",
       "EDM                            0.003                   0.004   \n",
       "cluster1_3                     0.002                   0.003   \n",
       "cluster2_4                     0.001                   0.002   \n",
       "cluster1_0                     0.001                   0.001   \n",
       "cluster2_3                     0.000                   0.001   \n",
       "cluster2_2                     0.000                   0.000   \n",
       "\n",
       "Model           AdaBoostClassifier  \n",
       "Adult_Standard               0.077  \n",
       "R&B                          0.076  \n",
       "Country                      0.038  \n",
       "Rock                         0.036  \n",
       "Pop                          0.022  \n",
       "Rap                          0.017  \n",
       "cluster2_7                   0.015  \n",
       "cluster2_1                   0.014  \n",
       "cluster2_5                   0.012  \n",
       "cluster1_1                   0.012  \n",
       "cluster1_2                   0.011  \n",
       "cluster2_6                   0.009  \n",
       "All                          0.010  \n",
       "Alternative                  0.009  \n",
       "cluster2_8                   0.009  \n",
       "cluster2_0                   0.009  \n",
       "Metal                        0.004  \n",
       "cluster2_9                   0.003  \n",
       "EDM                          0.003  \n",
       "cluster1_3                   0.002  \n",
       "cluster2_4                   0.001  \n",
       "cluster1_0                   0.001  \n",
       "cluster2_3                   0.000  \n",
       "cluster2_2                   0.000  "
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best performing classification by cluster = Adult_Standard (1st or 2nd for all ML models)\n",
    "sortbyfeature = 'LogisticRegression'\n",
    "pd.DataFrame(default_results_by_metric().iloc[:, :-3].set_index('Model').T).sort_values(sortbyfeature, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ebf33fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup tuning algorithm with a small dataset\n",
    "small = X_all.sample(10_000)\n",
    "X_small = small[X_columns]\n",
    "y_small = small[y_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d0b78d",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "2ffd468e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'logisticregression__C': 1.1570383472211494,\n",
       "  'logisticregression__penalty': 'l1'},\n",
       " 0.07801951769451305)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'f1'\n",
    "param_grid = {}\n",
    "param_grid['logisticregression__penalty'] = ['l1', 'l2']\n",
    "param_grid['logisticregression__C'] = [\n",
    "    0.0001, 0.0005, 0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100\n",
    "]\n",
    "\n",
    "# pipeline\n",
    "transform = RandomUnderSampler(sampling_strategy='majority')\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "pipe = make_pipeline(transform, model)\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)  # use cv=10 when training the final model\n",
    "\n",
    "# randomise?\n",
    "randomise = True  # randomise had the best results in the small dataset, but both performed similarly\n",
    "if randomise:\n",
    "    param_grid['logisticregression__C'] = sp.stats.lognorm(2, scale=0.1) # log distribution centred at 0.1\n",
    "    lr_grid = RandomizedSearchCV(\n",
    "        estimator = pipe,\n",
    "        param_distributions = param_grid,\n",
    "        cv = cv,\n",
    "        scoring = scoring, \n",
    "        n_jobs = -1,\n",
    "        n_iter = 1000  # 1000 should take 30min\n",
    "    )\n",
    "else:\n",
    "    lr_grid = GridSearchCV(\n",
    "        estimator = pipe,\n",
    "        param_grid = param_grid,\n",
    "        cv = cv,\n",
    "        scoring = scoring, \n",
    "        n_jobs = -1\n",
    "    )\n",
    "\n",
    "# calculate best parameters\n",
    "lr_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "lr_grid.best_params_, lr_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "0c8a7dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huh, that's not better than no tuning... let's try the other algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "fe1c1f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'logisticregression__C': 11.279203301969044}, 0.07790385187982632)"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'f1'\n",
    "param_grid = {}\n",
    "param_grid['logisticregression__C'] = [\n",
    "    0.0001, 0.0005, 0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100\n",
    "]\n",
    "\n",
    "# pipeline\n",
    "transform = RandomUnderSampler(sampling_strategy='majority')\n",
    "model = LogisticRegression()\n",
    "pipe = make_pipeline(transform, model)\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)  # use cv=10 when training the final model\n",
    "\n",
    "# randomise?\n",
    "randomise = True  # randomise had the best results in the small dataset, but both performed similarly\n",
    "if randomise:\n",
    "    param_grid['logisticregression__C'] = sp.stats.lognorm(2, scale=0.1) # log distribution centred at 0.1\n",
    "    lr_grid = RandomizedSearchCV(\n",
    "        estimator = pipe,\n",
    "        param_distributions = param_grid,\n",
    "        cv = cv,\n",
    "        scoring = scoring, \n",
    "        n_jobs = -1,\n",
    "        n_iter = 1000  # 1000 should take 30min\n",
    "    )\n",
    "else:\n",
    "    lr_grid = GridSearchCV(\n",
    "        estimator = pipe,\n",
    "        param_grid = param_grid,\n",
    "        cv = cv,\n",
    "        scoring = scoring, \n",
    "        n_jobs = -1\n",
    "    )\n",
    "\n",
    "# calculate best parameters\n",
    "lr_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "lr_grid.best_params_, lr_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "28cd16d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 59.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'logisticregression__C': 5, 'logisticregression__penalty': 'l1'},\n",
       " 0.07774724465610885)"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# gridsearch, not random\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'f1'\n",
    "param_grid = {}\n",
    "param_grid['logisticregression__penalty'] = ['l1', 'l2']\n",
    "param_grid['logisticregression__C'] = [\n",
    "    0.0001, 0.0005, 0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100\n",
    "]\n",
    "\n",
    "# pipeline\n",
    "transform = RandomUnderSampler(sampling_strategy='majority')\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "pipe = make_pipeline(transform, model)\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)  # use cv=10 when training the final model\n",
    "lr_grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "lr_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "lr_grid.best_params_, lr_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "d4082fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.625"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hmmm doesn't seem to make a difference\n",
    "# maybe switch back to whichever is less steps\n",
    "# maybe add more C values, only doing 32 vs 1000 for rando\n",
    ".98 * 1000 / 32 # seems to scale linearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33aa008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NOTES ####\n",
    "\n",
    "# time taken for n_iter = 10 >>> 28s\n",
    "\n",
    "# 0.03 at C=0.009216644946391565\n",
    "# 0.03 at C=0.005648016650396617\n",
    "# 0.03 at C=0.01325562486033278\n",
    "# 0.0747 at C=0.005211080410662897\n",
    "# 0.03 at C=0.0339936737521536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3aac04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbfc25d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842002ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28455ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c7f6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b477e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c134fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d21c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
