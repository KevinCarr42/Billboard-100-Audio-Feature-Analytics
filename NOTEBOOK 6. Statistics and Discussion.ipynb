{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f379970c",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a36765e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# math and dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# statistics\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import friedmanchisquare, wilcoxon\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Pipeline and Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# jupyter notebook full-width display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cbcb793",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10M = pd.read_pickle('df_10M_clustered.pickle')\n",
    "X_all = pd.read_pickle('X_clustered.pickle')\n",
    "X_all.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed65dd3",
   "metadata": {},
   "source": [
    "# Setup inputs for statistical scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "065df1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns for datasets\n",
    "\n",
    "y_column = 'in_B100'\n",
    "X_columns = [\n",
    "    'mode', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
    "    'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence'\n",
    "]\n",
    "genre_columns = [\n",
    "    'is_Adult_Standard', 'is_Rock', 'is_R&B', 'is_Country', 'is_Pop',\n",
    "    'is_Rap', 'is_Alternative', 'is_EDM', 'is_Metal'\n",
    "]\n",
    "cluster_columns = ['cluster', 'cluster2']\n",
    "other_columns = ['key', 'time_signature', 'genre', 'release_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d64aee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters\n",
    "\n",
    "# create a dict with all 'name': (X, y) key match pairs\n",
    "clusters = {}\n",
    "\n",
    "# entire predictive dataset\n",
    "clusters['All'] = (X_all[X_columns], X_all[y_column])\n",
    "\n",
    "# add genres\n",
    "for genre in genre_columns:\n",
    "    title = genre[3:]\n",
    "    clusters[title] = (X_all[X_all[genre]][X_columns], X_all[X_all[genre]][y_column])\n",
    "    \n",
    "# add clusters\n",
    "for n in sorted(X_all['cluster'].unique()):\n",
    "    title = genre[3:]\n",
    "    clusters['cluster1_' + str(n)] = (X_all[X_all['cluster'] == n][X_columns], X_all[X_all['cluster'] == n][y_column])\n",
    "    \n",
    "for n in sorted(X_all['cluster2'].unique()):\n",
    "    title = genre[3:]\n",
    "    clusters['cluster2_' + str(n)] = (X_all[X_all['cluster2'] == n][X_columns], X_all[X_all['cluster2'] == n][y_column])\n",
    "\n",
    "# a small dataset for testing\n",
    "small = X_all.sample(10_000, random_state=42)\n",
    "X_small = small[X_columns]\n",
    "y_small = small[y_column]\n",
    "clusters['small'] = (X_small, y_small)\n",
    "\n",
    "cluster_keys = [\n",
    "    'All', \n",
    "    'Adult_Standard', 'Rock', 'R&B', 'Country', 'Pop', 'Rap', 'Alternative', 'EDM', 'Metal', \n",
    "    'cluster1_0', 'cluster1_1', 'cluster1_2', 'cluster1_3', \n",
    "    'cluster2_0', 'cluster2_1', 'cluster2_2', 'cluster2_3', 'cluster2_4', \n",
    "    'cluster2_5', 'cluster2_6', 'cluster2_7', 'cluster2_8', 'cluster2_9',\n",
    "    'small'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b6014b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning algorithms\n",
    "# note: tensorflow is harder to tune and use in a pipeline, so has been kept separate\n",
    "\n",
    "ML_algorithms = [\n",
    "    LogisticRegression,\n",
    "    DecisionTreeClassifier,\n",
    "    KNeighborsClassifier,\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18cfdba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 160\n",
      "DecisionTreeClassifier 160\n",
      "KNeighborsClassifier 210\n",
      "RandomForestClassifier 1800\n",
      "AdaBoostClassifier 162\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "\n",
    "param_by_model = {}\n",
    "\n",
    "params_lr = {}\n",
    "orders_of_magnitude = []\n",
    "for lst in [[int(x)/10000 for x in range(1, 11)],\n",
    "            [int(x)/1000 for x in range(1, 11)],\n",
    "            [int(x)/100 for x in range(1, 11)],\n",
    "            [int(x)/10 for x in range(1, 11)],\n",
    "            [1 * x for x in range(1, 11)],\n",
    "            [10 * x for x in range(1, 11)],\n",
    "            [100 * x for x in range(1, 11)],\n",
    "            [1000 * x for x in range(1, 11)]]:\n",
    "    orders_of_magnitude += lst\n",
    "params_lr['logisticregression__penalty'] = ['l1', 'l2']\n",
    "params_lr['logisticregression__C'] = orders_of_magnitude\n",
    "params_lr['logisticregression__solver'] = ['liblinear']\n",
    "param_by_model[0] = params_lr\n",
    "\n",
    "params_dt = {}\n",
    "params_dt['decisiontreeclassifier__max_depth'] = [3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 40, 50, 100, None]\n",
    "params_dt['decisiontreeclassifier__min_samples_leaf'] = [5, 10, 50, 100, 1000]\n",
    "params_dt['decisiontreeclassifier__criterion'] = ['gini', 'entropy']\n",
    "param_by_model[1] = params_dt\n",
    "\n",
    "params_knn = {}\n",
    "params_knn['kneighborsclassifier__n_neighbors'] = [x for x in range(2,20)]+[x for x in range(20,101,5)]\n",
    "params_knn['kneighborsclassifier__weights'] = ['uniform', 'distance']\n",
    "params_knn['kneighborsclassifier__metric'] = ['minkowski', 'euclidean', 'manhattan']\n",
    "param_by_model[2] = params_knn\n",
    "\n",
    "params_rf = {}\n",
    "params_rf['randomforestclassifier__n_estimators'] = [5, 10, 20, 50, 100, 200, 500, 1000, 2000]\n",
    "params_rf['randomforestclassifier__max_features'] = ['sqrt', 'log2']\n",
    "params_rf['randomforestclassifier__max_depth'] = [3, 5, 7, 10, 15, 20, 30, 50, 100, None]\n",
    "params_rf['randomforestclassifier__min_samples_leaf'] = [5, 10, 50, 100, 1000]\n",
    "params_rf['randomforestclassifier__bootstrap'] = [True, False]\n",
    "param_by_model[3] = params_rf\n",
    "\n",
    "params_ab = {}\n",
    "params_ab['adaboostclassifier__n_estimators'] = [10, 50, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "params_ab['adaboostclassifier__learning_rate'] = [0.0001, 0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 1.5, 2.0]\n",
    "params_ab['adaboostclassifier__algorithm'] = ['SAMME', 'SAMME.R']\n",
    "param_by_model[4] = params_ab\n",
    "\n",
    "# scoring metrics\n",
    "\n",
    "metrics = [\n",
    "    'balanced_accuracy', 'average_precision', 'neg_brier_score', 'f1', 'f1_micro', \n",
    "    'f1_macro', 'f1_weighted', 'neg_log_loss', 'precision', 'recall', 'roc_auc', 'jaccard'\n",
    "]\n",
    "\n",
    "# how many hyperparameter scenarios in the grid search\n",
    "\n",
    "def how_many_scenarios(n_ML):\n",
    "    n_scenarios = 1\n",
    "    for key in param_by_model[n_ML].keys():\n",
    "        n_scenarios *=  len(param_by_model[n_ML][key])\n",
    "    return n_scenarios\n",
    "\n",
    "for i in range(5):\n",
    "    print(str(ML_algorithms[i]())[:-2], how_many_scenarios(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c41815",
   "metadata": {},
   "source": [
    "# Make Predictions Dataframe for Statistics\n",
    "* split into 5 stratified folds\n",
    "    * using a consistent random_state to use the same folds between tests\n",
    "* for each fold:\n",
    "    * train on undersampled training fold\n",
    "    * predict on full test fold\n",
    "    * add out of fold predictions to add to predictions dataframe\n",
    "    \n",
    "NOTES: \n",
    "* Tuning individual models on limited datasets has been investigated in NOTEBOOK 5B (and 5D).\n",
    "* Random undersampling and oversampling were investigated in NOTEBOOK 5A\n",
    "    * More oversampling methods like SMOTE were not considered because the nature of music. For example, interpolating between modes leads to an atonal, non-musical result. Discrete combinations of features are likely to be important in terms of audio features as well. More importantly, with over 20k positive cases in our dataset, we should have enough data for a well trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d9c4ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the dataframe\n",
    "\n",
    "# use the same stratified split for all test cases\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# scenarios to test\n",
    "stats_scenarios = [\n",
    "    'y_lr', 'y_dt', 'y_knn', 'y_rf', 'y_ab', 'y_lr_tuned', 'y_knn_tuned', 'y_cl_1', 'y_cl_2', 'y_genres'\n",
    "]\n",
    "\n",
    "df_predictions = pd.DataFrame(columns=stats_scenarios)\n",
    "df_predictions['y_actual'] = pd.NA  # for debugging\n",
    "df_predictions = pd.concat([X_all, df_predictions], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b65d7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_default_performance(dataframe, X_columns, y_column, n_scenario):\n",
    "    \n",
    "    # entire dataset for predictions\n",
    "    X_, y_ = dataframe[X_columns], dataframe[y_column]\n",
    "    \n",
    "    # actual y and predicted y\n",
    "    y_actual = pd.DataFrame()\n",
    "    y_pred = pd.DataFrame()\n",
    "\n",
    "    # loop through folds\n",
    "    for train_i, test_i in kfold.split(X_, y_):\n",
    "\n",
    "        # train test split for current fold\n",
    "        train_X, test_X = X_.iloc[train_i], X_.iloc[test_i]\n",
    "        train_y, test_y = y_.iloc[train_i], y_.iloc[test_i]\n",
    "        \n",
    "        # create and fit pipeline\n",
    "        undersampler = RandomUnderSampler(sampling_strategy='majority', random_state=42)\n",
    "        \n",
    "        if n_scenario in [1]:\n",
    "            model = DecisionTreeClassifier()\n",
    "        elif n_scenario in [2, 6]:\n",
    "            model = KNeighborsClassifier()\n",
    "        elif n_scenario in [3]:\n",
    "            model = RandomForestClassifier()\n",
    "        elif n_scenario in [4]:\n",
    "            model = AdaBoostClassifier()\n",
    "        else:\n",
    "            model = LogisticRegression()\n",
    "        \n",
    "        pipe = make_pipeline(undersampler, model)\n",
    "        \n",
    "        pipe.fit(train_X, train_y)\n",
    "        \n",
    "        # append results\n",
    "        y_pred_temp = pipe.predict(test_X)\n",
    "        y_pred_temp = pd.concat([\n",
    "            pd.DataFrame(y_pred_temp),\n",
    "            pd.DataFrame(test_i, columns=[''])\n",
    "        ], axis=1).set_index('')\n",
    "        y_pred = pd.concat([y_pred, y_pred_temp], axis=0)\n",
    "        y_actual = pd.concat([y_actual, test_y], axis=0)  # for debugging\n",
    "\n",
    "    return y_pred.sort_index()\n",
    "    \n",
    "#     # return the full sorted results, appended into the input dataframe\n",
    "#     dataframe[stats_scenarios[n_scenario]] = y_pred.sort_index()\n",
    "#     dataframe['y_actual'] = y_actual.sort_index()  # for debugging, this should always be equal to in_B100 or folds are misaligned\n",
    "    \n",
    "#     return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "81270378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# which statistical scenario are we evaluating\n",
    "n_scenario = 0\n",
    "\n",
    "TEMP = evaluate_default_performance(df_predictions, X_columns, y_column, n_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c80a96f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827714</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827715</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827716</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827717</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827718</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8827719 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "              \n",
       "0        False\n",
       "1        False\n",
       "2         True\n",
       "3         True\n",
       "4        False\n",
       "...        ...\n",
       "8827714  False\n",
       "8827715   True\n",
       "8827716  False\n",
       "8827717   True\n",
       "8827718  False\n",
       "\n",
       "[8827719 rows x 1 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "aa3a48a9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'in_B100'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8208/1830870490.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# should be zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEMP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'in_B100'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mTEMP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_actual'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    386\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'in_B100'"
     ]
    }
   ],
   "source": [
    "# should be zero\n",
    "sum(TEMP['in_B100'] != TEMP['y_actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fcd59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions[stats_scenarios[n_scenario]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f4325f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827668</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827670</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827695</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827711</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827714</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1765543 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [13, 15, 16, 20, 24, 26, 35, 47, 54, 58, 59, 60, 64, 91, 108, 117, 129, 134, 146, 149, 168, 169, 176, 183, 202, 206, 209, 215, 216, 218, 221, 222, 226, 227, 237, 241, 247, 248, 257, 258, 259, 264, 267, 268, 269, 271, 277, 284, 290, 296, 297, 302, 308, 312, 313, 314, 319, 320, 322, 326, 327, 329, 341, 342, 344, 347, 348, 349, 355, 358, 362, 368, 371, 384, 385, 387, 395, 415, 419, 424, 431, 432, 437, 439, 441, 447, 452, 455, 465, 466, 472, 473, 475, 477, 482, 484, 489, 495, 499, 503, ...]\n",
       "\n",
       "[1765543 rows x 0 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for train_i, test_i in kfold.split(X_, y_):\n",
    "    pass\n",
    "\n",
    "tempdataframe = pd.DataFrame()\n",
    "tempdataframe = pd.concat([tempdataframe, ], axis=1).set_index('')\n",
    "tempdataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b835df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafaf340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4103cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba785a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13baaf50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fd064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions with base algorithms\n",
    "\n",
    "\n",
    "# save dataframe\n",
    "df_predictions.to_pickle('df_predictions_DEFAULT.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266f26b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions with tuned logistic regression, tuned knn\n",
    "\n",
    "\n",
    "# save dataframe\n",
    "df_predictions.to_pickle('df_predictions_TUNED.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49597aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions separating into clusters and genres\n",
    "\n",
    "\n",
    "\n",
    "# save dataframe\n",
    "df_predictions.to_pickle('df_predictions_CLUSTERS.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a15e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final predictions dataframe\n",
    "df_predictions.to_pickle('df_predictions.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031c1211",
   "metadata": {},
   "source": [
    "# Explore Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646178f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Friedman Test (Wilcoxn if required)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a988ac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms \n",
    "## NEED TO COMBINE WITH id to compare AF\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
