{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f379970c",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a36765e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# math and dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# statistics\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import friedmanchisquare, wilcoxon\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Pipeline and Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# jupyter notebook full-width display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cbcb793",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10M = pd.read_pickle('df_10M_clustered.pickle')\n",
    "X_all = pd.read_pickle('X_clustered.pickle')\n",
    "X_all.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed65dd3",
   "metadata": {},
   "source": [
    "# Setup inputs for statistical scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "065df1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns for datasets\n",
    "\n",
    "y_column = 'in_B100'\n",
    "X_columns = [\n",
    "    'mode', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
    "    'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence'\n",
    "]\n",
    "genre_columns = [\n",
    "    'is_Adult_Standard', 'is_Rock', 'is_R&B', 'is_Country', 'is_Pop',\n",
    "    'is_Rap', 'is_Alternative', 'is_EDM', 'is_Metal'\n",
    "]\n",
    "cluster_columns = ['cluster', 'cluster2']\n",
    "other_columns = ['key', 'time_signature', 'genre', 'release_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d64aee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters\n",
    "\n",
    "# create a dict with all 'name': (X, y) key match pairs\n",
    "clusters = {}\n",
    "\n",
    "# entire predictive dataset\n",
    "clusters['All'] = (X_all[X_columns], X_all[y_column])\n",
    "\n",
    "# add genres\n",
    "for genre in genre_columns:\n",
    "    title = genre[3:]\n",
    "    clusters[title] = (X_all[X_all[genre]][X_columns], X_all[X_all[genre]][y_column])\n",
    "    \n",
    "# add clusters\n",
    "for n in sorted(X_all['cluster'].unique()):\n",
    "    title = genre[3:]\n",
    "    clusters['cluster1_' + str(n)] = (X_all[X_all['cluster'] == n][X_columns], X_all[X_all['cluster'] == n][y_column])\n",
    "    \n",
    "for n in sorted(X_all['cluster2'].unique()):\n",
    "    title = genre[3:]\n",
    "    clusters['cluster2_' + str(n)] = (X_all[X_all['cluster2'] == n][X_columns], X_all[X_all['cluster2'] == n][y_column])\n",
    "\n",
    "# a small dataset for testing\n",
    "small = X_all.sample(10_000, random_state=42)\n",
    "X_small = small[X_columns]\n",
    "y_small = small[y_column]\n",
    "clusters['small'] = (X_small, y_small)\n",
    "\n",
    "cluster_keys = [\n",
    "    'All', \n",
    "    'Adult_Standard', 'Rock', 'R&B', 'Country', 'Pop', 'Rap', 'Alternative', 'EDM', 'Metal', \n",
    "    'cluster1_0', 'cluster1_1', 'cluster1_2', 'cluster1_3', \n",
    "    'cluster2_0', 'cluster2_1', 'cluster2_2', 'cluster2_3', 'cluster2_4', \n",
    "    'cluster2_5', 'cluster2_6', 'cluster2_7', 'cluster2_8', 'cluster2_9',\n",
    "    'small'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b6014b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning algorithms\n",
    "# note: tensorflow is harder to tune and use in a pipeline, so has been kept separate\n",
    "\n",
    "ML_algorithms = [\n",
    "    LogisticRegression,\n",
    "    DecisionTreeClassifier,\n",
    "    KNeighborsClassifier,\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18cfdba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 160\n",
      "DecisionTreeClassifier 160\n",
      "KNeighborsClassifier 210\n",
      "RandomForestClassifier 1800\n",
      "AdaBoostClassifier 162\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "\n",
    "param_by_model = {}\n",
    "\n",
    "params_lr = {}\n",
    "orders_of_magnitude = []\n",
    "for lst in [[int(x)/10000 for x in range(1, 11)],\n",
    "            [int(x)/1000 for x in range(1, 11)],\n",
    "            [int(x)/100 for x in range(1, 11)],\n",
    "            [int(x)/10 for x in range(1, 11)],\n",
    "            [1 * x for x in range(1, 11)],\n",
    "            [10 * x for x in range(1, 11)],\n",
    "            [100 * x for x in range(1, 11)],\n",
    "            [1000 * x for x in range(1, 11)]]:\n",
    "    orders_of_magnitude += lst\n",
    "params_lr['logisticregression__penalty'] = ['l1', 'l2']\n",
    "params_lr['logisticregression__C'] = orders_of_magnitude\n",
    "params_lr['logisticregression__solver'] = ['liblinear']\n",
    "param_by_model[0] = params_lr\n",
    "\n",
    "params_dt = {}\n",
    "params_dt['decisiontreeclassifier__max_depth'] = [3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 40, 50, 100, None]\n",
    "params_dt['decisiontreeclassifier__min_samples_leaf'] = [5, 10, 50, 100, 1000]\n",
    "params_dt['decisiontreeclassifier__criterion'] = ['gini', 'entropy']\n",
    "param_by_model[1] = params_dt\n",
    "\n",
    "params_knn = {}\n",
    "params_knn['kneighborsclassifier__n_neighbors'] = [x for x in range(2,20)]+[x for x in range(20,101,5)]\n",
    "params_knn['kneighborsclassifier__weights'] = ['uniform', 'distance']\n",
    "params_knn['kneighborsclassifier__metric'] = ['minkowski', 'euclidean', 'manhattan']\n",
    "param_by_model[2] = params_knn\n",
    "\n",
    "params_rf = {}\n",
    "params_rf['randomforestclassifier__n_estimators'] = [5, 10, 20, 50, 100, 200, 500, 1000, 2000]\n",
    "params_rf['randomforestclassifier__max_features'] = ['sqrt', 'log2']\n",
    "params_rf['randomforestclassifier__max_depth'] = [3, 5, 7, 10, 15, 20, 30, 50, 100, None]\n",
    "params_rf['randomforestclassifier__min_samples_leaf'] = [5, 10, 50, 100, 1000]\n",
    "params_rf['randomforestclassifier__bootstrap'] = [True, False]\n",
    "param_by_model[3] = params_rf\n",
    "\n",
    "params_ab = {}\n",
    "params_ab['adaboostclassifier__n_estimators'] = [10, 50, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "params_ab['adaboostclassifier__learning_rate'] = [0.0001, 0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 1.5, 2.0]\n",
    "params_ab['adaboostclassifier__algorithm'] = ['SAMME', 'SAMME.R']\n",
    "param_by_model[4] = params_ab\n",
    "\n",
    "# scoring metrics\n",
    "\n",
    "metrics = [\n",
    "    'balanced_accuracy', 'average_precision', 'neg_brier_score', 'f1', 'f1_micro', \n",
    "    'f1_macro', 'f1_weighted', 'neg_log_loss', 'precision', 'recall', 'roc_auc', 'jaccard'\n",
    "]\n",
    "\n",
    "# how many hyperparameter scenarios in the grid search\n",
    "\n",
    "def how_many_scenarios(n_ML):\n",
    "    n_scenarios = 1\n",
    "    for key in param_by_model[n_ML].keys():\n",
    "        n_scenarios *=  len(param_by_model[n_ML][key])\n",
    "    return n_scenarios\n",
    "\n",
    "for i in range(5):\n",
    "    print(str(ML_algorithms[i]())[:-2], how_many_scenarios(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f3f99",
   "metadata": {},
   "source": [
    "# Make Predictions Dataframe for Statistics\n",
    "* split into 5 stratified folds\n",
    "    * using a consistent random_state to use the same folds between tests\n",
    "* for each fold:\n",
    "    * train on undersampled training fold\n",
    "    * predict on full test fold\n",
    "    * add out of fold predictions to add to predictions dataframe\n",
    "    \n",
    "NOTES: \n",
    "* Tuning individual models on limited datasets has been investigated in NOTEBOOK 5B (and 5D).\n",
    "* Random undersampling and oversampling were investigated in NOTEBOOK 5A\n",
    "    * More oversampling methods like SMOTE were not considered because the nature of music. For example, interpolating between modes leads to an atonal, non-musical result. Discrete combinations of features are likely to be important in terms of audio features as well. More importantly, with over 20k positive cases in our dataset, we should have enough data for a well trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a48848a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the dataframe\n",
    "\n",
    "# use the same stratified split for all test cases\n",
    "stratified_5fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# scenarios to test\n",
    "stats_scenarios = [\n",
    "    'y_lr', 'y_dt', 'y_knn', 'y_rf', 'y_ab', 'y_lr_tuned', 'y_knn_tuned', 'y_cl_1', 'y_cl_2', 'y_genres'\n",
    "]\n",
    "\n",
    "df_predictions = pd.DataFrame(columns=stats_scenarios)\n",
    "df_predictions['y_actual'] = pd.NA  # for debugging\n",
    "df_predictions = pd.concat([X_all, df_predictions], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dbf2af",
   "metadata": {},
   "source": [
    "### Predict Using Default Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "faa59a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_default_performance(dataframe, kfold, feature_columns, class_column, n_scenario):\n",
    "    \n",
    "    # entire dataset for predictions\n",
    "    X_, y_ = dataframe[feature_columns], dataframe[class_column]\n",
    "    \n",
    "    # initialise actual y and predicted y as blank dataframes\n",
    "    y_actual = pd.DataFrame()\n",
    "    y_pred = pd.DataFrame()\n",
    "\n",
    "    # loop through folds\n",
    "    for train_i, test_i in kfold.split(X_, y_):\n",
    "\n",
    "        # train test split for current fold\n",
    "        train_X, test_X = X_.iloc[train_i], X_.iloc[test_i]\n",
    "        train_y, test_y = y_.iloc[train_i], y_.iloc[test_i]\n",
    "        \n",
    "        # create and fit pipeline\n",
    "        undersampler = RandomUnderSampler(sampling_strategy='majority', random_state=42)\n",
    "        \n",
    "        if n_scenario in [1]:\n",
    "            model = DecisionTreeClassifier()\n",
    "        elif n_scenario in [2, 6]:\n",
    "            model = KNeighborsClassifier()\n",
    "        elif n_scenario in [3]:\n",
    "            model = RandomForestClassifier()\n",
    "        elif n_scenario in [4]:\n",
    "            model = AdaBoostClassifier()\n",
    "        else:\n",
    "            model = LogisticRegression()\n",
    "        \n",
    "        pipe = make_pipeline(undersampler, model)\n",
    "        \n",
    "        pipe.fit(train_X, train_y)\n",
    "        \n",
    "        # append results\n",
    "        y_pred_temp = pipe.predict(test_X)\n",
    "        y_pred_temp = pd.concat([\n",
    "            pd.DataFrame(y_pred_temp),\n",
    "            pd.DataFrame(test_i, columns=[''])\n",
    "        ], axis=1).set_index('')\n",
    "        y_pred = pd.concat([y_pred, y_pred_temp], axis=0)\n",
    "        y_actual = pd.concat([y_actual, test_y], axis=0)  # for debugging\n",
    "\n",
    "    # return the full sorted results, appended into the input dataframe\n",
    "    dataframe[stats_scenarios[n_scenario]] = y_pred.sort_index()\n",
    "    dataframe['y_actual'] = y_actual.sort_index()  # for debugging, this should always be equal to in_B100 or folds are misaligned\n",
    "    \n",
    "    # DEBUGGING: should be zero\n",
    "    is_ERRORS = sum(dataframe['in_B100'] != dataframe['y_actual'])\n",
    "    if is_ERRORS != 0:\n",
    "        print('THERE WERE ERRORS!!!! (compare the in_B100 and y_actual columns)')\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8ab3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Logistic Regression\n",
    "n_scenario = 0\n",
    "df_predictions = evaluate_default_performance(df_predictions, stratified_5fold, X_columns, y_column, n_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c83ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Decision Tree\n",
    "n_scenario = 1\n",
    "df_predictions = evaluate_default_performance(df_predictions, stratified_5fold, X_columns, y_column, n_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de4df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# K Nearest Neighbours\n",
    "n_scenario = 2\n",
    "df_predictions = evaluate_default_performance(df_predictions, stratified_5fold, X_columns, y_column, n_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fddb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Random Forest\n",
    "n_scenario = 3\n",
    "df_predictions = evaluate_default_performance(df_predictions, stratified_5fold, X_columns, y_column, n_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65bec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# AdaBoost\n",
    "n_scenario = 4\n",
    "df_predictions = evaluate_default_performance(df_predictions, stratified_5fold, X_columns, y_column, n_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d7bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe\n",
    "df_predictions.to_pickle('df_predictions_DEFAULT.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88004e7",
   "metadata": {},
   "source": [
    "### Make Predictions with tuned logistic regression and tuned kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e5330c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f7f816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a59df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe\n",
    "df_predictions.to_pickle('df_predictions_TUNED.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6cac86",
   "metadata": {},
   "source": [
    "### Make predictions separating into clusters and genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2700e911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb31d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bdc883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe\n",
    "df_predictions.to_pickle('df_predictions_CLUSTERS.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4631a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final predictions dataframe\n",
    "df_predictions.to_pickle('df_predictions.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a899d",
   "metadata": {},
   "source": [
    "# Explore Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2735be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Friedman Test (Wilcoxn if required)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18f6b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms \n",
    "## NEED TO COMBINE WITH id to compare AF\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
