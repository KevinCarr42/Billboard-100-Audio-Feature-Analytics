{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e8981b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# math and dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# neural network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Pipeline and Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "# Undersampling \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# jupyter notebook full-width display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef73037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10M = pd.read_pickle('df_10M_clustered.pickle')\n",
    "X_all = pd.read_pickle('X_clustered.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c66ad633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to cast to float to use in tensor\n",
    "X_all['mode'] = X_all['mode'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c52df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = 'in_B100'\n",
    "X_columns = [\n",
    "    'mode', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
    "    'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence'\n",
    "]\n",
    "genre_columns = [\n",
    "    'is_Adult_Standard', 'is_Rock', 'is_R&B', 'is_Country', 'is_Pop',\n",
    "    'is_Rap', 'is_Alternative', 'is_EDM', 'is_Metal'\n",
    "]\n",
    "cluster_columns = ['cluster', 'cluster2']\n",
    "other_columns = ['key', 'time_signature', 'genre', 'release_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1361dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict with all 'name': (X, y) key match pairs\n",
    "clusters = {}\n",
    "\n",
    "# entire predictive dataset\n",
    "clusters['All'] = (X_all[X_columns+genre_columns], X_all[y_column])\n",
    "# clusters['All'] = (X_all[X_columns], X_all[y_column])\n",
    "\n",
    "# add genres\n",
    "for genre in genre_columns:\n",
    "    title = genre[3:]\n",
    "    clusters[title] = (X_all[X_all[genre]][X_columns], X_all[X_all[genre]][y_column])\n",
    "    \n",
    "# add clusters\n",
    "for n in sorted(X_all['cluster'].unique()):\n",
    "    title = genre[3:]\n",
    "    clusters['cluster1_' + str(n)] = (X_all[X_all['cluster'] == n][X_columns], X_all[X_all['cluster'] == n][y_column])\n",
    "    \n",
    "for n in sorted(X_all['cluster2'].unique()):\n",
    "    title = genre[3:]\n",
    "    clusters['cluster2_' + str(n)] = (X_all[X_all['cluster2'] == n][X_columns], X_all[X_all['cluster2'] == n][y_column])\n",
    "    \n",
    "# setup tuning algorithm with a small dataset\n",
    "small = X_all.sample(10_000, random_state=42)\n",
    "X_small = small[X_columns]\n",
    "y_small = small[y_column]\n",
    "clusters['small'] = (X_small, y_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "404bc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenarios to check\n",
    "\n",
    "metrics = [\n",
    "    'balanced_accuracy', 'average_precision', 'neg_brier_score', 'f1', 'f1_micro', \n",
    "    'f1_macro', 'f1_weighted', 'neg_log_loss', 'precision', 'recall', 'roc_auc', 'jaccard'\n",
    "]\n",
    "\n",
    "cluster1_keys = [\n",
    "    'cluster1_0', 'cluster1_1', 'cluster1_2', 'cluster1_3'\n",
    "]\n",
    "\n",
    "cluster2_keys = [\n",
    "    'cluster2_0', 'cluster2_1', 'cluster2_2', 'cluster2_3', 'cluster2_4', \n",
    "    'cluster2_5', 'cluster2_6', 'cluster2_7', 'cluster2_8', 'cluster2_9',\n",
    "]\n",
    "\n",
    "genre_keys = [\n",
    "    'Adult_Standard', 'Rock', 'R&B', 'Country', 'Pop', 'Rap', 'Alternative', 'EDM', 'Metal'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d53f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the neural network\n",
    "\n",
    "# start with width of number of features \n",
    "# (could encode to higher dimensions)\n",
    "tf_width = len(X_columns)\n",
    "tf_dropout = 0\n",
    "\n",
    "# setup\n",
    "tf_model = Sequential(name='sequential')\n",
    "\n",
    "# hidden layers\n",
    "how_many_hidden_layers = 5\n",
    "for i in range(how_many_hidden_layers):\n",
    "    tf_model.add(Dense(tf_width, activation=\"relu\", name='dense_'+str(i)))\n",
    "    tf_model.add(Dropout(tf_dropout, name='dropout_'+str(i)))\n",
    "\n",
    "# output\n",
    "tf_model.add(Dense(1, activation='sigmoid', name='output'))\n",
    "\n",
    "# setup a checkpoint to save model\n",
    "checkpoint = ModelCheckpoint('tf_model', save_best_only=True)\n",
    "\n",
    "# compile model\n",
    "tf_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0fb3b218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "247/275 [=========================>....] - ETA: 0s - loss: 0.6933 - auc_3: 0.5555INFO:tensorflow:Assets written to: tf_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 10s 36ms/step - loss: 0.6923 - auc_3: 0.5575 - val_loss: 0.6411 - val_auc_3: 0.5908\n",
      "Epoch 2/10\n",
      "275/275 [==============================] - 9s 31ms/step - loss: 0.6811 - auc_3: 0.5848 - val_loss: 0.6692 - val_auc_3: 0.6051\n",
      "Epoch 3/10\n",
      "251/275 [==========================>...] - ETA: 0s - loss: 0.6764 - auc_3: 0.5990INFO:tensorflow:Assets written to: tf_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 10s 36ms/step - loss: 0.6770 - auc_3: 0.5980 - val_loss: 0.6306 - val_auc_3: 0.6151\n",
      "Epoch 4/10\n",
      "253/275 [==========================>...] - ETA: 0s - loss: 0.6745 - auc_3: 0.6037INFO:tensorflow:Assets written to: tf_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 10s 35ms/step - loss: 0.6739 - auc_3: 0.6056 - val_loss: 0.6266 - val_auc_3: 0.6203\n",
      "Epoch 5/10\n",
      "275/275 [==============================] - 9s 32ms/step - loss: 0.6724 - auc_3: 0.6091 - val_loss: 0.7199 - val_auc_3: 0.6241\n",
      "Epoch 6/10\n",
      "275/275 [==============================] - 9s 32ms/step - loss: 0.6703 - auc_3: 0.6159 - val_loss: 0.7639 - val_auc_3: 0.6273\n",
      "Epoch 7/10\n",
      "275/275 [==============================] - 9s 31ms/step - loss: 0.6694 - auc_3: 0.6203 - val_loss: 0.6649 - val_auc_3: 0.6318\n",
      "Epoch 8/10\n",
      "275/275 [==============================] - 9s 31ms/step - loss: 0.6680 - auc_3: 0.6256 - val_loss: 0.7383 - val_auc_3: 0.6331\n",
      "Epoch 9/10\n",
      "275/275 [==============================] - 9s 31ms/step - loss: 0.6669 - auc_3: 0.6280 - val_loss: 0.7024 - val_auc_3: 0.6375\n",
      "Epoch 10/10\n",
      "256/275 [==========================>...] - ETA: 0s - loss: 0.6658 - auc_3: 0.6314INFO:tensorflow:Assets written to: tf_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 10s 36ms/step - loss: 0.6654 - auc_3: 0.6327 - val_loss: 0.6212 - val_auc_3: 0.6414\n",
      "Wall time: 1min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b203533100>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# train the model\n",
    "\n",
    "# pick the dataset\n",
    "am_testing = False\n",
    "if am_testing:\n",
    "    dataset = 'small'\n",
    "else:\n",
    "    dataset = 'cluster2_7' # good amount of hits, about 1M songs \n",
    "X_, y_ = clusters[dataset]\n",
    "\n",
    "# split the dataset into train test, then separate validation set for fitting the neural network\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=42, stratify=y_)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42, stratify=y_train)\n",
    "\n",
    "# undersample data\n",
    "undersample = True\n",
    "if undersample:\n",
    "    undersampler = RandomUnderSampler(sampling_strategy='majority', random_state=42)\n",
    "    X_train, y_train = undersampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "# convert to Numpy arrays\n",
    "X_train = np.asarray(X_train).astype('float32')\n",
    "X_val = np.asarray(X_val).astype('float32')\n",
    "X_test = np.asarray(X_test).astype('float32')\n",
    "y_train = np.asarray(y_train).astype('float32')\n",
    "y_val = np.asarray(y_val).astype('float32')\n",
    "y_test = np.asarray(y_test).astype('float32')\n",
    "\n",
    "# fit the data\n",
    "tf_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, callbacks=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2ae9846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 611us/step\n",
      "\n",
      "Classification Report\n",
      "------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.45      0.62      1994\n",
      "         1.0       0.00      0.83      0.01         6\n",
      "\n",
      "    accuracy                           0.45      2000\n",
      "   macro avg       0.50      0.64      0.32      2000\n",
      "weighted avg       1.00      0.45      0.62      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and check results\n",
    "y_pred = tf_model.predict(X_test)\n",
    "print('\\nClassification Report\\n------------------------------\\n', classification_report(y_test, y_pred.flatten() > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "670792be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000.000</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count  mean   std   min   25%   50%   75%   max\n",
       "0 2000.000 0.555 0.141 0.308 0.429 0.538 0.684 0.834"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this neural network is not very certain about anything\n",
    "pd.DataFrame(y_pred).describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "920db6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2.5%</th>\n",
       "      <td>0.365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.5%</th>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "2.5%  0.365\n",
       "97.5% 0.792"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 95% of predictions are in this range of certainty\n",
    "pd.DataFrame(y_pred).describe([0.025, 0.975]).loc[['2.5%', '97.5%']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47033fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
