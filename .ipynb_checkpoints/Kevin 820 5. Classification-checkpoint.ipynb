{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d98e1f03",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "442cc05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# math and dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "\n",
    "\n",
    "# Pipeline and Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# jupyter notebook full-width display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fb0f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10M = pd.read_pickle('df_10M_clustered.pickle')\n",
    "X_all = pd.read_pickle('X_clustered.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6f0809",
   "metadata": {},
   "source": [
    "# Create Datasets for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abc5b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = 'in_B100'\n",
    "X_columns = [\n",
    "    'mode', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
    "    'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence'\n",
    "]\n",
    "genre_columns = [\n",
    "    'is_Adult_Standard', 'is_Rock', 'is_R&B', 'is_Country', 'is_Pop',\n",
    "    'is_Rap', 'is_Alternative', 'is_EDM', 'is_Metal'\n",
    "]\n",
    "cluster_columns = ['cluster', 'cluster2']\n",
    "other_columns = ['key', 'time_signature', 'genre', 'release_date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f646faa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict with all 'name': (y, X) key match pairs\n",
    "clusters = {}\n",
    "\n",
    "# entire predictive dataset\n",
    "clusters['All'] = (X_all[y_column], X_all[X_columns])\n",
    "\n",
    "# add genres\n",
    "for genre in genre_columns:\n",
    "    title = genre[3:]\n",
    "    clusters[title] = (X_all[X_all[genre]][y_column], X_all[X_all[genre]][X_columns])\n",
    "    \n",
    "# add clusters\n",
    "for n in sorted(X_all['cluster'].unique()):\n",
    "    title = genre[3:]\n",
    "    clusters['cluster1_' + str(n)] = (X_all[X_all['cluster'] == n][y_column], X_all[X_all['cluster'] == n][X_columns])\n",
    "    \n",
    "for n in sorted(X_all['cluster2'].unique()):\n",
    "    title = genre[3:]\n",
    "    clusters['cluster2_' + str(n)] = (X_all[X_all['cluster2'] == n][y_column], X_all[X_all['cluster2'] == n][X_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc779131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters['All'][1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dfd9f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(clusters.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64fa9b1",
   "metadata": {},
   "source": [
    "# Make Predictions Using Default ML Settings\n",
    "### COMPARE ALGORITHMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a35f6437",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_algorithms = [\n",
    "    LogisticRegression,\n",
    "    DecisionTreeClassifier,\n",
    "#     SVC,  # too slow, would take days/months\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "568f55a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are slow, even the simlest models\n",
    "# let's see how long they take with a small and medium dataset\n",
    "# then we can estimate how long each algorithm will take to run\n",
    "\n",
    "small = X_all.sample(10_000)\n",
    "y_small = small[y_column]\n",
    "X_small = small[X_columns]\n",
    "\n",
    "medium = X_all.sample(100_000)\n",
    "y_medium = medium[y_column]\n",
    "X_medium = medium[X_columns]\n",
    "\n",
    "large = X_all.sample(1_000_000)\n",
    "y_large = large[y_column]\n",
    "X_large = large[X_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd17d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_time(X, y, ml_n):\n",
    "    \"\"\"testing how long each algorithm takes\"\"\"\n",
    "    grid = GridSearchCV(\n",
    "        estimator=ML_algorithms[ml_n](),\n",
    "        param_grid={},\n",
    "        cv=5\n",
    "    )\n",
    "    %time grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75962f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Wall time: 131 ms\n",
      "DecisionTreeClassifier: Wall time: 228 ms\n",
      "RandomForestClassifier: Wall time: 3.69 s\n",
      "AdaBoostClassifier: Wall time: 2.33 s\n",
      "GradientBoostingClassifier: Wall time: 9.35 s\n"
     ]
    }
   ],
   "source": [
    "# small datasets\n",
    "for i in range(len(ML_algorithms)):\n",
    "    print(str(ML_algorithms[i])[:-2].split('.')[-1], end=': ')\n",
    "    ml_time(X_small, y_small, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef574ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Wall time: 981 ms\n",
      "DecisionTreeClassifier: Wall time: 3.74 s\n",
      "RandomForestClassifier: Wall time: 1min 2s\n",
      "AdaBoostClassifier: Wall time: 21.4 s\n",
      "GradientBoostingClassifier: Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "# medium datasets\n",
    "for i in range(len(ML_algorithms)):\n",
    "    print(str(ML_algorithms[i])[:-2].split('.')[-1], end=': ')\n",
    "    ml_time(X_medium, y_medium, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "071e7157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Wall time: 11.8 s\n",
      "DecisionTreeClassifier: Wall time: 1min 3s\n",
      "RandomForestClassifier: Wall time: 25min 24s\n",
      "AdaBoostClassifier: Wall time: 6min 8s\n",
      "GradientBoostingClassifier: Wall time: 21min 36s\n"
     ]
    }
   ],
   "source": [
    "# medium datasets\n",
    "for i in range(len(ML_algorithms)):\n",
    "    print(str(ML_algorithms[i])[:-2].split('.')[-1], end=': ')\n",
    "    ml_time(X_large, y_large, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e311ddd7",
   "metadata": {},
   "source": [
    "Time Complexity Notes:\n",
    "* Naive Bayes: O(n*d)\n",
    "* Logistic Regression: O(n*d)\n",
    "* Decision Tree: O(n*log(n))\n",
    "* SVC: O(n^2)\n",
    "    * Note from medium.com: \"if n is large, avoid using SVM.\"\n",
    "* Random Forest: O(n*log(n)*k)\n",
    "    * i assume other boosted trees are similar\n",
    "    \n",
    "    \n",
    "REFERENCE:\n",
    "https://medium.com/analytics-vidhya/time-complexity-of-ml-models-4ec39fad2770\n",
    "\n",
    "* based on the above times, it will take about this long to calculate without resampling:\n",
    "    * LogisticRegression: 1 minute\n",
    "    * DecisionTreeClassifier: Wall time: 15 minutes\n",
    "    * RandomForestClassifier: Wall time: 7 hours\n",
    "    * AdaBoostClassifier: Wall time: 58 minutes\n",
    "    * GradientBoostingClassifier: Wall time: 4 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2540126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2997ba56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a596b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5605e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# test logistic regression\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=ML_algorithms[0](),\n",
    "    param_grid={},\n",
    "    cv=5\n",
    ")\n",
    "grid.fit(X, y)\n",
    "\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f87e16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# almost 100% accurate by predicting no songs are hits\n",
    "# need to deal with unbalanced data, but for now, it looks like it's working\n",
    "1 - sum(y) / y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213366d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# check decision tree, different method, just the score\n",
    "cross_val_score(ML_algorithms[1](), X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45281a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1009b13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3118c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
