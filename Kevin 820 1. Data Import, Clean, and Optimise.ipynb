{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e33f60",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "355b4cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from ast import literal_eval\n",
    "import spotipy\n",
    "\n",
    "# jupyter notebook full-width display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:_.2f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c34bad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def find_all_tracks(track_title, artist_name):\n",
    "    \"\"\" returns list of lists ['id', 'song', 'artist'] \"\"\"\n",
    "    track_info = spotify.search(q='artist:' + artist_name + ' track:' + track_title, type='track')\n",
    "    \n",
    "    if track_info['tracks']['items'] == []:  # if track doesn't exist on Spotify\n",
    "        return 'MISSING'\n",
    "    else:\n",
    "        all_tracks = []\n",
    "        number_of_results = len(track_info['tracks']['items'])\n",
    "        \n",
    "        # check if there is a better match\n",
    "        for i in range(number_of_results):\n",
    "            track_id = track_info['tracks']['items'][i]['id']\n",
    "            artist_name = track_info['tracks']['items'][i]['artists'][0]['name']\n",
    "            song_name = track_info['tracks']['items'][i]['name']\n",
    "            all_tracks.append([track_id, song_name, artist_name])\n",
    "        \n",
    "        # if we made it through the loop without returning, note 'MISSING' and return the 0th id\n",
    "        return all_tracks\n",
    "\n",
    "\n",
    "def remove_punctuation(text_input):\n",
    "    text_input = str(text_input)  # avoid float errors in applymap()\n",
    "    text_input = re.sub(r'&', 'and', text_input)  # replaces & with 'and'\n",
    "    text_input = re.compile(r'[^a-zA-Z 0-9]').sub('', text_input)\n",
    "    return text_input.lower().strip()\n",
    "\n",
    "\n",
    "def clean_text(text_input):\n",
    "    text_input = str(text_input)  # avoid float errors in applymap()\n",
    "    text_input = text_input.strip().lower()\n",
    "    text_input = re.sub(r'&', 'and', text_input)  # replaces & with 'and'\n",
    "    text_input = re.sub(r'and.+', '', text_input)  # removes text after the 'and'\n",
    "    text_input = re.compile(r'the').sub('', text_input)  # remove all 'the' (maybe just need the 1st word?)\n",
    "    text_input = re.sub(r',.+', '', text_input)  # removes all misc artists, after comma \n",
    "    text_input = re.sub(r'(?:feat).+', '', text_input)  # removes all misc artists, after 'feat' \n",
    "    text_input = re.sub(r'\\(.+', '', text_input)  # removes text after first bracket\n",
    "    text_input = re.sub(r'\\-.+', '', text_input)  # removes text after first dash\n",
    "    text_input = re.compile(r'[^a-zA-Z 0-9]').sub('', text_input)  # remove punctuation\n",
    "    text_input = re.sub(' +', ' ', text_input)  # remove multiple spaces\n",
    "    return text_input.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e7a18f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##### SQL 8+M\n",
    "\"\"\"\n",
    "    SELECT * FROM tracks\n",
    "    JOIN r_track_artist ON tracks.id = r_track_artist.track_id\n",
    "    JOIN artists ON r_track_artist.artist_id = artists.id\n",
    "    JOIN audio_features ON audio_features.id = tracks.audio_feature_id\n",
    "\"\"\"\n",
    "dtypes = {\n",
    "    'key': 'Int16', 'mode': 'Int16', 'time_signature': 'Int16', 'tempo': 'float32', \n",
    "    'acousticness': 'float32', 'danceability': 'float32', 'duration_ms': 'Int64',  \n",
    "    'energy': 'float32', 'instrumentalness': 'float32', 'liveness': 'float32', \n",
    "    'loudness': 'float32', 'speechiness': 'float32', 'valence': 'float32'\n",
    "} \n",
    "df_SQL = pd.read_csv('all_audio_features_sql.csv', dtype=dtypes)\n",
    "\n",
    "# import genre and release date data\n",
    "\"\"\"\n",
    "    SELECT tracks.id AS id, release_date, genre_id as genre FROM tracks\n",
    "    JOIN r_albums_tracks ON tracks.id = r_albums_tracks.track_id\n",
    "    JOIN albums ON r_albums_tracks.album_id = albums.id\n",
    "    JOIN r_track_artist ON tracks.id = r_track_artist.track_id\n",
    "    JOIN r_artist_genre ON r_track_artist.artist_id = r_artist_genre.artist_id\n",
    "\"\"\"\n",
    "df_genre = pd.read_csv('SQL_track_release_date_and_genre.csv')\n",
    "df_genre['genre_count'] = df_genre.groupby('genre')['genre'].transform('count')  # add a count column\n",
    "df_TEMP = df_genre.copy()  # create temp df, sort by most common genre, merge with SQL data\n",
    "df_TEMP = df_TEMP.drop_duplicates(['id']).sort_values('genre_count', ascending=False).drop_duplicates(['id']).reset_index(drop=True)\n",
    "df_SQL = df_SQL.merge(df_TEMP, on='id')\n",
    "\n",
    "# now format and save df_genre\n",
    "# NOTE: slightly different then old method, counts multiple instances of a song with multiple artists (for each artist)\n",
    "df_genre = df_genre[['genre', 'genre_count']].sort_values('genre_count', ascending=False).drop_duplicates(['genre']).reset_index(drop=True)\n",
    "\n",
    "# formatting\n",
    "df_SQL['release_date'] = pd.to_datetime(df_SQL['release_date'], unit='ms', origin='unix', errors = 'coerce')\n",
    "df_SQL = df_SQL.rename({\n",
    "    'name:1': 'artist',\n",
    "    'name': 'song',\n",
    "    'duration:1': 'duration_ms'\n",
    "}, axis=1)[[\n",
    "    'id', 'song', 'artist', 'genre', 'release_date',\n",
    "    'acousticness', 'danceability', 'duration_ms', \n",
    "    'energy', 'instrumentalness', 'key', 'liveness', 'loudness', \n",
    "    'mode', 'speechiness', 'tempo','time_signature', 'valence'\n",
    "]].reset_index(drop=True)\n",
    "\n",
    "# NOTE: DO NOT DROP DUPLICATES YET, NEED FOR LOOKUP WITH B100\n",
    "\n",
    "# save files as pickle\n",
    "df_genre.to_pickle('df_genre.pickle')\n",
    "df_SQL.to_pickle('df_SQL.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea52148d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##### Spotify 1.2M+ Songs\n",
    "url_1M_songs = r'D:\\RYERSON\\820\\Datasets\\Spotify 1.2M+ Songs\\tracks_features.csv'\n",
    "df_1M_songs = pd.read_csv(url_1M_songs)\n",
    "\n",
    "# doesn't have genre (would take 1000+ to get using API, will stay NA)\n",
    "df_1M_songs['genre'] = pd.NA\n",
    "\n",
    "# explode artists\n",
    "df_1M_songs['artists'] = df_1M_songs['artists'].apply(literal_eval) #convert to list type\n",
    "df_1M_songs = df_1M_songs.explode('artists', ignore_index=True)\n",
    "\n",
    "# formatting\n",
    "df_1M_songs['release_date'] = pd.to_datetime(df_1M_songs['release_date'], errors = 'coerce')\n",
    "df_1M_songs = df_1M_songs.rename({\n",
    "    'name': 'song',\n",
    "    'artists': 'artist'\n",
    "}, axis=1)[[\n",
    "    'id', 'song', 'artist', 'genre', 'release_date',\n",
    "    'acousticness', 'danceability', 'duration_ms', \n",
    "    'energy', 'instrumentalness', 'key', 'liveness', 'loudness', \n",
    "    'mode', 'speechiness', 'tempo','time_signature', 'valence'\n",
    "]].reset_index(drop=True)\n",
    "\n",
    "# NOTE: DO NOT DROP DUPLICATES YET, NEED FOR LOOKUP WITH B100\n",
    "\n",
    "# save files as pickle\n",
    "df_1M_songs.to_pickle('df_1M_songs.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5431788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 806 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##### Billboard Top 100 Historical Data\n",
    "url_B100 = r'D:\\RYERSON\\820\\Datasets\\Billboard The Hot 100 Songs\\charts.csv'\n",
    "dtypes_timeseries = {\n",
    "    'rank': 'Int16', 'last-week': 'Int16', 'peak-rank': 'Int16', 'weeks-on-board': 'Int16'\n",
    "}\n",
    "df_B100 = pd.read_csv(url_B100, dtype=dtypes_timeseries)\n",
    "df_B100['date'] = pd.to_datetime(df_B100['date'])\n",
    "\n",
    "# Unique Songs from The Billboard 100 Dataset\n",
    "df_B100_songs = df_B100[['song', 'artist']].drop_duplicates().sort_values(['artist', 'song']).reset_index(drop=True)\n",
    "\n",
    "# save files as pickle\n",
    "df_B100.to_pickle('df_B100.pickle')\n",
    "df_B100_songs.to_pickle('df_B100_songs.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9303d6e",
   "metadata": {},
   "source": [
    "# Merge into Working Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8f7334b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# reload data\n",
    "df_genre = pd.read_pickle('df_genre.pickle')\n",
    "df_SQL = pd.read_pickle('df_SQL.pickle')\n",
    "df_1M_songs = pd.read_pickle('df_1M_songs.pickle')\n",
    "df_B100 = pd.read_pickle('df_B100.pickle')\n",
    "df_B100_songs = pd.read_pickle('df_B100_songs.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f5f92e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# merge SQL and CSV AF to get df_10M\n",
    "ids_SQL = set(df_SQL['id'].to_list())\n",
    "df_TEMP = df_1M_songs.copy()  \n",
    "df_TEMP = df_TEMP[~df_TEMP.id.isin(ids_SQL)]  # drop songs already in SQL before merge\n",
    "df_10M = pd.concat([df_SQL, df_TEMP]).reset_index(drop=True)\n",
    "\n",
    "# drop duplicate song/artist (exact matches only)\n",
    "df_10M = df_10M.sort_values('release_date').drop_duplicates(['song', 'artist']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b518ad6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# add approx song and artist columns for approx match\n",
    "df_10M['approx_song'] = df_10M[['song']].applymap(clean_text)\n",
    "df_10M['approx_artist'] = df_10M[['artist']].applymap(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6fd3cb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 417 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# add approx song and artist columns to B100 for merging\n",
    "df_B100_songs['approx_song'] = df_B100_songs[['song']].applymap(clean_text)\n",
    "df_B100_songs['approx_artist'] = df_B100_songs[['artist']].applymap(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ca58f055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# merge B100 with 10M to get AF, where available\n",
    "df_B100_songs = df_B100_songs.merge(df_10M, on=['approx_song', 'approx_artist'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "18a729c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 295 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# drop blank artist+song\n",
    "df_B100_songs = df_B100_songs[~((df_B100_songs.approx_song == '') & (df_B100_songs.approx_artist == ''))]\n",
    "\n",
    "# sort by exact matches, then release_date\n",
    "df_B100_songs['EXACT_MATCH'] = (df_B100_songs['song_x'] == df_B100_songs['song_y'])*1 + (df_B100_songs['artist_x'] == df_B100_songs['artist_y'])*1\n",
    "\n",
    "# drop duplicates (keep exact matches, or oldest song)\n",
    "df_B100_songs = (\n",
    "    df_B100_songs.sort_values('release_date')\n",
    "    .sort_values('EXACT_MATCH', ascending=False)\n",
    "    .dropna(subset=['song_x', 'artist_x'], axis='rows')\n",
    "    .drop_duplicates(['song_x', 'artist_x'])\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bb1ade61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat dataframe\n",
    "df_B100_songs = df_B100_songs.rename({'song_x': 'song', 'artist_x': 'artist'}, axis=1)[[\n",
    "    'id', 'song', 'artist', 'genre', 'release_date',\n",
    "    'acousticness', 'danceability', 'duration_ms', \n",
    "    'energy', 'instrumentalness', 'key', 'liveness', 'loudness', \n",
    "    'mode', 'speechiness', 'tempo','time_signature', 'valence'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "be28510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save intermediate file\n",
    "df_B100_songs.to_pickle('df_B100_songs_PRE_API.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8db61f",
   "metadata": {},
   "source": [
    "# Spotify API - GET missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "96046c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6902"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload data if required\n",
    "df_B100_songs = pd.read_pickle('df_B100_songs_PRE_API.pickle')\n",
    "\n",
    "# number missing ids\n",
    "df_B100_songs[df_B100_songs.id.isnull()].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6038d33",
   "metadata": {},
   "source": [
    "##### get a temporary authorization token from: https://developer.spotify.com/console/get-search-item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "20b5353e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter token: BQDryQ2lIpWoqbIaZp36XPO_KFxlYmh1uMBwjHf7xlASedyb403Adg_Hiboaesop0vHhDZgq887jfVNUWcODt7YublktB1naCo78fr_Bxu54LJZYRiy_TA4ejEFnAvrFa2uGRfOOxJcwFBzibemYMjjITPhuZ9Po-dSeHjLGhq58\n"
     ]
    }
   ],
   "source": [
    "# input the temporary token\n",
    "TEMP_TOKEN = input('Enter token: ')\n",
    "\n",
    "# create a spotify object\n",
    "spotify = spotipy.Spotify(auth=TEMP_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "4642eb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "100 200 300 400 500 600 700 800 900 1000 \n",
      "1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 \n",
      "2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 \n",
      "3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 \n",
      "4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 \n",
      "5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 \n",
      "6100 6200 6300 6400 6500 6600 6700 6800 6900 7000 \n",
      "7100 7200 7300 7400 7500 7600 7700 7800 7900 8000 \n",
      "8100 8200 8300 8400 8500 8600 8700 8800 8900 9000 \n",
      "9100 9200 9300 9400 9500 9600 9700 9800 9900 10000 \n",
      "10100 10200 10300 10400 10500 10600 10700 10800 10900 11000 \n",
      "11100 11200 11300 11400 11500 11600 11700 11800 11900 12000 \n",
      "12100 12200 12300 12400 12500 12600 12700 12800 12900 13000 \n",
      "13100 13200 13300 13400 13500 13600 13700 13800 13900 14000 \n",
      "14100 14200 14300 14400 14500 14600 14700 14800 14900 15000 \n",
      "15100 15200 15300 15400 15500 15600 15700 15800 15900 16000 \n",
      "16100 16200 16300 16400 16500 16600 16700 16800 16900 17000 \n",
      "17100 17200 17300 17400 17500 17600 17700 17800 17900 18000 \n",
      "18100 18200 18300 18400 18500 18600 18700 18800 18900 19000 \n",
      "19100 19200 19300 19400 19500 19600 19700 19800 19900 20000 \n",
      "20100 20200 20300 20400 20500 20600 20700 20800 20900 21000 \n",
      "21100 21200 21300 21400 21500 21600 21700 21800 21900 22000 \n",
      "22100 22200 22300 22400 22500 22600 22700 22800 22900 23000 \n",
      "23100 23200 23300 23400 23500 23600 23700 23800 23900 24000 \n",
      "24100 24200 24300 24400 24500 24600 24700 24800 24900 25000 \n",
      "25100 25200 25300 25400 25500 25600 25700 25800 25900 26000 \n",
      "26100 26200 26300 26400 26500 26600 26700 26800 26900 27000 \n",
      "27100 27200 27300 27400 27500 27600 27700 27800 27900 28000 \n",
      "28100 28200 28300 28400 28500 28600 28700 28800 28900 29000 \n",
      "29100 29200 29300 29400 29500 29600 Wall time: 21min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# loop to get id where missing\n",
    "\n",
    "counter = 0\n",
    "id_from_API = set()\n",
    "\n",
    "for i, row in df_B100_songs.iterrows():\n",
    "    \n",
    "    if i < 0:  # where we timed out last time\n",
    "        continue\n",
    "        \n",
    "    if counter % 100 == 0:\n",
    "        print(counter, end=' ')\n",
    "    if counter % 1000 == 0:\n",
    "        print()\n",
    "        df_B100_songs.to_pickle('df_B100_songs_AF_TEMP.pickle') # save temp file\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    if not df_B100_songs.iloc[[i]].isnull()['id'].values[0]:\n",
    "        continue    \n",
    "    \n",
    "    # these are the actual song and artist from the Billboard Hot 100\n",
    "    song = df_B100_songs.loc[df_B100_songs.index[i], 'song']\n",
    "    artist = df_B100_songs.loc[df_B100_songs.index[i], 'artist']\n",
    "    \n",
    "    # get all track info from Spotify API matching 'song' and 'artist'\n",
    "    all_track_info = find_all_tracks(song, artist)\n",
    "    \n",
    "    # restart loop if there are no results\n",
    "    if all_track_info == 'MISSING':\n",
    "        continue\n",
    "    \n",
    "    # first subloop - check for direct matched\n",
    "    is_exact_match = False\n",
    "    id_found = False\n",
    "    \n",
    "    for track_info in all_track_info:\n",
    "        temp_id = track_info[0]\n",
    "        temp_song = track_info[1]\n",
    "        temp_artist = track_info[2]\n",
    "        \n",
    "        # if there is an exact text match\n",
    "        is_exact_match = remove_punctuation(temp_song) == remove_punctuation(song) and \\\n",
    "                         remove_punctuation(temp_artist) == remove_punctuation(artist)\n",
    "        \n",
    "        # continue subloop\n",
    "        if is_exact_match:\n",
    "            df_B100_songs.loc[df_B100_songs.index[i], 'id'] = temp_id\n",
    "            id_from_API.add(temp_id)\n",
    "            id_found = True\n",
    "            break\n",
    "    \n",
    "    # if we found the id, go to the next row item, else check for approx matches\n",
    "    if not id_found:\n",
    "      \n",
    "        is_probable_match = False    \n",
    "            \n",
    "        # second subloop - check for indirect matches (shouldn't run if direct match occurs)\n",
    "        for track_info in all_track_info:\n",
    "            temp_id = track_info[0]\n",
    "            temp_song = track_info[1]\n",
    "            temp_artist = track_info[2]\n",
    "\n",
    "            # if there is a probable text match\n",
    "            is_probable_match = clean_text(temp_song) == clean_text(song) and \\\n",
    "                                clean_text(temp_artist) == clean_text(artist)\n",
    "\n",
    "            if is_probable_match:\n",
    "                df_B100_songs.loc[df_B100_songs.index[i], 'id'] = temp_id\n",
    "                id_from_API.add(temp_id)\n",
    "                break\n",
    "            \n",
    "\n",
    "df_B100_songs.to_pickle('df_B100_songs_AF_COMPLETE.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "637da389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2762"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new ids\n",
    "len(id_from_API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "2ce07be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4140"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# still missing ids\n",
    "df_B100_songs[df_B100_songs.id.isnull()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "5d516be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2762"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of songs in new ids (should match len(id_from_API))\n",
    "df_B100_songs[df_B100_songs.id.isin(id_from_API)].id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "14745a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2762"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberz = 0\n",
    "for i, row in df_B100_songs.iterrows():\n",
    "    track_id = df_B100_songs['id'].iloc[i]\n",
    "    if track_id not in id_from_API:\n",
    "        continue\n",
    "    numberz += 1\n",
    "    \n",
    "numberz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "2770c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ids to pickled dataframe\n",
    "pd.DataFrame(id_from_API).to_pickle('id_from_API.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b961fff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497da06f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef8a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b5e471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "de6b0b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "100 200 300 400 500 600 700 800 900 1000 \n",
      "1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 \n",
      "2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 \n",
      "3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 \n",
      "4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 \n",
      "5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 \n",
      "6100 6200 6300 6400 6500 6600 6700 6800 6900 7000 \n",
      "7100 7200 7300 7400 7500 7600 7700 7800 7900 8000 \n",
      "8100 8200 8300 8400 8500 8600 8700 8800 8900 9000 \n",
      "9100 9200 9300 9400 9500 9600 9700 9800 9900 10000 \n",
      "10100 10200 10300 10400 10500 10600 10700 10800 10900 11000 \n",
      "11100 11200 11300 11400 11500 11600 11700 11800 11900 12000 \n",
      "12100 12200 12300 12400 12500 12600 12700 12800 12900 13000 \n",
      "13100 13200 13300 13400 13500 13600 13700 13800 13900 14000 \n",
      "14100 14200 14300 14400 14500 14600 14700 14800 14900 15000 \n",
      "15100 15200 15300 15400 15500 15600 15700 15800 15900 16000 \n",
      "16100 16200 16300 16400 16500 16600 16700 16800 16900 17000 \n",
      "17100 17200 17300 17400 17500 17600 17700 17800 17900 18000 \n",
      "18100 18200 18300 18400 18500 18600 18700 18800 18900 19000 \n",
      "19100 19200 19300 19400 19500 19600 19700 19800 19900 20000 \n",
      "20100 20200 20300 20400 20500 20600 20700 20800 20900 21000 \n",
      "21100 21200 21300 21400 21500 21600 21700 21800 21900 22000 \n",
      "22100 22200 22300 22400 22500 22600 22700 22800 22900 23000 \n",
      "23100 23200 23300 23400 23500 23600 23700 23800 23900 24000 \n",
      "24100 24200 24300 24400 24500 24600 24700 24800 24900 25000 \n",
      "25100 25200 25300 25400 25500 25600 25700 25800 25900 26000 \n",
      "26100 26200 26300 26400 26500 26600 26700 26800 26900 27000 \n",
      "27100 27200 27300 27400 27500 27600 27700 27800 27900 28000 \n",
      "28100 28200 28300 28400 28500 28600 28700 28800 28900 29000 \n",
      "29100 29200 29300 29400 29500 29600 Wall time: 17min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# loop to get genre, release_date, and audio features\n",
    "\n",
    "# ordered list of genres for choosing the best genre\n",
    "list_of_ordered_genres = list(df_genre.genre)\n",
    "\n",
    "how_many_passes = 0  # just for QA / error checking\n",
    "counter = 0\n",
    "\n",
    "for i, row in df_B100_songs.iterrows():\n",
    "    # not sure if this is too many GETs...\n",
    "    \n",
    "    if i < 0:  # where we timed out last time\n",
    "        continue\n",
    "        \n",
    "    if counter % 100 == 0:\n",
    "        print(counter, end=' ')\n",
    "    if counter % 1000 == 0:\n",
    "        print()\n",
    "        df_B100_songs.to_pickle('df_B100_songs_AF2_TEMP.pickle') # save temp file\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    track_id = df_B100_songs['id'].iloc[i]\n",
    "    \n",
    "    # if we don't have a new ID, skip the entry (it's not on Spotify)\n",
    "    if track_id not in id_from_API:\n",
    "        continue\n",
    "    \n",
    "    # Get Audio Features - 1st GET request\n",
    "    list_of_features = [\n",
    "        'acousticness', 'danceability', 'duration_ms', 'energy',\n",
    "        'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\n",
    "        'speechiness', 'tempo', 'time_signature', 'valence'\n",
    "    ]\n",
    "    \n",
    "    temp_audio_features = spotify.audio_features(track_id)\n",
    "    for key in list_of_features:\n",
    "        df_B100_songs.loc[i, key] = temp_audio_features[0][key]\n",
    "\n",
    "    # Get Release Date - 2nd GET request\n",
    "    track_info = spotify.track(track_id)\n",
    "    df_B100_songs.loc[i, 'release_date'] = track_info['album']['release_date']\n",
    "\n",
    "    # Get Release Date Genre - 3rd GET request\n",
    "    artist_id = track_info['artists'][0]['id']\n",
    "    artist_info = spotify.artist(artist_id)\n",
    "    list_of_artist_genres = artist_info['genres']\n",
    "\n",
    "    try:\n",
    "        most_common_genre = list_of_artist_genres[0] # default to first genre\n",
    "        if len(list_of_artist_genres) == 1:\n",
    "            pass\n",
    "        else:\n",
    "            for genre in list_of_ordered_genres:\n",
    "                if genre in list_of_artist_genres:\n",
    "                    most_common_genre = genre\n",
    "                    break\n",
    "        df_B100_songs.loc[i, 'genre'] = most_common_genre\n",
    "    except:\n",
    "        how_many_passes += 1\n",
    "        pass  # didn't have any genres (or other error), move on\n",
    "\n",
    "    \n",
    "df_B100_songs.to_pickle('df_B100_songs_AF2_COMPLETE.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "a381fe76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>release_date</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21297</th>\n",
       "      <td>10h6Y5HHIFM9KhNSxGi6e3</td>\n",
       "      <td>For He's A Jolly Good Fellow</td>\n",
       "      <td>Bobby Vinton</td>\n",
       "      <td>adult standards</td>\n",
       "      <td>1967-04-24</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.45</td>\n",
       "      <td>163_013.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.47</td>\n",
       "      <td>-11.51</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>93.93</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21298</th>\n",
       "      <td>4e4vO6bp5nSdP9G79O3qS6</td>\n",
       "      <td>Miss Me Baby</td>\n",
       "      <td>Chris Cagle</td>\n",
       "      <td>country</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.53</td>\n",
       "      <td>234_653.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-5.79</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>147.87</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21299</th>\n",
       "      <td>6mYAXUpuLUgDmWd5JhZnXc</td>\n",
       "      <td>Together Again</td>\n",
       "      <td>Bobby Sherman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1972-11-18</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.48</td>\n",
       "      <td>140_864.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-10.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>140.23</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21303</th>\n",
       "      <td>0dRcpXKSo9fzJJjR9siMil</td>\n",
       "      <td>She's My Girl</td>\n",
       "      <td>Bobby Shafto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.42</td>\n",
       "      <td>121_730.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-5.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.11</td>\n",
       "      <td>146.78</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21304</th>\n",
       "      <td>46CuB9nNPwY6RyvAoVRtjD</td>\n",
       "      <td>Love Takes A Long Time Growing</td>\n",
       "      <td>Deon Jackson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1966-07-31</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.59</td>\n",
       "      <td>144_693.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-18.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>133.63</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28211</th>\n",
       "      <td>0fmjCC6ItD4vixqwLTNGfg</td>\n",
       "      <td>Wild, Wild West</td>\n",
       "      <td>Kool Moe Dee</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>1987-12-08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>280_840.00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-9.09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>185.88</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28214</th>\n",
       "      <td>5aDgXViz32oC08vyf1vIwV</td>\n",
       "      <td>Africanism/Gimme Some Lovin'</td>\n",
       "      <td>Kongas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-12-15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.74</td>\n",
       "      <td>420_733.00</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-8.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>124.97</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28219</th>\n",
       "      <td>5kO43qSJE70fpFxOe0azxc</td>\n",
       "      <td>Summer's Comin'</td>\n",
       "      <td>Kirby St. Romain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-01-29</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.60</td>\n",
       "      <td>119_320.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-4.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>141.06</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28221</th>\n",
       "      <td>47T4ZY4D3V8ZlMn4k8ZeC0</td>\n",
       "      <td>Black Leather</td>\n",
       "      <td>Kings Of The Sun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1988-01-01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.52</td>\n",
       "      <td>235_240.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-9.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>121.74</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28225</th>\n",
       "      <td>7LDez5sTopv9xLQykv1X03</td>\n",
       "      <td>Hello World</td>\n",
       "      <td>Lady Antebellum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-08-15</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.43</td>\n",
       "      <td>326_133.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-6.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>111.06</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2762 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id                            song  \\\n",
       "21297  10h6Y5HHIFM9KhNSxGi6e3    For He's A Jolly Good Fellow   \n",
       "21298  4e4vO6bp5nSdP9G79O3qS6                    Miss Me Baby   \n",
       "21299  6mYAXUpuLUgDmWd5JhZnXc                  Together Again   \n",
       "21303  0dRcpXKSo9fzJJjR9siMil                   She's My Girl   \n",
       "21304  46CuB9nNPwY6RyvAoVRtjD  Love Takes A Long Time Growing   \n",
       "...                       ...                             ...   \n",
       "28211  0fmjCC6ItD4vixqwLTNGfg                 Wild, Wild West   \n",
       "28214  5aDgXViz32oC08vyf1vIwV    Africanism/Gimme Some Lovin'   \n",
       "28219  5kO43qSJE70fpFxOe0azxc                 Summer's Comin'   \n",
       "28221  47T4ZY4D3V8ZlMn4k8ZeC0                   Black Leather   \n",
       "28225  7LDez5sTopv9xLQykv1X03                     Hello World   \n",
       "\n",
       "                 artist            genre release_date  acousticness  \\\n",
       "21297      Bobby Vinton  adult standards   1967-04-24          0.58   \n",
       "21298       Chris Cagle          country   2005-01-01          0.18   \n",
       "21299     Bobby Sherman              NaN   1972-11-18          0.60   \n",
       "21303      Bobby Shafto              NaN   2017-01-20          0.27   \n",
       "21304      Deon Jackson              NaN   1966-07-31          0.78   \n",
       "...                 ...              ...          ...           ...   \n",
       "28211      Kool Moe Dee          hip hop   1987-12-08          0.00   \n",
       "28214            Kongas              NaN   2014-12-15          0.01   \n",
       "28219  Kirby St. Romain              NaN   2013-01-29          0.67   \n",
       "28221  Kings Of The Sun              NaN   1988-01-01          0.03   \n",
       "28225   Lady Antebellum              NaN   2021-08-15          0.06   \n",
       "\n",
       "       danceability  duration_ms  energy  instrumentalness  key  liveness  \\\n",
       "21297          0.45   163_013.00    0.34              0.00    7      0.47   \n",
       "21298          0.53   234_653.00    0.57              0.00    1      0.08   \n",
       "21299          0.48   140_864.00    0.53              0.00    4      0.36   \n",
       "21303          0.42   121_730.00    0.88              0.00    9      0.10   \n",
       "21304          0.59   144_693.00    0.22              0.00    9      0.09   \n",
       "...             ...          ...     ...               ...  ...       ...   \n",
       "28211          0.67   280_840.00    0.77              0.00    1      0.18   \n",
       "28214          0.74   420_733.00    0.81              0.24    7      0.06   \n",
       "28219          0.60   119_320.00    0.84              0.00    5      0.18   \n",
       "28221          0.52   235_240.00    0.75              0.00    2      0.07   \n",
       "28225          0.43   326_133.00    0.52              0.00    8      0.09   \n",
       "\n",
       "       loudness  mode  speechiness  tempo  time_signature  valence  \n",
       "21297    -11.51     1         0.04  93.93            3.00     0.45  \n",
       "21298     -5.79     1         0.03 147.87            4.00     0.36  \n",
       "21299    -10.03     1         0.04 140.23            4.00     0.44  \n",
       "21303     -5.26     1         0.11 146.78            4.00     0.85  \n",
       "21304    -18.60     0         0.04 133.63            4.00     0.64  \n",
       "...         ...   ...          ...    ...             ...      ...  \n",
       "28211     -9.09     1         0.06 185.88            4.00     0.94  \n",
       "28214     -8.75     1         0.05 124.97            4.00     0.50  \n",
       "28219     -4.69     1         0.03 141.06            4.00     0.96  \n",
       "28221     -9.54     1         0.06 121.74            4.00     0.49  \n",
       "28225     -6.90     1         0.03 111.06            4.00     0.15  \n",
       "\n",
       "[2762 rows x 18 columns]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all there, not all genre (as expected)\n",
    "df_B100_songs[df_B100_songs.id.isin(id_from_API)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "3ac7dbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no audio features missing\n",
    "df_B100_songs[df_B100_songs.id.isin(id_from_API)].key.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "d15acead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29677, 25537, 23184)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total, \n",
    "(\n",
    "    df_B100_songs.shape[0], \n",
    "    df_B100_songs.shape[0] - df_B100_songs.key.isnull().sum(), \n",
    "    df_B100_songs.shape[0] - df_B100_songs.genre.isnull().sum()\n",
    ")\n",
    "# all, with AF, with genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "8513aed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29677, 25537, 23184)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that saved data is good\n",
    "(\n",
    "    pd.read_pickle('df_B100_songs_AF2_COMPLETE.pickle').shape[0], \n",
    "    pd.read_pickle('df_B100_songs_AF2_COMPLETE.pickle').shape[0] - pd.read_pickle('df_B100_songs_AF2_COMPLETE.pickle').key.isnull().sum(), \n",
    "    pd.read_pickle('df_B100_songs_AF2_COMPLETE.pickle').shape[0] - pd.read_pickle('df_B100_songs_AF2_COMPLETE.pickle').genre.isnull().sum()\n",
    ")\n",
    "# yep!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a23081",
   "metadata": {},
   "source": [
    "# Merge and Save Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53146aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reimport data\n",
    "df_B100_songs = pd.read_pickle('df_B100_songs_AF2_COMPLETE.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d1b973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ebdf2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff2a895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ee140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3f9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
