{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f8e5d5a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2303f477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from ast import literal_eval\n",
    "import spotipy\n",
    "\n",
    "# jupyter notebook full-width display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:_.2f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41195d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def find_all_tracks(track_title, artist_name):\n",
    "    \"\"\" returns list of lists ['id', 'song', 'artist'] \"\"\"\n",
    "    track_info = spotify.search(q='artist:' + artist_name + ' track:' + track_title, type='track')\n",
    "    \n",
    "    if track_info['tracks']['items'] == []:  # if track doesn't exist on Spotify\n",
    "        return 'MISSING'\n",
    "    else:\n",
    "        all_tracks = []\n",
    "        number_of_results = len(track_info['tracks']['items'])\n",
    "        \n",
    "        # check if there is a better match\n",
    "        for i in range(number_of_results):\n",
    "            track_id = track_info['tracks']['items'][i]['id']\n",
    "            artist_name = track_info['tracks']['items'][i]['artists'][0]['name']\n",
    "            song_name = track_info['tracks']['items'][i]['name']\n",
    "            all_tracks.append([track_id, song_name, artist_name])\n",
    "        \n",
    "        # if we made it through the loop without returning, note 'MISSING' and return the 0th id\n",
    "        return all_tracks\n",
    "\n",
    "\n",
    "def remove_punctuation(text_input):\n",
    "    text_input = str(text_input)  # avoid float errors in applymap()\n",
    "    text_input = re.sub(r'&', 'and', text_input)  # replaces & with 'and'\n",
    "    text_input = re.compile(r'[^a-zA-Z 0-9]').sub('', text_input)\n",
    "    return text_input.lower().strip()\n",
    "\n",
    "\n",
    "def clean_text(text_input):\n",
    "    text_input = str(text_input)  # avoid float errors in applymap()\n",
    "    text_input = text_input.strip().lower()\n",
    "    text_input = re.sub(r'&', 'and', text_input)  # replaces & with 'and'\n",
    "    text_input = re.sub(r'and.+', '', text_input)  # removes text after the 'and'\n",
    "    text_input = re.compile(r'the').sub('', text_input)  # remove all 'the' (maybe just need the 1st word?)\n",
    "    text_input = re.sub(r',.+', '', text_input)  # removes all misc artists, after comma \n",
    "    text_input = re.sub(r'(?:feat).+', '', text_input)  # removes all misc artists, after 'feat' \n",
    "    text_input = re.sub(r'\\(.+', '', text_input)  # removes text after first bracket\n",
    "    text_input = re.sub(r'\\-.+', '', text_input)  # removes text after first dash\n",
    "    text_input = re.compile(r'[^a-zA-Z 0-9]').sub('', text_input)  # remove punctuation\n",
    "    text_input = re.sub(' +', ' ', text_input)  # remove multiple spaces\n",
    "    return text_input.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5665f3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##### SQL 8+M\n",
    "\"\"\"\n",
    "    SELECT * FROM tracks\n",
    "    JOIN r_track_artist ON tracks.id = r_track_artist.track_id\n",
    "    JOIN artists ON r_track_artist.artist_id = artists.id\n",
    "    JOIN audio_features ON audio_features.id = tracks.audio_feature_id\n",
    "\"\"\"\n",
    "dtypes = {\n",
    "    'key': 'Int16', 'mode': 'Int16', 'time_signature': 'Int16', 'tempo': 'float32', \n",
    "    'acousticness': 'float32', 'danceability': 'float32', 'duration_ms': 'Int64',  \n",
    "    'energy': 'float32', 'instrumentalness': 'float32', 'liveness': 'float32', \n",
    "    'loudness': 'float32', 'speechiness': 'float32', 'valence': 'float32'\n",
    "} \n",
    "df_SQL = pd.read_csv('all_audio_features_sql.csv', dtype=dtypes)\n",
    "\n",
    "# import genre and release date data\n",
    "\"\"\"\n",
    "    SELECT tracks.id AS id, release_date, genre_id as genre FROM tracks\n",
    "    JOIN r_albums_tracks ON tracks.id = r_albums_tracks.track_id\n",
    "    JOIN albums ON r_albums_tracks.album_id = albums.id\n",
    "    JOIN r_track_artist ON tracks.id = r_track_artist.track_id\n",
    "    JOIN r_artist_genre ON r_track_artist.artist_id = r_artist_genre.artist_id\n",
    "\"\"\"\n",
    "df_genre = pd.read_csv('SQL_track_release_date_and_genre.csv')\n",
    "df_genre['genre_count'] = df_genre.groupby('genre')['genre'].transform('count')  # add a count column\n",
    "df_TEMP = df_genre.copy()  # create temp df, sort by most common genre, merge with SQL data\n",
    "df_TEMP = df_TEMP.drop_duplicates(['id']).sort_values('genre_count', ascending=False).drop_duplicates(['id']).reset_index(drop=True)\n",
    "df_SQL = df_SQL.merge(df_TEMP, on='id')\n",
    "\n",
    "# now format and save df_genre\n",
    "# NOTE: slightly different then old method, counts multiple instances of a song with multiple artists (for each artist)\n",
    "df_genre = df_genre[['genre', 'genre_count']].sort_values('genre_count', ascending=False).drop_duplicates(['genre']).reset_index(drop=True)\n",
    "\n",
    "# formatting\n",
    "df_SQL['release_date'] = pd.to_datetime(df_SQL['release_date'], unit='ms', origin='unix', errors = 'coerce')\n",
    "df_SQL = df_SQL.rename({\n",
    "    'name:1': 'artist',\n",
    "    'name': 'song',\n",
    "    'duration:1': 'duration_ms'\n",
    "}, axis=1)[[\n",
    "    'id', 'song', 'artist', 'genre', 'release_date',\n",
    "    'acousticness', 'danceability', 'duration_ms', \n",
    "    'energy', 'instrumentalness', 'key', 'liveness', 'loudness', \n",
    "    'mode', 'speechiness', 'tempo','time_signature', 'valence'\n",
    "]].reset_index(drop=True)\n",
    "\n",
    "# NOTE: DO NOT DROP DUPLICATES YET, NEED FOR LOOKUP WITH B100\n",
    "\n",
    "# save files as pickle\n",
    "df_genre.to_pickle('df_genre.pickle')\n",
    "df_SQL.to_pickle('df_SQL.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7a484f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##### Spotify 1.2M+ Songs\n",
    "url_1M_songs = r'D:\\RYERSON\\820\\Datasets\\Spotify 1.2M+ Songs\\tracks_features.csv'\n",
    "df_1M_songs = pd.read_csv(url_1M_songs)\n",
    "\n",
    "# doesn't have genre (would take 1000+ to get using API, will stay NA)\n",
    "df_1M_songs['genre'] = pd.NA\n",
    "\n",
    "# explode artists\n",
    "df_1M_songs['artists'] = df_1M_songs['artists'].apply(literal_eval) #convert to list type\n",
    "df_1M_songs = df_1M_songs.explode('artists', ignore_index=True)\n",
    "\n",
    "# formatting\n",
    "df_1M_songs['release_date'] = pd.to_datetime(df_1M_songs['release_date'], errors = 'coerce')\n",
    "df_1M_songs = df_1M_songs.rename({\n",
    "    'name': 'song',\n",
    "    'artists': 'artist'\n",
    "}, axis=1)[[\n",
    "    'id', 'song', 'artist', 'genre', 'release_date',\n",
    "    'acousticness', 'danceability', 'duration_ms', \n",
    "    'energy', 'instrumentalness', 'key', 'liveness', 'loudness', \n",
    "    'mode', 'speechiness', 'tempo','time_signature', 'valence'\n",
    "]].reset_index(drop=True)\n",
    "\n",
    "# NOTE: DO NOT DROP DUPLICATES YET, NEED FOR LOOKUP WITH B100\n",
    "\n",
    "# save files as pickle\n",
    "df_1M_songs.to_pickle('df_1M_songs.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da221923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 806 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##### Billboard Top 100 Historical Data\n",
    "url_B100 = r'D:\\RYERSON\\820\\Datasets\\Billboard The Hot 100 Songs\\charts.csv'\n",
    "dtypes_timeseries = {\n",
    "    'rank': 'Int16', 'last-week': 'Int16', 'peak-rank': 'Int16', 'weeks-on-board': 'Int16'\n",
    "}\n",
    "df_B100 = pd.read_csv(url_B100, dtype=dtypes_timeseries)\n",
    "df_B100['date'] = pd.to_datetime(df_B100['date'])\n",
    "\n",
    "# Unique Songs from The Billboard 100 Dataset\n",
    "df_B100_songs = df_B100[['song', 'artist']].drop_duplicates().sort_values(['artist', 'song']).reset_index(drop=True)\n",
    "\n",
    "# save files as pickle\n",
    "df_B100.to_pickle('df_B100.pickle')\n",
    "df_B100_songs.to_pickle('df_B100_songs.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c5b8f5",
   "metadata": {},
   "source": [
    "# Merge into Working Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ece38a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# reload data\n",
    "df_genre = pd.read_pickle('df_genre.pickle')\n",
    "df_SQL = pd.read_pickle('df_SQL.pickle')\n",
    "df_1M_songs = pd.read_pickle('df_1M_songs.pickle')\n",
    "df_B100 = pd.read_pickle('df_B100.pickle')\n",
    "df_B100_songs = pd.read_pickle('df_B100_songs.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e0fbcd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# merge SQL and CSV AF to get df_10M\n",
    "ids_SQL = set(df_SQL['id'].to_list())\n",
    "df_TEMP = df_1M_songs.copy()  \n",
    "df_TEMP = df_TEMP[~df_TEMP.id.isin(ids_SQL)]  # drop songs already in SQL before merge\n",
    "df_10M = pd.concat([df_SQL, df_TEMP]).reset_index(drop=True)\n",
    "\n",
    "# drop duplicate song/artist (exact matches only)\n",
    "df_10M = df_10M.sort_values('release_date').drop_duplicates(['song', 'artist']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ce9eb7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# add approx song and artist columns for approx match\n",
    "df_10M['approx_song'] = df_10M[['song']].applymap(clean_text)\n",
    "df_10M['approx_artist'] = df_10M[['artist']].applymap(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3ffdfc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 417 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# add approx song and artist columns to B100 for merging\n",
    "df_B100_songs['approx_song'] = df_B100_songs[['song']].applymap(clean_text)\n",
    "df_B100_songs['approx_artist'] = df_B100_songs[['artist']].applymap(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "112889c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# merge B100 with 10M to get AF, where available\n",
    "df_B100_songs = df_B100_songs.merge(df_10M, on=['approx_song', 'approx_artist'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "408dfcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 295 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# drop blank artist+song\n",
    "df_B100_songs = df_B100_songs[~((df_B100_songs.approx_song == '') & (df_B100_songs.approx_artist == ''))]\n",
    "\n",
    "# sort by exact matches, then release_date\n",
    "df_B100_songs['EXACT_MATCH'] = (df_B100_songs['song_x'] == df_B100_songs['song_y'])*1 + (df_B100_songs['artist_x'] == df_B100_songs['artist_y'])*1\n",
    "\n",
    "# drop duplicates (keep exact matches, or oldest song)\n",
    "df_B100_songs = (\n",
    "    df_B100_songs.sort_values('release_date')\n",
    "    .sort_values('EXACT_MATCH', ascending=False)\n",
    "    .dropna(subset=['song_x', 'artist_x'], axis='rows')\n",
    "    .drop_duplicates(['song_x', 'artist_x'])\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a524a3f",
   "metadata": {},
   "source": [
    "# Spotify API - GET missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf6375b",
   "metadata": {},
   "source": [
    "##### get a temporary authorization token from: https://developer.spotify.com/console/get-search-item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd01f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input the temporary token\n",
    "TEMP_TOKEN = input('Enter token: ')\n",
    "\n",
    "# create a spotify object\n",
    "spotify = spotipy.Spotify(auth=TEMP_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908a6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# loop to get id where missing\n",
    "\n",
    "counter = 0\n",
    "id_from_API = set()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i, row in df_B100_songs.iterrows():\n",
    "    \n",
    "    if i < 0:  # where we timed out last time\n",
    "        continue\n",
    "        \n",
    "    if counter % 10 == 0:\n",
    "        print(counter, end=' ')\n",
    "    if counter % 100 == 0:\n",
    "        print()\n",
    "        df_B100_songs.to_pickle('df_B100_songs_AF_TEMP.pickle') # save temp file\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    if df_B100_songs[~df_B100_songs.id.isna()]:\n",
    "        continue    \n",
    "    \n",
    "    # these are the actual song and artist from the Billboard Hot 100\n",
    "    song = df_B100_songs.loc[df_B100_songs.index[i], 'song']\n",
    "    artist = df_B100_songs.loc[df_B100_songs.index[i], 'artist']\n",
    "    \n",
    "    # get all track info from Spotify API matching 'song' and 'artist'\n",
    "    all_track_info = find_all_tracks(song, artist)\n",
    "    \n",
    "    # restart loop if there are no results\n",
    "    if all_track_info == 'MISSING':\n",
    "        continue\n",
    "    \n",
    "    is_exact_match = False\n",
    "    \n",
    "    # first subloop - check for direct matched\n",
    "    for track_info in all_track_info:\n",
    "        temp_id = track_info[0]\n",
    "        temp_song = track_info[1]\n",
    "        temp_artist = track_info[2]\n",
    "        \n",
    "        # if there is an exact text match\n",
    "        is_exact_match = remove_punctuation(temp_song) == remove_punctuation(song) and \\\n",
    "                         remove_punctuation(temp_artist) == remove_punctuation(artist)\n",
    "        \n",
    "        # continue subloop\n",
    "        if is_exact_match:\n",
    "            df_B100_songs.loc[df_B100_songs.index[i], 'CORRECT_ID'] = temp_id\n",
    "            df_B100_songs.loc[df_B100_songs.index[i], 'id_status'] = 'CONFIRMED'\n",
    "            continue\n",
    "    \n",
    "    # if we confirmed, go to the next row item\n",
    "    if df_B100_songs.loc[df_B100_songs.index[i], 'id_status'] != 'CONFIRMED':\n",
    "            \n",
    "        # second subloop - check for indirect matches (shouldn't run if direct match occurs)\n",
    "        for track_info in all_track_info:\n",
    "            temp_id = track_info[0]\n",
    "            temp_song = track_info[1]\n",
    "            temp_artist = track_info[2]\n",
    "\n",
    "            # if there is a probable text match\n",
    "            is_probable_match = clean_text(temp_song) == clean_text(song) and \\\n",
    "                                clean_text(temp_artist) == clean_text(artist)\n",
    "\n",
    "            if is_probable_match:\n",
    "                df_B100_songs.loc[df_QA2.index[i], 'PROBABLE_ID'] = temp_id\n",
    "                df_B100_songs.loc[df_QA2.index[i], 'id_status'] = 'LIKELY'\n",
    "                continue\n",
    "            \n",
    "\n",
    "df_B100_songs.to_pickle('df_B100_songs_AF_COMPLETE.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc6911",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# loop to get genre, release_date, and audio features\n",
    "\n",
    "how_many_passes = 0\n",
    "\n",
    "for i, row in df_need_AF.iterrows():\n",
    "    # not sure if this is too many GETs...\n",
    "    \n",
    "    # show status update\n",
    "    if i%10 == 0:\n",
    "        print(i, end='  ')\n",
    "    if i%100 == 0:\n",
    "        print()\n",
    "\n",
    "    # Get Audio Features - 1st GET request\n",
    "    list_of_features = [\n",
    "        'acousticness', 'danceability', 'duration_ms', 'energy',\n",
    "        'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\n",
    "        'speechiness', 'tempo', 'time_signature', 'valence'\n",
    "    ]\n",
    "    \n",
    "    track_id = df_need_AF['id'].iloc[i]\n",
    "    temp_audio_features = spotify.audio_features(track_id)\n",
    "    for key in list_of_features:\n",
    "        df_need_AF.loc[i, key] = temp_audio_features[0][key]\n",
    "\n",
    "    # Get Release Date - 2nd GET request\n",
    "    track_info = spotify.track(track_id)\n",
    "    df_need_AF.loc[i, 'release_date'] = track_info['album']['release_date']\n",
    "\n",
    "    # Get Release Date Genre - 3rd GET request\n",
    "    artist_id = track_info['artists'][0]['id']\n",
    "    artist_info = spotify.artist(artist_id)\n",
    "    list_of_artist_genres = artist_info['genres']\n",
    "\n",
    "    try:\n",
    "        most_common_genre = list_of_artist_genres[0] # default to first genre\n",
    "        if len(list_of_artist_genres) == 1:\n",
    "            pass\n",
    "        else:\n",
    "            for genre in list_of_ordered_genres:\n",
    "                if genre in list_of_artist_genres:\n",
    "                    most_common_genre = genre\n",
    "                    break\n",
    "        df_need_AF.loc[i, 'genre'] = most_common_genre\n",
    "    except:\n",
    "        how_many_passes += 1\n",
    "        pass  # didn't have any genres, move on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4617ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7246b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121d8377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def679e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
