{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99f63722",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea5d21f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from ast import literal_eval\n",
    "import spotipy\n",
    "\n",
    "# jupyter notebook full-width display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:_.2f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05412bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def find_all_tracks(track_title, artist_name):\n",
    "    \"\"\" returns list of lists ['id', 'song', 'artist'] \"\"\"\n",
    "    track_info = spotify.search(q='artist:' + artist_name + ' track:' + track_title, type='track')\n",
    "    \n",
    "    if track_info['tracks']['items'] == []:  # if track doesn't exist on Spotify\n",
    "        return 'MISSING'\n",
    "    else:\n",
    "        all_tracks = []\n",
    "        number_of_results = len(track_info['tracks']['items'])\n",
    "        \n",
    "        # check if there is a better match\n",
    "        for i in range(number_of_results):\n",
    "            track_id = track_info['tracks']['items'][i]['id']\n",
    "            artist_name = track_info['tracks']['items'][i]['artists'][0]['name']\n",
    "            song_name = track_info['tracks']['items'][i]['name']\n",
    "            all_tracks.append([track_id, song_name, artist_name])\n",
    "        \n",
    "        # if we made it through the loop without returning, note 'MISSING' and return the 0th id\n",
    "        return all_tracks\n",
    "\n",
    "\n",
    "def remove_punctuation(text_input):\n",
    "    text_input = re.sub(r'&', 'and', text_input)  # replaces & with 'and'\n",
    "    text_input = re.compile(r'[^a-zA-Z 0-9]').sub('', text_input)\n",
    "    return text_input.lower().strip()\n",
    "\n",
    "\n",
    "def clean_text(text_input):\n",
    "    text_input = text_input.strip().lower()\n",
    "    text_input = re.sub(r'&', 'and', text_input)  # replaces & with 'and'\n",
    "    text_input = re.sub(r'and.+', '', text_input)  # removes text after the 'and'\n",
    "    text_input = re.compile(r'the').sub('', text_input)  # remove all 'the' (maybe just need the 1st word?)\n",
    "    text_input = re.sub(r',.+', '', text_input)  # removes all misc artists, after comma \n",
    "    text_input = re.sub(r'(?:feat).+', '', text_input)  # removes all misc artists, after 'feat' \n",
    "    text_input = re.sub(r'\\(.+', '', text_input)  # removes text after first bracket\n",
    "    text_input = re.sub(r'\\-.+', '', text_input)  # removes text after first dash\n",
    "    text_input = re.compile(r'[^a-zA-Z 0-9]').sub('', text_input)  # remove punctuation\n",
    "    text_input = re.sub(' +', ' ', text_input)  # remove multiple spaces\n",
    "    return text_input.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51b4a294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##### SQL 8+M\n",
    "\"\"\"\n",
    "    SELECT * FROM tracks\n",
    "    JOIN r_track_artist ON tracks.id = r_track_artist.track_id\n",
    "    JOIN artists ON r_track_artist.artist_id = artists.id\n",
    "    JOIN audio_features ON audio_features.id = tracks.audio_feature_id\n",
    "\"\"\"\n",
    "dtypes = {\n",
    "    'key': 'Int16', 'mode': 'Int16', 'time_signature': 'Int16', 'tempo': 'float32', \n",
    "    'acousticness': 'float32', 'danceability': 'float32', 'duration_ms': 'Int64',  \n",
    "    'energy': 'float32', 'instrumentalness': 'float32', 'liveness': 'float32', \n",
    "    'loudness': 'float32', 'speechiness': 'float32', 'valence': 'float32'\n",
    "} \n",
    "df_SQL = pd.read_csv('all_audio_features_sql.csv', dtype=dtypes)\n",
    "\n",
    "# import genre and release date data\n",
    "\"\"\"\n",
    "    SELECT tracks.id AS id, release_date, genre_id as genre FROM tracks\n",
    "    JOIN r_albums_tracks ON tracks.id = r_albums_tracks.track_id\n",
    "    JOIN albums ON r_albums_tracks.album_id = albums.id\n",
    "    JOIN r_track_artist ON tracks.id = r_track_artist.track_id\n",
    "    JOIN r_artist_genre ON r_track_artist.artist_id = r_artist_genre.artist_id\n",
    "\"\"\"\n",
    "df_genre = pd.read_csv('SQL_track_release_date_and_genre.csv')\n",
    "df_genre['genre_count'] = df_genre.groupby('genre')['genre'].transform('count')  # add a count column\n",
    "df_TEMP = df_genre.copy()  # create temp df, sort by most common genre, merge with SQL data\n",
    "df_TEMP = df_TEMP.drop_duplicates(['id']).sort_values('genre_count', ascending=False).drop_duplicates(['id']).reset_index(drop=True)\n",
    "df_SQL = df_SQL.merge(df_TEMP, on='id')\n",
    "\n",
    "# now format and save df_genre\n",
    "# NOTE: slightly different then old method, counts multiple instances of a song with multiple artists (for each artist)\n",
    "df_genre = df_genre[['genre', 'genre_count']].sort_values('genre_count', ascending=False).drop_duplicates(['genre']).reset_index(drop=True)\n",
    "\n",
    "# formatting\n",
    "df_SQL['release_date'] = pd.to_datetime(df_SQL['release_date'], unit='ms', origin='unix', errors = 'coerce')\n",
    "df_SQL = df_SQL.rename({\n",
    "    'name:1': 'artist',\n",
    "    'name': 'song',\n",
    "    'duration:1': 'duration_ms'\n",
    "}, axis=1)[[\n",
    "    'id', 'song', 'artist', 'genre', 'release_date',\n",
    "    'acousticness', 'danceability', 'duration_ms', \n",
    "    'energy', 'instrumentalness', 'key', 'liveness', 'loudness', \n",
    "    'mode', 'speechiness', 'tempo','time_signature', 'valence'\n",
    "]].reset_index(drop=True)\n",
    "\n",
    "# NOTE: DO NOT DROP DUPLICATES YET, NEED FOR LOOKUP WITH B100\n",
    "\n",
    "# save files as pickle\n",
    "df_genre.to_pickle('df_genre.pickle')\n",
    "df_SQL.to_pickle('df_SQL.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2048ecc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##### Spotify 1.2M+ Songs\n",
    "url_1M_songs = r'D:\\RYERSON\\820\\Datasets\\Spotify 1.2M+ Songs\\tracks_features.csv'\n",
    "df_1M_songs = pd.read_csv(url_1M_songs)\n",
    "\n",
    "# doesn't have genre (would take 1000+ to get using API, will stay NA)\n",
    "df_1M_songs['genre'] = pd.NA\n",
    "\n",
    "# explode artists\n",
    "df_1M_songs['artists'] = df_1M_songs['artists'].apply(literal_eval) #convert to list type\n",
    "df_1M_songs = df_1M_songs.explode('artists', ignore_index=True)\n",
    "\n",
    "# formatting\n",
    "df_1M_songs['release_date'] = pd.to_datetime(df_1M_songs['release_date'], errors = 'coerce')\n",
    "df_1M_songs = df_1M_songs.rename({\n",
    "    'name': 'song',\n",
    "    'artists': 'artist'\n",
    "}, axis=1)[[\n",
    "    'id', 'song', 'artist', 'genre', 'release_date',\n",
    "    'acousticness', 'danceability', 'duration_ms', \n",
    "    'energy', 'instrumentalness', 'key', 'liveness', 'loudness', \n",
    "    'mode', 'speechiness', 'tempo','time_signature', 'valence'\n",
    "]].reset_index(drop=True)\n",
    "\n",
    "# NOTE: DO NOT DROP DUPLICATES YET, NEED FOR LOOKUP WITH B100\n",
    "\n",
    "# save files as pickle\n",
    "df_1M_songs.to_pickle('df_1M_songs.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a549018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 848 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##### Billboard Top 100 Historical Data\n",
    "url_B100 = r'D:\\RYERSON\\820\\Datasets\\Billboard The Hot 100 Songs\\charts.csv'\n",
    "dtypes_timeseries = {\n",
    "    'rank': 'Int16', 'last-week': 'Int16', 'peak-rank': 'Int16', 'weeks-on-board': 'Int16'\n",
    "}\n",
    "df_B100 = pd.read_csv(url_B100, dtype=dtypes_timeseries)\n",
    "df_B100['date'] = pd.to_datetime(df_B100['date'])\n",
    "\n",
    "# Unique Songs from The Billboard 100 Dataset\n",
    "df_B100_songs = df_B100[['song', 'artist']].drop_duplicates().sort_values(['artist', 'song']).reset_index(drop=True)\n",
    "df_B100_songs['id'] = ''  # add a blank id column\n",
    "\n",
    "# save files as pickle\n",
    "df_B100.to_pickle('df_B100.pickle')\n",
    "df_B100_songs.to_pickle('df_B100_songs.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a9725e",
   "metadata": {},
   "source": [
    "# Merge into Working Datasets, and GET missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588567bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# reload data\n",
    "df_genre = pd.read_pickle('df_genre.pickle')\n",
    "df_SQL = pd.read_pickle('df_SQL.pickle')\n",
    "df_1M_songs = pd.read_pickle('df_1M_songs.pickle')\n",
    "df_B100 = pd.read_pickle('df_B100.pickle')\n",
    "df_B100_songs = pd.read_pickle('df_B100_songs.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c55d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# merge SQL and CSV AF to get df_10M\n",
    "ids_SQL = set(df_SQL['id'].to_list())\n",
    "df_TEMP = df_1M_songs.copy()  \n",
    "df_TEMP = df_TEMP[~df_TEMP.id.isin(ids_SQL)]  # drop songs already in SQL before merge\n",
    "df_10M = pd.concat([df_SQL, df_TEMP]).reset_index(drop=True)\n",
    "\n",
    "# add approx song and artist columns for approx match\n",
    "df_10M['approx_song'] = df_10M[['song']].applymap(clean_text)\n",
    "df_10M['approx_artist'] = df_10M[['artist']].applymap(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d9154c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10M.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18448ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1798207, 18), (1355164, 18))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1M_songs.shape, df_1M_songs[~df_1M_songs.id.isin(ids_SQL)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e147541c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00132ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
