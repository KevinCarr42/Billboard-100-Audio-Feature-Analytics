{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cc4646d",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92fb833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spotipy\n",
    "\n",
    "# jupyter notebook full-width display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:_.0f}'.format)\n",
    "# NOTE: underscore separaters ('_') are better than commas (',') because \n",
    "# numbers with underscores work in Python without any extra effort.\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e749a91f",
   "metadata": {},
   "source": [
    "# Import Starting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c8526b",
   "metadata": {},
   "source": [
    "### The Billboard 100\n",
    "https://www.kaggle.com/datasets/dhruvildave/billboard-the-hot-100-songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a90136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Billboard Top 100 Historical Data\n",
    "# via:  https://toolbox.google.com/datasetsearch\n",
    "url_billboard = r'D:\\RYERSON\\820\\Datasets\\Billboard The Hot 100 Songs\\charts.csv'\n",
    "\n",
    "df_billboard = pd.read_csv(url_billboard)\n",
    "df_billboard['date'] = pd.to_datetime(df_billboard['date'])\n",
    "\n",
    "# Unique Songs from The Billboard 100 Dataset\n",
    "\n",
    "# just the songs on the billboard 100, once per song\n",
    "df_billboard_songs = df_billboard[['song', 'artist']].drop_duplicates().sort_values(['artist', 'song']).reset_index(drop=True)\n",
    "\n",
    "# add a blank id column and a blank MISSING column \n",
    "df_billboard_songs['id'] = ''\n",
    "df_billboard_songs['MISSING'] = ''\n",
    "\n",
    "df_billboard.shape, df_billboard_songs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e30aa88",
   "metadata": {},
   "source": [
    "### 1.2M Songs with Metadata (csv)\n",
    "https://www.kaggle.com/datasets/rodolfofigueroa/spotify-12m-songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b1cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spotify 1.2M+ Songs\n",
    "# via:  https://www.kaggle.com/datasets/\n",
    "url_1M_songs = r'D:\\RYERSON\\820\\Datasets\\Spotify 1.2M+ Songs\\tracks_features.csv'\n",
    "\n",
    "# create the dataframe with the large number of songs metadata\n",
    "df_1M_songs = pd.read_csv(url_1M_songs)\n",
    "\n",
    "# make a list of song ids from the 1M dataset\n",
    "metadata_ids_csv = df_1M_songs.id.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d647687c",
   "metadata": {},
   "source": [
    "### 8.7M Songs with Metadata (SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5b3071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all ids from the SQLite database\n",
    "metadata_ids_SQL = pd.read_csv('all_ids_sql.csv', header=None, names=['id'])\n",
    "metadata_ids_SQL = metadata_ids_SQL.id.to_list()\n",
    "\n",
    "# audio feature data not imported yet (very large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0890645d",
   "metadata": {},
   "source": [
    "### Combine Ids For Datasets with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba335356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of ids for all of our known metadata\n",
    "all_metadata_ids = set(metadata_ids_csv + metadata_ids_SQL) # set() faster to search, and no duplicates\n",
    "len(all_metadata_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b3b605",
   "metadata": {},
   "source": [
    "### Get Track IDs using API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ea6389",
   "metadata": {},
   "source": [
    "### TEMPORARY TOKEN WORKFLOW\n",
    "\n",
    "##### get a temporary authorization token from: https://developer.spotify.com/console/get-search-item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418a133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input the temporary token\n",
    "TEMP_TOKEN = input('Enter token: ')\n",
    "\n",
    "# create a spotify object\n",
    "spotify = spotipy.Spotify(auth=TEMP_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d8d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def find_id(track_title, artist_name, metadata_ids):\n",
    "    \"\"\" \n",
    "    for searches with multiple results, all id were identical for the test cases I ran \n",
    "    some searches return no results, in this case the song is not on spotify\n",
    "        confirmed by spot checks in the spotify music player\n",
    "    some tracks give a 404 error, \n",
    "        these seem to exist in Spotify but 404 anyway\n",
    "        not sure why the API does this but \n",
    "    \"\"\"\n",
    "    track_info = spotify.search(q='artist:' + artist_name + ' track:' + track_title, type='track')\n",
    "    \n",
    "    if track_info['tracks']['items'] == []:  # if track doesn't exist on Spotify\n",
    "        return '', 'MISSING'\n",
    "    else:\n",
    "        # default to 0th id\n",
    "        track_id = track_info['tracks']['items'][0]['id']\n",
    "        \n",
    "        number_of_results = len(track_info['tracks']['items'])\n",
    "        \n",
    "        # check if there is a better match\n",
    "        for i in range(number_of_results):\n",
    "            current_id = track_info['tracks']['items'][i]['id']\n",
    "            if current_id in metadata_ids:\n",
    "                return current_id, 'matched'  # immediately return it if it's found\n",
    "        \n",
    "        # if we made it through the loop without returning, note 'MISSING' and return the 0th id\n",
    "        return track_id, 'MISSING'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f39645",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# TEST\n",
    "find_id(\"You Can't Turn Me Off (In The Middle Of Turning Me On)\", 'High Inergy', all_metadata_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "find_id(\"You Can't Find this (SONG)\", 'Low Unergy', all_metadata_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3432b777",
   "metadata": {},
   "source": [
    "### Add Spotify IDs to billboard songs matched in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dfe9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved csv if required\n",
    "df_billboard_songs = pd.read_csv('df_billboard_songs.csv', keep_default_na=False)\n",
    "df_billboard_songs.id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46839b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start over at\n",
    "start_over_at = 30000\n",
    "\n",
    "# populate df_billboard_songs with ids, where available\n",
    "for i, row in df_billboard_songs.iterrows():\n",
    "    \n",
    "    # start over at\n",
    "    if i < start_over_at-1:\n",
    "        continue\n",
    "    \n",
    "    # show status update\n",
    "    if i%10 == 0:\n",
    "        print(i, end='  ')\n",
    "    if i%100 == 0:\n",
    "        print()\n",
    "        \n",
    "    # start over where we finished (don't overwrite known ids)\n",
    "    if df_billboard_songs['id'].iloc[i] != '':  \n",
    "        continue\n",
    "    # append id, NONE, or 'ERROR'\n",
    "    else:\n",
    "        artist = row[1]\n",
    "        song = row[0]\n",
    "        try:\n",
    "            # unless there is an error, will append the id or None \n",
    "            df_billboard_songs['id'].iloc[i], df_billboard_songs['MISSING'].iloc[i] = find_id(song, artist, all_metadata_ids)\n",
    "        except:  # all errors treated the same\n",
    "            # if there is an error, change id to 'ERROR'\n",
    "            print('ERROR:  ', artist, song)\n",
    "            df_billboard_songs['MISSING'].iloc[i] = 'ERROR'  # leave id blank\n",
    "        \n",
    "        # save every 1000 rows, if new\n",
    "        if i%1000 == 0:\n",
    "            df_billboard_songs.to_csv('df_billboard_songs_TEMP.csv', index=False)\n",
    "        \n",
    "# save final dataframe\n",
    "df_billboard_songs.to_csv('df_billboard_songs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4305c040",
   "metadata": {},
   "source": [
    "### After Gathering all IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210aae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload df_billboard_songs if required\n",
    "df_billboard_songs = pd.read_csv('df_billboard_songs.csv', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5d9c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many id have we added\n",
    "df_billboard_songs.id.nunique(), sum(df_billboard_songs.id != \"\")\n",
    "# 83 duplicated ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c49623",
   "metadata": {},
   "source": [
    "### Remove Duplicates / Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f14879",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df_billboard_songs[df_billboard_songs.id!='']\n",
    "duplicates = duplicates[duplicates.id.duplicated(False)]\n",
    "duplicates.to_csv('duplicated_ids.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df93aa5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # go through this manually and fix it\n",
    "#     # in this case NEED TO FIX BOTH BILLBOARD DATAFRAMES\n",
    "\n",
    "# # OR drop the corrupted rows\n",
    "# # manually imputing is problematic, error prone, and time consuming\n",
    "\n",
    "# duplicates.sort_values('id').head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54044aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of duplicated ids\n",
    "duplicated_ids = set(duplicates.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99450183",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_billboard_songs['id'].isin(duplicated_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13798075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop from billboard list of known ids \n",
    "for i, row in df_billboard_songs.iterrows():\n",
    "    if df_billboard_songs.iloc[i]['id'] in duplicated_ids:\n",
    "        df_billboard_songs['MISSING'].iloc[i] = 'DUPLICATED'\n",
    "        df_billboard_songs['id'].iloc[i] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdff09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_billboard_songs['id'].isin(duplicated_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba2d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_billboard_songs.to_csv('df_billboard_songs - duplicates removed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf30b4e",
   "metadata": {},
   "source": [
    "### what songs are still missing audio feature data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addcd859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the dataframe if required\n",
    "df_billboard_songs = pd.read_csv('df_billboard_songs - duplicates removed.csv', keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c0f359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many id have we added\n",
    "df_billboard_songs.id.nunique(), sum(df_billboard_songs.id != '')\n",
    "# off by one because '' counts as a unique id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4ff26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many id match the metadata_ids\n",
    "sum(df_billboard_songs.id.isin(all_metadata_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7370921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# songs on spotify that we don't have audio features for yet\n",
    "need_audio_features = df_billboard_songs[(~df_billboard_songs.id.isin(all_metadata_ids) & (df_billboard_songs.id != ''))]\n",
    "need_audio_features.to_csv('need_audio_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd410117",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(need_audio_features.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adad0703",
   "metadata": {},
   "source": [
    "### Use API again to get missing audio features\n",
    "https://developer.spotify.com/console/get-audio-features-track/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166bc83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input the temporary token\n",
    "TEMP_TOKEN = input('Enter token: ')\n",
    "\n",
    "# create a spotify object\n",
    "spotify = spotipy.Spotify(auth=TEMP_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f1a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise dataframe\n",
    "\n",
    "with_audio_features = need_audio_features.copy().reset_index()\n",
    "\n",
    "list_of_features = [\n",
    "    'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
    "    'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature'\n",
    "]\n",
    "\n",
    "for feature in list_of_features:\n",
    "    with_audio_features[feature] = ''\n",
    "\n",
    "with_audio_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_over_at = 1200\n",
    "\n",
    "list_of_features = [\n",
    "    'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
    "    'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature'\n",
    "]\n",
    "\n",
    "for i, row in with_audio_features.iterrows():\n",
    "    \n",
    "    # start over at\n",
    "    if i < start_over_at-1:\n",
    "        continue\n",
    "    \n",
    "    # show status update\n",
    "    if i%10 == 0:\n",
    "        print(i, end='  ')\n",
    "    if i%100 == 0:\n",
    "        print()\n",
    "    \n",
    "    track_id = with_audio_features['id'].iloc[i]\n",
    "    temp_audio_features = spotify.audio_features(track_id)\n",
    "    \n",
    "    for key in list_of_features:\n",
    "        with_audio_features[key].iloc[i] = temp_audio_features[0][key]\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        with_audio_features.to_csv('audio_features_TEMP.csv', index=True)\n",
    "    \n",
    "# save final df\n",
    "with_audio_features.to_csv('audio_features_FINAL.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9408044d",
   "metadata": {},
   "source": [
    "### OPTIONAL QA SPOTCHECKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4e1dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO: QA check ####\n",
    "# should I confirm that i get the same audio features as from the other datasets??\n",
    "# maybe do a small spotcheck\n",
    "\n",
    "QA_DATAFRAME = df_billboard_songs[df_billboard_songs.MISSING == 'matched'].sample(100).reset_index()\n",
    "\n",
    "list_of_features = [\n",
    "    'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
    "    'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature'\n",
    "]\n",
    "\n",
    "for feature in list_of_features:\n",
    "    QA_DATAFRAME[feature] = ''\n",
    "\n",
    "QA_DATAFRAME.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081815e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_over_at = 0\n",
    "\n",
    "list_of_features = [\n",
    "    'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness',\n",
    "    'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature'\n",
    "]\n",
    "\n",
    "for i, row in QA_DATAFRAME.iterrows():\n",
    "    \n",
    "    # start over at\n",
    "    if i < start_over_at-1:\n",
    "        continue\n",
    "    \n",
    "    # show status update\n",
    "    if i%10 == 0:\n",
    "        print(i, end='  ')\n",
    "    if i%100 == 0:\n",
    "        print()\n",
    "    \n",
    "    track_id = QA_DATAFRAME['id'].iloc[i]\n",
    "    temp_audio_features = spotify.audio_features(track_id)\n",
    "    \n",
    "    for key in list_of_features:\n",
    "        QA_DATAFRAME[key].iloc[i] = temp_audio_features[0][key]\n",
    "    \n",
    "# save final df\n",
    "QA_DATAFRAME.to_csv('QA_DATAFRAME.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42a74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check these later to confirm that the downloaded data is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c719939c",
   "metadata": {},
   "source": [
    "# Finalize Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c23cf",
   "metadata": {},
   "source": [
    "### Reimport data from Billboard 100 and 1.2M Songs Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b8b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# billboard songs \n",
    "df_billboard_songs = pd.read_csv('df_billboard_songs - duplicates removed.csv', keep_default_na=False)\n",
    "\n",
    "# billboard songs with audio features from API (missing from other datasets)\n",
    "df_api_features = pd.read_csv('audio_features_FINAL, keep_default_na=False)\n",
    "\n",
    "# billboard time series\n",
    "df_billboard = pd.read_csv(url_billboard)\n",
    "df_billboard['date'] = pd.to_datetime(df_billboard['date'])\n",
    "\n",
    "# 1.2M songs with metadata\n",
    "df_1M_songs = pd.read_csv(url_1M_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88011271",
   "metadata": {},
   "source": [
    "### 8+ M. Spotify Tracks, Genre, Audio Features (SQLite)\n",
    "https://www.kaggle.com/datasets/maltegrosse/8-m-spotify-tracks-genre-audio-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee495f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_8M_sql = 'D:\\RYERSON\\820\\Datasets\\8+ M. Spotify Tracks, Genre, Audio Features\\spotify.sqlite'\n",
    "url_8M_csv = 'all_audio_features_sql.csv'  # .gitignore (very big)\n",
    "\n",
    "df_8M_songs = pd.read_csv(url_8M_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aee7a1",
   "metadata": {},
   "source": [
    "### Merge Billboard 100 with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccd06cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# STEP 1\n",
    "# df_billboard_songs, append\n",
    "    # df_8M_songs\n",
    "    # df_1M_songs\n",
    "    # df_api_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2\n",
    "# df_billboard, append\n",
    "    # df_billboard_songs\n",
    "# set missing audio = np.nan\n",
    "    # create dataframe of billboard songs not on spotify\n",
    "    # create dataframe of billboard songs not on spotify\n",
    "# sort, reset index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3010f11",
   "metadata": {},
   "source": [
    "### Merge All Songs With Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f2389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# df_8M_songs, append\n",
    "    # df_1M_songs\n",
    "    # df_billboard_songs\n",
    "    # remove duplicates, sort, reset index\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37492690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fc6a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ca9b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate songs into\n",
    "    # not on spotify (no id)\n",
    "    # matched with audio features\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d363e8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the percentage of songs accounted for\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec8a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now merge with entire billboard list\n",
    "\n",
    "\n",
    "\n",
    "# re-count the percentage of songs accounted for in the entire set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb6774d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadd7df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e11d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3554c618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df673bd9",
   "metadata": {},
   "source": [
    "### Merge all Datasets into Billboard Features, \n",
    "export Billboard Features and All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d227d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b524b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e91a68b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f83b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA check vs QA dataframe\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
