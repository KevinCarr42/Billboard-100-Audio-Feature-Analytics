{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f379970c",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a36765e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# math and dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# statistics\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import friedmanchisquare, wilcoxon\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Pipeline and Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# jupyter notebook full-width display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cbcb793",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10M = pd.read_pickle('df_10M_clustered.pickle')\n",
    "X_all = pd.read_pickle('X_clustered.pickle')\n",
    "X_all.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed65dd3",
   "metadata": {},
   "source": [
    "# Setup inputs for statistical scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "065df1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns for datasets\n",
    "\n",
    "y_column = 'in_B100'\n",
    "X_columns = [\n",
    "    'mode', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
    "    'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence'\n",
    "]\n",
    "genre_columns = [\n",
    "    'is_Adult_Standard', 'is_Rock', 'is_R&B', 'is_Country', 'is_Pop',\n",
    "    'is_Rap', 'is_Alternative', 'is_EDM', 'is_Metal'\n",
    "]\n",
    "cluster_columns = ['cluster', 'cluster2']\n",
    "other_columns = ['key', 'time_signature', 'genre', 'release_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18cfdba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 160\n",
      "DecisionTreeClassifier 160\n",
      "KNeighborsClassifier 210\n",
      "RandomForestClassifier 1800\n",
      "AdaBoostClassifier 162\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "\n",
    "param_by_model = {}\n",
    "\n",
    "params_lr = {}\n",
    "orders_of_magnitude = []\n",
    "for lst in [[int(x)/10000 for x in range(1, 11)],\n",
    "            [int(x)/1000 for x in range(1, 11)],\n",
    "            [int(x)/100 for x in range(1, 11)],\n",
    "            [int(x)/10 for x in range(1, 11)],\n",
    "            [1 * x for x in range(1, 11)],\n",
    "            [10 * x for x in range(1, 11)],\n",
    "            [100 * x for x in range(1, 11)],\n",
    "            [1000 * x for x in range(1, 11)]]:\n",
    "    orders_of_magnitude += lst\n",
    "params_lr['logisticregression__penalty'] = ['l1', 'l2']\n",
    "params_lr['logisticregression__C'] = orders_of_magnitude\n",
    "params_lr['logisticregression__solver'] = ['liblinear']\n",
    "param_by_model[0] = params_lr\n",
    "\n",
    "params_dt = {}\n",
    "params_dt['decisiontreeclassifier__max_depth'] = [3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 40, 50, 100, None]\n",
    "params_dt['decisiontreeclassifier__min_samples_leaf'] = [5, 10, 50, 100, 1000]\n",
    "params_dt['decisiontreeclassifier__criterion'] = ['gini', 'entropy']\n",
    "param_by_model[1] = params_dt\n",
    "\n",
    "params_knn = {}\n",
    "params_knn['kneighborsclassifier__n_neighbors'] = [x for x in range(2,20)]+[x for x in range(20,101,5)]\n",
    "params_knn['kneighborsclassifier__weights'] = ['uniform', 'distance']\n",
    "params_knn['kneighborsclassifier__metric'] = ['minkowski', 'euclidean', 'manhattan']\n",
    "param_by_model[2] = params_knn\n",
    "\n",
    "params_rf = {}\n",
    "params_rf['randomforestclassifier__n_estimators'] = [5, 10, 20, 50, 100, 200, 500, 1000, 2000]\n",
    "params_rf['randomforestclassifier__max_features'] = ['sqrt', 'log2']\n",
    "params_rf['randomforestclassifier__max_depth'] = [3, 5, 7, 10, 15, 20, 30, 50, 100, None]\n",
    "params_rf['randomforestclassifier__min_samples_leaf'] = [5, 10, 50, 100, 1000]\n",
    "params_rf['randomforestclassifier__bootstrap'] = [True, False]\n",
    "param_by_model[3] = params_rf\n",
    "\n",
    "params_ab = {}\n",
    "params_ab['adaboostclassifier__n_estimators'] = [10, 50, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "params_ab['adaboostclassifier__learning_rate'] = [0.0001, 0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 1.5, 2.0]\n",
    "params_ab['adaboostclassifier__algorithm'] = ['SAMME', 'SAMME.R']\n",
    "param_by_model[4] = params_ab\n",
    "\n",
    "# scoring metrics\n",
    "\n",
    "metrics = [\n",
    "    'balanced_accuracy', 'average_precision', 'neg_brier_score', 'f1', 'f1_micro', \n",
    "    'f1_macro', 'f1_weighted', 'neg_log_loss', 'precision', 'recall', 'roc_auc', 'jaccard'\n",
    "]\n",
    "\n",
    "# how many hyperparameter scenarios in the grid search\n",
    "\n",
    "def how_many_scenarios(n_ML):\n",
    "    n_scenarios = 1\n",
    "    for key in param_by_model[n_ML].keys():\n",
    "        n_scenarios *=  len(param_by_model[n_ML][key])\n",
    "    return n_scenarios\n",
    "\n",
    "for i in range(5):\n",
    "    print(str(ML_algorithms[i]())[:-2], how_many_scenarios(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e4f987",
   "metadata": {},
   "source": [
    "# Make Predictions Dataframe for Statistics\n",
    "* split into 5 stratified folds\n",
    "    * using a consistent random_state to use the same folds between tests\n",
    "* for each fold:\n",
    "    * train on undersampled training fold\n",
    "    * predict on full test fold\n",
    "    * add out of fold predictions to add to predictions dataframe\n",
    "    \n",
    "NOTES: \n",
    "* Tuning individual models on limited datasets has been investigated in NOTEBOOK 5B (and 5D).\n",
    "* Random undersampling and oversampling were investigated in NOTEBOOK 5A\n",
    "    * More oversampling methods like SMOTE were not considered because the nature of music. For example, interpolating between modes leads to an atonal, non-musical result. Discrete combinations of features are likely to be important in terms of audio features as well. More importantly, with over 20k positive cases in our dataset, we should have enough data for a well trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8d214a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the dataframe\n",
    "\n",
    "# use the same stratified split for all test cases\n",
    "stratified_5fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# scenarios to test\n",
    "stats_scenarios = [\n",
    "    'y_lr', 'y_dt', 'y_knn', 'y_rf', 'y_ab', 'y_lr_tuned', 'y_dt_tuned', 'y_knn_tuned', 'y_rf_tuned', 'y_ab_tuned', 'y_cl_1', 'y_cl_2', 'y_genres'\n",
    "]\n",
    "\n",
    "df_predictions = pd.DataFrame(columns=stats_scenarios)\n",
    "df_predictions['y_actual'] = pd.NA  # for debugging\n",
    "df_predictions = pd.concat([X_all, df_predictions], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ef70ed",
   "metadata": {},
   "source": [
    "### Predict Using Default Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "14e6cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### UPDATE THIS WITH FUTURE FUNCTION\n",
    "\n",
    "def evaluate_default_performance(dataframe, kfold, feature_columns, class_column, n_scenario):\n",
    "    \n",
    "    # entire dataset for predictions\n",
    "    X_, y_ = dataframe[feature_columns], dataframe[class_column]\n",
    "    \n",
    "    # initialise actual y and predicted y as blank dataframes\n",
    "    y_actual = pd.DataFrame()\n",
    "    y_pred = pd.DataFrame()\n",
    "\n",
    "    # loop through folds\n",
    "    for train_i, test_i in kfold.split(X_, y_):\n",
    "\n",
    "        # train test split for current fold\n",
    "        train_X, test_X = X_.iloc[train_i], X_.iloc[test_i]\n",
    "        train_y, test_y = y_.iloc[train_i], y_.iloc[test_i]\n",
    "        \n",
    "        # create and fit pipeline\n",
    "        undersampler = RandomUnderSampler(sampling_strategy='majority', random_state=42)\n",
    "        \n",
    "        if n_scenario in [1, 6]:\n",
    "            model = DecisionTreeClassifier()\n",
    "        elif n_scenario in [2, 7]:\n",
    "            model = KNeighborsClassifier()\n",
    "        elif n_scenario in [3, 8]:\n",
    "            model = RandomForestClassifier()\n",
    "        elif n_scenario in [4, 9]:\n",
    "            model = AdaBoostClassifier()\n",
    "        else:\n",
    "            model = LogisticRegression()\n",
    "        \n",
    "        pipe = make_pipeline(undersampler, model)\n",
    "        \n",
    "        pipe.fit(train_X, train_y)\n",
    "        \n",
    "        # append results\n",
    "        y_pred_temp = pipe.predict(test_X)\n",
    "        y_pred_temp = pd.concat([\n",
    "            pd.DataFrame(y_pred_temp),\n",
    "            pd.DataFrame(test_i, columns=[''])\n",
    "        ], axis=1).set_index('')\n",
    "        y_pred = pd.concat([y_pred, y_pred_temp], axis=0)\n",
    "        y_actual = pd.concat([y_actual, test_y], axis=0)  # for debugging\n",
    "\n",
    "    # return the full sorted results, appended into the input dataframe\n",
    "    dataframe[stats_scenarios[n_scenario]] = y_pred.sort_index()\n",
    "    dataframe['y_actual'] = y_actual.sort_index()  # for debugging, this should always be equal to in_B100 or folds are misaligned\n",
    "    \n",
    "    # DEBUGGING: should be zero\n",
    "    is_ERRORS = sum(dataframe['in_B100'] != dataframe['y_actual'])\n",
    "    if is_ERRORS != 0:\n",
    "        print('THERE WERE ERRORS!!!! (compare the in_B100 and y_actual columns)')\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "371d3637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Logistic Regression\n",
    "n_scenario = 0\n",
    "df_predictions = evaluate_default_performance(df_predictions, stratified_5fold, X_columns, y_column, n_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1943f9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Decision Tree\n",
    "n_scenario = 1\n",
    "df_predictions = evaluate_default_performance(df_predictions, stratified_5fold, X_columns, y_column, n_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "543c1da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# K Nearest Neighbours\n",
    "n_scenario = 2\n",
    "df_predictions = evaluate_default_performance(df_predictions, stratified_5fold, X_columns, y_column, n_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6405d5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Random Forest\n",
    "n_scenario = 3\n",
    "df_predictions = evaluate_default_performance(df_predictions, stratified_5fold, X_columns, y_column, n_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "989fc351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# AdaBoost\n",
    "n_scenario = 4\n",
    "df_predictions = evaluate_default_performance(df_predictions, stratified_5fold, X_columns, y_column, n_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4d904fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe\n",
    "df_predictions.to_pickle('df_predictions_DEFAULT.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811fcd10",
   "metadata": {},
   "source": [
    "### Make Predictions With Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "902c329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_predictions(dataframe, kfold, feature_columns, class_column, n_scenario):\n",
    "    \n",
    "    # entire dataset for predictions\n",
    "    X_, y_ = dataframe[feature_columns], dataframe[class_column]\n",
    "    \n",
    "    # initialise actual y and predicted y as blank dataframes\n",
    "    y_actual = pd.DataFrame()\n",
    "    y_pred = pd.DataFrame()\n",
    "\n",
    "    # loop through folds\n",
    "    for train_i, test_i in kfold.split(X_, y_):\n",
    "\n",
    "        # train test split for current fold\n",
    "        train_X, test_X = X_.iloc[train_i], X_.iloc[test_i]\n",
    "        train_y, test_y = y_.iloc[train_i], y_.iloc[test_i]\n",
    "        \n",
    "        # create pipeline\n",
    "        undersampler = RandomUnderSampler(sampling_strategy='majority', random_state=42)\n",
    "        \n",
    "        if n_scenario in [1, 6]:\n",
    "            n_ML = 1\n",
    "            model = DecisionTreeClassifier()\n",
    "        elif n_scenario in [2, 7]:\n",
    "            n_ML = 2\n",
    "            model = KNeighborsClassifier()\n",
    "        elif n_scenario in [3, 8]:\n",
    "            n_ML = 3\n",
    "            model = RandomForestClassifier()\n",
    "        elif n_scenario in [4, 9]:\n",
    "            n_ML = 4\n",
    "            model = AdaBoostClassifier()\n",
    "        else:\n",
    "            n_ML = 0\n",
    "            model = LogisticRegression()\n",
    "        \n",
    "        pipe = make_pipeline(undersampler, model)\n",
    "        \n",
    "        # tune hyperparameters if required\n",
    "        if n_scenario in [5, 6, 7, 8, 9]:\n",
    "            # create and fit gridsearch\n",
    "            grid = GridSearchCV(\n",
    "                pipe,\n",
    "                param_grid = param_by_model[n_ML]\n",
    "            )\n",
    "            grid.fit(train_X, train_y)\n",
    "            y_pred_temp = grid.predict(test_X)\n",
    "        else:\n",
    "            pipe.fit(train_X, train_y)\n",
    "            y_pred_temp = pipe.predict(test_X)\n",
    "        \n",
    "        # append results\n",
    "        y_pred_temp = pd.concat([\n",
    "            pd.DataFrame(y_pred_temp),\n",
    "            pd.DataFrame(test_i, columns=[''])\n",
    "        ], axis=1).set_index('')\n",
    "        y_pred = pd.concat([y_pred, y_pred_temp], axis=0)\n",
    "        y_actual = pd.concat([y_actual, test_y], axis=0)  # for debugging\n",
    "\n",
    "    # return the full sorted results, appended into the input dataframe\n",
    "    dataframe[stats_scenarios[n_scenario]] = y_pred.sort_index()\n",
    "    dataframe['y_actual'] = y_actual.sort_index()  # for debugging, this should always be equal to in_B100 or folds are misaligned\n",
    "    \n",
    "    # DEBUGGING: should be zero\n",
    "    is_ERRORS = sum(dataframe['in_B100'] != dataframe['y_actual'])\n",
    "    if is_ERRORS != 0:\n",
    "        print('THERE WERE ERRORS!!!! (compare the in_B100 and y_actual columns)')\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "2aeef34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61.333333333333336, 66.66666666666667, 3780, 5580.0, 213.3)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_LogisticRegression = 160\n",
    "n_DecisionTreeClassifier = 160\n",
    "n_KNeighborsClassifier = 210\n",
    "n_RandomForestClassifier = 1800\n",
    "n_AdaBoostClassifier = 162\n",
    "\n",
    "# KNN and Random Forest Will Take Too Long, only try \n",
    "n_LogisticRegression * 23/60, n_DecisionTreeClassifier * 25/60, n_KNeighborsClassifier * 18, n_RandomForestClassifier  * 186/60, n_AdaBoostClassifier * 79/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "4c7f46df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 54min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_scenario = 5\n",
    "df_predictions = append_predictions(df_predictions, stratified_5fold, X_columns, y_column, n_scenario)\n",
    "\n",
    "# save dataframe\n",
    "df_predictions.to_pickle('df_predictions_TUNED.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "6f93bf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 56min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_scenario = 6\n",
    "df_predictions = append_predictions(df_predictions, stratified_5fold, X_columns, y_column, n_scenario)\n",
    "\n",
    "# save dataframe\n",
    "df_predictions.to_pickle('df_predictions_TUNED.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceef74f",
   "metadata": {},
   "source": [
    "### These are too time consuming to complete\n",
    "these were investigated using smaller fitting dataset in earlier notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0e5f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # calculated this from early afternoon until the next morning, and it didn't complete\n",
    "# # drop adaboost from partially tuned models\n",
    "# n_scenario = 9\n",
    "# df_predictions = append_predictions(df_predictions, stratified_5fold, X_columns, y_column, n_scenario)\n",
    "\n",
    "# save dataframe\n",
    "# df_predictions.to_pickle('df_predictions_FULLYTUNED.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108429a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # this should take too long\n",
    "# n_scenario = 7\n",
    "# df_predictions = append_predictions(df_predictions, stratified_5fold, X_columns, y_column, n_scenario)\n",
    "\n",
    "# save dataframe\n",
    "# df_predictions.to_pickle('df_predictions_FULLYTUNED.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca26551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # this should take too long\n",
    "# n_scenario = 8\n",
    "# df_predictions = append_predictions(df_predictions, stratified_5fold, X_columns, y_column, n_scenario)\n",
    "\n",
    "# save dataframe\n",
    "# df_predictions.to_pickle('df_predictions_FULLYTUNED.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce2af95",
   "metadata": {},
   "source": [
    "### Make predictions separating into clusters and genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "3027f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_predictions(dataframe, kfold, feature_columns, class_column, n_scenario):\n",
    "    \"\"\"\n",
    "    cluster could be 'genre', 'cluster1', 'cluster2', or False (default)\n",
    "    \"\"\"\n",
    "    # based on the scenario number, do we need to cluster?\n",
    "    if n_scenario == 10:\n",
    "        cluster = 'cluster1'\n",
    "    elif n_scenario == 11:\n",
    "        cluster = 'cluster2'\n",
    "    elif n_scenario == 12:\n",
    "        cluster = 'genre'\n",
    "    else:\n",
    "        cluster = False\n",
    "    \n",
    "    # entire dataset for predictions\n",
    "    X_, y_ = dataframe[feature_columns], dataframe[class_column]\n",
    "    \n",
    "    # initialise actual y and predicted y as blank dataframes\n",
    "    y_actual = pd.DataFrame()\n",
    "    y_pred = pd.DataFrame()\n",
    "\n",
    "    # loop through folds\n",
    "    for train_i, test_i in kfold.split(X_, y_):\n",
    "\n",
    "        # train test split for current fold\n",
    "        train_X, test_X = X_.iloc[train_i], X_.iloc[test_i]\n",
    "        train_y, test_y = y_.iloc[train_i], y_.iloc[test_i]\n",
    "        \n",
    "        # create pipeline\n",
    "        undersampler = RandomUnderSampler(sampling_strategy='majority', random_state=42)\n",
    "        \n",
    "        if n_scenario in [1, 6]:\n",
    "            n_ML = 1\n",
    "            model = DecisionTreeClassifier()\n",
    "        elif n_scenario in [2, 7]:\n",
    "            n_ML = 2\n",
    "            model = KNeighborsClassifier()\n",
    "        elif n_scenario in [3, 8]:\n",
    "            n_ML = 3\n",
    "            model = RandomForestClassifier()\n",
    "        elif n_scenario in [4, 9]:\n",
    "            n_ML = 4\n",
    "            model = AdaBoostClassifier()\n",
    "        else:\n",
    "            n_ML = 0\n",
    "            model = LogisticRegression()\n",
    "        \n",
    "        pipe = make_pipeline(undersampler, model)\n",
    "        \n",
    "        # THREE OPTIONS: tune hyperparameters, loop through clusters, just fit the pipe\n",
    "        \n",
    "        # OPTION 1: tune hyperparameters, tune/fit the grid\n",
    "        if n_scenario in [5, 6, 7, 8, 9]:\n",
    "            # create and fit gridsearch\n",
    "            grid = GridSearchCV(\n",
    "                pipe,\n",
    "                param_grid = param_by_model[n_ML]\n",
    "            )\n",
    "            grid.fit(train_X, train_y)\n",
    "            y_pred_temp = grid.predict(test_X)\n",
    "        \n",
    "        # OPTION 2: loop through clusters, individually fit the pipe\n",
    "        elif cluster:  \n",
    "            \n",
    "            print('IS CLUSTER')\n",
    "            \n",
    "            # initialise dataframe to append results\n",
    "            y_pred_temp = pd.DataFrame()\n",
    "            \n",
    "            # genre\n",
    "            if cluster == 'genre':\n",
    "                genre_columns = [\n",
    "                    'is_Adult_Standard', 'is_Rock', 'is_R&B', 'is_Country', 'is_Pop',\n",
    "                    'is_Rap', 'is_Alternative', 'is_EDM', 'is_Metal'\n",
    "                ]\n",
    "                for genre in genre_columns:\n",
    "                    pass\n",
    "            # cluster 1\n",
    "            elif cluster == 'cluster1':\n",
    "                for i in range(4):\n",
    "                    pass\n",
    "            # cluster 2\n",
    "            elif cluster == 'cluster2':\n",
    "                \n",
    "                print('IS CLUSTER2')\n",
    "                \n",
    "                for i in range(10):\n",
    "                    \n",
    "                    print(i)\n",
    "                    # SOOOOO SLOW 13s per loop (50 loops)\n",
    "                    \n",
    "                    i_train_cluster = dataframe.iloc[train_i][dataframe.iloc[train_i]['cluster2'] == 0].index\n",
    "                    i_test_cluster = dataframe.iloc[test_i][dataframe.iloc[test_i]['cluster2'] == 0].index\n",
    "                    \n",
    "                    print(len(i_train_cluster), len(i_test_cluster))\n",
    "                    \n",
    "                    train_X_c = train_X[train_X.index.isin(i_train_cluster)]\n",
    "                    test_X_c = test_X[test_X.index.isin(i_test_cluster)]\n",
    "                    train_y_c = train_y[train_y.index.isin(i_train_cluster)]\n",
    "                    test_y_c = test_y[test_y.index.isin(i_test_cluster)]\n",
    "                    \n",
    "                    print(train_X_c.shape)\n",
    "                    print(test_X_c.shape)\n",
    "                    print(train_y_c.shape)\n",
    "                    print(test_y_c.shape)                    \n",
    "                    \n",
    "                    if True:  # JUST FOR TESTING\n",
    "                        y_pred_cluster = np.array(test_y_c)\n",
    "                    else:\n",
    "                        pipe.fit(train_X_c, train_y_c)\n",
    "                        y_pred_cluster = pipe.predict(test_X_c)\n",
    "                        \n",
    "                    print(len(y_pred_cluster))\n",
    "                    \n",
    "                    y_pred_temp = pd.concat([\n",
    "                        y_pred_temp,\n",
    "                        pd.DataFrame(y_pred_cluster, index=i_test_cluster)\n",
    "                    ], axis=0)\n",
    "                    \n",
    "                    print(y_pred_temp.shape)\n",
    "                    \n",
    "            else:\n",
    "                print('NO SUCH CLUSTER')  # could raise an error instead\n",
    "                return dataframe  # do nothing, just return the input dataframe\n",
    "            \n",
    "            # sort y_pred_temp by index so it aligns properly\n",
    "            y_pred_temp = y_pred_temp.sort_index()\n",
    "                \n",
    "        # OPTION 3: just fit the pipe\n",
    "        else:  \n",
    "            pipe.fit(train_X, train_y)\n",
    "            y_pred_temp = pipe.predict(test_X)\n",
    "                \n",
    "        # fitting complete for fold\n",
    "        # append results\n",
    "        y_pred_temp = pd.concat([\n",
    "            pd.DataFrame(y_pred_temp),\n",
    "            pd.DataFrame(test_i, columns=[''])\n",
    "        ], axis=1).set_index('')\n",
    "        y_pred = pd.concat([y_pred, y_pred_temp], axis=0)\n",
    "        y_actual = pd.concat([y_actual, test_y], axis=0)  # for debugging\n",
    "\n",
    "    return dataframe\n",
    "    \n",
    "    # return the full sorted results, appended into the input dataframe\n",
    "    dataframe[stats_scenarios[n_scenario]] = y_pred.sort_index()\n",
    "    dataframe['y_actual'] = y_actual.sort_index()  # for debugging, this should always be equal to in_B100 or folds are misaligned\n",
    "    \n",
    "    # DEBUGGING: should be zero\n",
    "    is_ERRORS = sum(dataframe['in_B100'] != dataframe['y_actual'])\n",
    "    if is_ERRORS != 0:\n",
    "        print('THERE WERE ERRORS!!!! (compare the in_B100 and y_actual columns)')\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "fa408a09",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS CLUSTER\n",
      "IS CLUSTER2\n",
      "0\n",
      "796683 198878\n",
      "Wall time: 2.34 s\n",
      "Wall time: 551 ms\n",
      "Wall time: 2.29 s\n",
      "Wall time: 542 ms\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_X_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8208/516447294.py\u001b[0m in \u001b[0;36mappend_predictions\u001b[1;34m(dataframe, kfold, feature_columns, class_column, n_scenario)\u001b[0m\n\u001b[0;32m     99\u001b[0m                     \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test_y_c = test_y[test_y.index.isin(i_test_cluster)]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_X_c' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "append_predictions(df_predictions, stratified_5fold, X_columns, y_column, n_scenario=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfebb04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833358cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521e6c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "93faa094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through folds\n",
    "for train_i, test_i in kfold.split(X_, y_):\n",
    "\n",
    "    # train test split for current fold\n",
    "    train_X, test_X = X_.iloc[train_i], X_.iloc[test_i]\n",
    "    train_y, test_y = y_.iloc[train_i], y_.iloc[test_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "48b20889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      0,       1,       2, ..., 8827716, 8827717, 8827718])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "14a08d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_train_cluster = df_predictions.iloc[train_i][df_predictions.iloc[train_i]['cluster2'] == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "022c87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X[train_X.index == [0, 1, 8827718]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "768ea735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827678</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827679</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827680</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827681</th>\n",
       "      <td>0</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827703</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>796892 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mode  acousticness  danceability  duration_ms  energy  \\\n",
       "21          1         0.032         0.671        0.330   0.788   \n",
       "28          0         0.006         0.686        0.435   0.904   \n",
       "30          0         0.001         0.626        0.561   0.930   \n",
       "53          0         0.001         0.505        0.230   0.992   \n",
       "66          0         0.029         0.474        0.869   0.813   \n",
       "...       ...           ...           ...          ...     ...   \n",
       "8827678     1         0.002         0.423        0.348   0.844   \n",
       "8827679     0         0.007         0.497        0.364   0.678   \n",
       "8827680     0         0.000         0.461        0.373   0.818   \n",
       "8827681     0         0.114         0.474        0.380   0.734   \n",
       "8827703     0         0.006         0.437        0.303   0.911   \n",
       "\n",
       "         instrumentalness  liveness  loudness  speechiness  tempo  valence  \n",
       "21                  0.005     0.077     0.690        0.070  0.437    0.552  \n",
       "28                  0.008     0.093     0.658        0.046  0.405    0.571  \n",
       "30                  0.108     0.126     0.686        0.052  0.405    0.398  \n",
       "53                  0.054     0.077     0.703        0.092  0.420    0.609  \n",
       "66                  0.094     0.214     0.720        0.120  0.292    0.688  \n",
       "...                   ...       ...       ...          ...    ...      ...  \n",
       "8827678             0.000     0.130     0.734        0.032  0.309    0.202  \n",
       "8827679             0.000     0.265     0.733        0.028  0.346    0.200  \n",
       "8827680             0.000     0.175     0.753        0.028  0.281    0.211  \n",
       "8827681             0.000     0.319     0.725        0.037  0.609    0.560  \n",
       "8827703             0.000     0.364     0.756        0.038  0.591    0.240  \n",
       "\n",
       "[796892 rows x 11 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[train_X.index.isin(i_train_cluster)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "8dfc703d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([     21,      28,      30,      53,      66,      68,      73,      75,\n",
       "            83,      96,\n",
       "       ...\n",
       "       8827661, 8827674, 8827675, 8827676, 8827677, 8827678, 8827679, 8827680,\n",
       "       8827681, 8827703],\n",
       "      dtype='object', length=796892)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_train_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97681553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d94997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dee277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe\n",
    "df_predictions.to_pickle('df_predictions_CLUSTERS.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89fab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final predictions dataframe\n",
    "df_predictions.to_pickle('df_predictions.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3539be8e",
   "metadata": {},
   "source": [
    "# Explore Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab4a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Friedman Test (Wilcoxn if required)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c78743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms \n",
    "## NEED TO COMBINE WITH id to compare AF\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
