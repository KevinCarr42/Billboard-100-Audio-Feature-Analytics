{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f379970c",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a36765e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import spotipy\n",
    "\n",
    "# math and dataframes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "# Pipeline and Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "# Undersampling \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# jupyter notebook full-width display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cbcb793",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10M = pd.read_pickle('df_10M_clustered.pickle')\n",
    "df_B100_songs = pd.read_pickle('df_B100_songs.pickle')\n",
    "X_all = pd.read_pickle('X_clustered.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b8acb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>popularity</th>\n",
       "      <td>6.118</td>\n",
       "      <td>10.580</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean    std   min   25%   50%   75%     max\n",
       "popularity 6.118 10.580 0.000 0.000 1.000 8.000 100.000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# popularity from the sql database\n",
    "\"\"\"\n",
    "    SELECT id, popularity FROM tracks\n",
    "\"\"\"\n",
    "df_sql_popularity = pd.read_csv('popularity_by_track_sql.csv')\n",
    "\n",
    "df_sql_popularity.describe()['mean':'max'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "036c81b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise popularity dataframe for B100 songs\n",
    "df_B100_popularity = df_B100_songs.copy()\n",
    "df_B100_popularity['popularity'] = pd.NA\n",
    "df_B100_popularity = df_B100_popularity[['id', 'popularity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "620fee85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm no duplicates\n",
    "df_B100_popularity.id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb8a39",
   "metadata": {},
   "source": [
    "# Get Popularity for Missing Tracks\n",
    "##### get a temporary authorization token from: https://developer.spotify.com/console/get-search-item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b44459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input the temporary token\n",
    "TEMP_TOKEN = input('Enter token: ')\n",
    "\n",
    "# create a spotify object\n",
    "spotify = spotipy.Spotify(auth=TEMP_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5082c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_popularity(track_id):\n",
    "    track_info = spotify.track(track_id)\n",
    "    popularity = track_info['popularity']\n",
    "    \n",
    "    return popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234db780",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# loop to GET popularity\n",
    "\n",
    "counter = 0\n",
    "start_over_at = 0\n",
    "if start_over_at == 0:\n",
    "    id_errors = set()\n",
    "\n",
    "for i, row in df_B100_popularity.iterrows():\n",
    "        \n",
    "    if counter % 100 == 0:\n",
    "        print(counter, end=' ')\n",
    "    if counter % 1000 == 0:\n",
    "        print()\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    if i < start_over_at:  # where we timed out last time\n",
    "        continue\n",
    "    \n",
    "    # save temp file\n",
    "    if counter % 1000 == 0:\n",
    "        df_B100_popularity.to_pickle('df_B100_popularity_TEMP.pickle')\n",
    "    \n",
    "    # does this track have a null popularity value? if not, next row\n",
    "    if not df_B100_popularity.iloc[[i]].isnull()['popularity'].values[0]:\n",
    "        continue    \n",
    "    \n",
    "    # current id for lookup in API\n",
    "    track_id = row.id\n",
    "    \n",
    "    # lookup song info from API and set the popularity value for that track\n",
    "    try:\n",
    "        df_B100_popularity.loc[i, 'popularity'] = get_popularity(track_id)\n",
    "    except:  # any error should \n",
    "        print(' -- get_popularity() didnt work -- ', track_id)\n",
    "        id_errors.add(track_id)\n",
    "        df_B100_popularity.loc[i, 'popularity'] = 0  # set it to zero anyway\n",
    "\n",
    "\n",
    "# save the dataframe\n",
    "df_B100_popularity.to_pickle('df_B100_popularity_COMPLETE.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many missing values\n",
    "len(id_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a7394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many null\n",
    "df_B100_popularity.popularity.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2a6e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b29a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10191f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine df_sql_popularity and df_B100_popularity into df_popularity\n",
    "df_popularity = pd.concat([df_B100_popularity, df_sql_popularity]).reset_index(drop=True)\n",
    "df_popularity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350bfef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm no duplicates\n",
    "df_popularity.duplicated(subset='id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3112cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe\n",
    "df_popularity.to_pickle('df_popularity.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7ef2bd",
   "metadata": {},
   "source": [
    "# Combine Spotify Popularity with X_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd042261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed8f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf4c411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25e7d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ed65dd3",
   "metadata": {},
   "source": [
    "# Create Datasets for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065df1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = 'is_Popular'\n",
    "X_columns = [\n",
    "    'mode', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
    "    'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence'\n",
    "]\n",
    "genre_columns = [\n",
    "    'is_Adult_Standard', 'is_Rock', 'is_R&B', 'is_Country', 'is_Pop',\n",
    "    'is_Rap', 'is_Alternative', 'is_EDM', 'is_Metal'\n",
    "]\n",
    "cluster_columns = ['cluster', 'cluster2']\n",
    "other_columns = ['key', 'time_signature', 'genre', 'release_date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64aee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict with all 'name': (X, y) key match pairs\n",
    "clusters = {}\n",
    "\n",
    "# entire predictive dataset\n",
    "clusters['All'] = (X_all[X_columns+genre_columns], X_all[y_column])\n",
    "# clusters['All'] = (X_all[X_columns], X_all[y_column])\n",
    "\n",
    "# add genres\n",
    "for genre in genre_columns:\n",
    "    title = genre[3:]\n",
    "    clusters[title] = (X_all[X_all[genre]][X_columns], X_all[X_all[genre]][y_column])\n",
    "    \n",
    "# add clusters\n",
    "for n in sorted(X_all['cluster'].unique()):\n",
    "    title = genre[3:]\n",
    "    clusters['cluster1_' + str(n)] = (X_all[X_all['cluster'] == n][X_columns], X_all[X_all['cluster'] == n][y_column])\n",
    "    \n",
    "for n in sorted(X_all['cluster2'].unique()):\n",
    "    title = genre[3:]\n",
    "    clusters['cluster2_' + str(n)] = (X_all[X_all['cluster2'] == n][X_columns], X_all[X_all['cluster2'] == n][y_column])\n",
    "    \n",
    "# setup tuning algorithm with a small dataset\n",
    "small = X_all.sample(10_000, random_state=42)\n",
    "X_small = small[X_columns]\n",
    "y_small = small[y_column]\n",
    "clusters['small'] = (X_small, y_small)\n",
    "    \n",
    "# OPTIONAL IF TIME PERMITS: consider adding decades or eras of music"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a98d9ab",
   "metadata": {},
   "source": [
    "# Tune Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_keys = [\n",
    "    'All', \n",
    "    'Adult_Standard', 'Rock', 'R&B', 'Country', 'Pop', 'Rap', 'Alternative', 'EDM', 'Metal', \n",
    "    'cluster1_0', 'cluster1_1', 'cluster1_2', 'cluster1_3', \n",
    "    'cluster2_0', 'cluster2_1', 'cluster2_2', 'cluster2_3', 'cluster2_4', \n",
    "    'cluster2_5', 'cluster2_6', 'cluster2_7', 'cluster2_8', 'cluster2_9',\n",
    "    'small'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2b45a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model parameters for grid search\n",
    "\n",
    "ML_algorithms = [\n",
    "    LogisticRegression,\n",
    "    DecisionTreeClassifier,\n",
    "    KNeighborsClassifier,\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier\n",
    "]\n",
    "\n",
    "param_by_model = {}\n",
    "\n",
    "params_lr = {}\n",
    "orders_of_magnitude = []\n",
    "for lst in [[int(x)/10000 for x in range(1, 11)],\n",
    "            [int(x)/1000 for x in range(1, 11)],\n",
    "            [int(x)/100 for x in range(1, 11)],\n",
    "            [int(x)/10 for x in range(1, 11)],\n",
    "            [1 * x for x in range(1, 11)],\n",
    "            [10 * x for x in range(1, 11)],\n",
    "            [100 * x for x in range(1, 11)],\n",
    "            [1000 * x for x in range(1, 11)]]:\n",
    "    orders_of_magnitude += lst\n",
    "params_lr['logisticregression__penalty'] = ['l1', 'l2']\n",
    "params_lr['logisticregression__C'] = orders_of_magnitude\n",
    "params_lr['logisticregression__solver'] = ['liblinear']\n",
    "param_by_model[0] = params_lr\n",
    "\n",
    "params_dt = {}\n",
    "params_dt['decisiontreeclassifier__max_depth'] = [3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 40, 50, 100, None]\n",
    "params_dt['decisiontreeclassifier__min_samples_leaf'] = [5, 10, 50, 100, 1000]\n",
    "params_dt['decisiontreeclassifier__criterion'] = ['gini', 'entropy']\n",
    "param_by_model[1] = params_dt\n",
    "\n",
    "params_knn = {}\n",
    "params_knn['kneighborsclassifier__n_neighbors'] = [x for x in range(2,20)]+[x for x in range(20,101,5)]\n",
    "params_knn['kneighborsclassifier__weights'] = ['uniform', 'distance']\n",
    "params_knn['kneighborsclassifier__metric'] = ['minkowski', 'euclidean', 'manhattan']\n",
    "param_by_model[2] = params_knn\n",
    "\n",
    "params_rf = {}\n",
    "params_rf['randomforestclassifier__n_estimators'] = [5, 10, 20, 50, 100, 200, 500, 1000, 2000]\n",
    "params_rf['randomforestclassifier__max_features'] = ['sqrt', 'log2']\n",
    "params_rf['randomforestclassifier__max_depth'] = [3, 5, 7, 10, 15, 20, 30, 50, 100, None]\n",
    "params_rf['randomforestclassifier__min_samples_leaf'] = [5, 10, 50, 100, 1000]\n",
    "params_rf['randomforestclassifier__bootstrap'] = [True, False]\n",
    "param_by_model[3] = params_rf\n",
    "\n",
    "params_ab = {}\n",
    "params_ab['adaboostclassifier__n_estimators'] = [10, 50, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "params_ab['adaboostclassifier__learning_rate'] = [0.0001, 0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 1.5, 2.0]\n",
    "params_ab['adaboostclassifier__algorithm'] = ['SAMME', 'SAMME.R']\n",
    "param_by_model[4] = params_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e64ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many scenarios in the grid search\n",
    "\n",
    "def how_many_scenarios(n_ML):\n",
    "    n_scenarios = 1\n",
    "    for key in param_by_model[n_ML].keys():\n",
    "        n_scenarios *=  len(param_by_model[n_ML][key])\n",
    "    return n_scenarios\n",
    "\n",
    "for i in range(5):\n",
    "    print(str(ML_algorithms[i]())[:-2], how_many_scenarios(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5b488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_metric_model(n_ML, dataset='small', n_cv=5, scoring='roc_auc', undersample=True, cv_res_print=False, heatmap=False):\n",
    "    \n",
    "    # split the dataset into train test\n",
    "    X_, y_ = clusters[dataset]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=42, stratify=y_)\n",
    "        \n",
    "    # params\n",
    "    param_grid = param_by_model[n_ML]\n",
    "\n",
    "    # pipeline\n",
    "    if undersample:\n",
    "        pipe = make_pipeline(\n",
    "            RandomUnderSampler(sampling_strategy='majority', random_state=42), \n",
    "            ML_algorithms[n_ML]()\n",
    "        )\n",
    "    else:\n",
    "        if n_ML in [0, 1, 3]:\n",
    "            pipe = make_pipeline(ML_algorithms[n_ML](class_weight='balanced'))\n",
    "        else:\n",
    "            pipe = make_pipeline(ML_algorithms[n_ML]())\n",
    "\n",
    "    # gridsearch\n",
    "    cv = StratifiedKFold(n_splits=n_cv, shuffle=True)\n",
    "    grid = GridSearchCV(\n",
    "        estimator = pipe,\n",
    "        param_grid = param_grid,\n",
    "        cv = cv,\n",
    "        scoring = scoring, \n",
    "        n_jobs = -1\n",
    "    )\n",
    "\n",
    "    # calculate best parameters\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # results\n",
    "    cv_results = (\n",
    "        grid.best_params_,\n",
    "        grid.cv_results_['mean_test_score'].mean(), \n",
    "        grid.cv_results_['mean_test_score'].min(), \n",
    "        grid.cv_results_['mean_test_score'].max()\n",
    "    )\n",
    "    \n",
    "    # print header\n",
    "    if undersample:\n",
    "        undersample_description = 'Undersampled'\n",
    "    else:\n",
    "        undersample_description = 'Full Dataset'\n",
    "    print(\n",
    "        '\\nScenario\\n------------------------------\\n', str(ML_algorithms[0]())[:-2], \n",
    "        dataset.title(), \n",
    "        scoring, \n",
    "        undersample_description\n",
    "    )\n",
    "    \n",
    "    if cv_res_print:\n",
    "        # print cv results\n",
    "        print('\\nCrossvalidation Results\\n------------------------------')\n",
    "        for i in cv_results:\n",
    "            print(i)\n",
    "\n",
    "    # print predictions\n",
    "    y_pred = grid.predict(X_test)\n",
    "    print('\\nClassification Report\\n------------------------------\\n', classification_report(y_test, y_pred))\n",
    "    \n",
    "    if heatmap:\n",
    "        print('\\nConfusion Matrix\\n------------------------------')\n",
    "        plt.subplots(figsize=(6, 6))\n",
    "        sns.heatmap(confusion_matrix(y_test, y_pred), vmin=0, cmap='Blues', annot=True, fmt='.0f', cbar=False,\n",
    "                   xticklabels=['Not Popular', 'Billboard Hit'], yticklabels=['Not Popular', 'Billboard Hit'])\n",
    "        plt.ylabel('Predicted')\n",
    "        plt.xlabel('Actual')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7164962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenarios to check\n",
    "\n",
    "metrics = [\n",
    "    'balanced_accuracy', 'average_precision', 'neg_brier_score', 'f1', 'f1_micro', \n",
    "    'f1_macro', 'f1_weighted', 'neg_log_loss', 'precision', 'recall', 'roc_auc', 'jaccard'\n",
    "]\n",
    "\n",
    "cluster1_keys = [\n",
    "    'cluster1_0', 'cluster1_1', 'cluster1_2', 'cluster1_3'\n",
    "]\n",
    "\n",
    "cluster2_keys = [\n",
    "    'cluster2_0', 'cluster2_1', 'cluster2_2', 'cluster2_3', 'cluster2_4', \n",
    "    'cluster2_5', 'cluster2_6', 'cluster2_7', 'cluster2_8', 'cluster2_9',\n",
    "]\n",
    "\n",
    "genre_keys = [\n",
    "    'Adult_Standard', 'Rock', 'R&B', 'Country', 'Pop', 'Rap', 'Alternative', 'EDM', 'Metal'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b33e14d",
   "metadata": {},
   "source": [
    "# LAST TRY: narrow results by year\n",
    "## still no.  this looks untrainable.\n",
    "maybe a neural network will have better luck..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c46a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X_all[(X_all['is_Rock']) & (X_all.release_date.dt.year.isin(list(range(2010, 2022))))][X_columns]\n",
    "y_ = X_all[(X_all['is_Rock']) & (X_all.release_date.dt.year.isin(list(range(2010, 2022))))][y_column]\n",
    "\n",
    "clusters['modern_rock'] = X_, y_\n",
    "clusters['modern_rock'][1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262ea0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit_predict_metric_model(0, dataset='modern_rock', n_cv=3, scoring='roc_auc', cv_res_print=False, undersample=True, heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85114ea3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# check metrics\n",
    "undersample = True\n",
    "\n",
    "for metric in metrics:\n",
    "    fit_predict_metric_model(0, dataset='modern_rock', n_cv=5, scoring=metric, \n",
    "                             cv_res_print=False, undersample=undersample, heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9147fb",
   "metadata": {},
   "source": [
    "# OLD CODE: no meaningful results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfe8f12",
   "metadata": {},
   "source": [
    "##### Logistic Regression - try a bunch of metrics fully sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc4b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit_predict_metric_model(0, dataset='small', n_cv=5, scoring=metric, cv_res_print=False, undersample=True, heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b90263",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit_predict_metric_model(0, dataset='small', n_cv=5, scoring=metric, cv_res_print=False, undersample=False, heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1734c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# check metrics\n",
    "undersample = True\n",
    "\n",
    "for metric in metrics:\n",
    "    fit_predict_metric_model(0, dataset='small', n_cv=5, scoring=metric, cv_res_print=False, undersample=undersample, heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfebebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# check clusters\n",
    "undersample = True\n",
    "\n",
    "for key in cluster1_keys:\n",
    "    fit_predict_metric_model(0, dataset=key, n_cv=5, scoring='roc_auc', cv_res_print=False, undersample=undersample, heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798723c3",
   "metadata": {},
   "source": [
    "# OLDER CODE: no meaningful results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c29c2e",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3793ae9b",
   "metadata": {},
   "source": [
    "#### huge loop (all night not nearly enough, better now anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e5024d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for key in cluster_keys:\n",
    "    fit_predict_metric_model(0, dataset=key, n_cv=5, scoring='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c4176",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for key in cluster_keys:\n",
    "    fit_predict_metric_model(0, dataset=key, n_cv=5, scoring='average_precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d5ed7",
   "metadata": {},
   "source": [
    "#### tons of scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1025a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit_predict_metric_model(0, dataset='Adult_Standard', n_cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471c95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit_predict_metric_model(0, dataset='Adult_Standard', n_cv=5, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9787ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit_predict_metric_model(0, dataset='Adult_Standard', n_cv=5, scoring='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db1f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit_predict_metric_model(0, dataset='Adult_Standard', n_cv=5, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce13a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit_predict_metric_model(0, dataset='cluster1_0', n_cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6084caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit_predict_metric_model(0, dataset='cluster1_1', n_cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621076b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit_predict_metric_model(0, dataset='cluster1_2', n_cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30755135",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit_predict_metric_model(0, dataset='cluster1_3', n_cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5795b5c1",
   "metadata": {},
   "source": [
    "##### Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a3972",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit_predict_metric_model(1, dataset='Adult_Standard', n_cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a8e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit_predict_metric_model(2, dataset='Adult_Standard', n_cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6115637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit_predict_metric_model(3, dataset='Adult_Standard', n_cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e24fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit_predict_metric_model(4, dataset='Adult_Standard', n_cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a3fe64",
   "metadata": {},
   "source": [
    "# EVEN OLDER CODE: no meaningful results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a602d0f",
   "metadata": {},
   "source": [
    "### Which ML models did well with default settings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd92ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('default_results.pickle', 'rb') as f:\n",
    "    default_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de167432",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_algorithms = [\n",
    "    LogisticRegression,\n",
    "    DecisionTreeClassifier,\n",
    "    KNeighborsClassifier,\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier\n",
    "]\n",
    "\n",
    "def default_results_by_metric(class_type='True', metric='f1-score'):\n",
    "    \"\"\"convert default results into readable form\"\"\"\n",
    "    output_ = []\n",
    "\n",
    "    for algo in ML_algorithms:\n",
    "        algo_ = str(algo())[:-2]\n",
    "        temp_ = [algo_]\n",
    "        for cluster in cluster_keys:\n",
    "            if class_type == 'accuracy':\n",
    "                metric_ = default_results[algo_][cluster][1][class_type]\n",
    "            else:\n",
    "                metric_ = default_results[algo_][cluster][1][class_type][metric]\n",
    "            temp_.append(metric_)\n",
    "        output_.append(temp_)\n",
    "\n",
    "    df_default_results = pd.DataFrame(output_, columns=['Model']+list(default_results['LogisticRegression'].keys()))\n",
    "    df_default_results['min'] = df_default_results.iloc[:, 1:].min(axis=1)\n",
    "    df_default_results['max'] = df_default_results.iloc[:, 1:].max(axis=1)\n",
    "    df_default_results['mean'] = df_default_results.iloc[:, 1:].mean(axis=1)\n",
    "\n",
    "    return df_default_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bdc6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best performing classification by cluster = Adult_Standard (1st or 2nd for all ML models)\n",
    "sortbyfeature = 'LogisticRegression'\n",
    "pd.DataFrame(default_results_by_metric().iloc[:, :-3].set_index('Model').T).sort_values(sortbyfeature, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037c6a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adult standard is just better because of randomness... there are more to start with ...\n",
    "for cluster in clusters:\n",
    "    print(cluster, clusters[cluster][1].sum(), clusters[cluster][1].count(), clusters[cluster][1].sum() / clusters[cluster][1].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da576a88",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f612e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huge list of orders of magnitude for gridsearch\n",
    "# formatted a bit funny to avoid rounding errors\n",
    "orders_of_magnitude = []\n",
    "for lst in [[int(x)/10000 for x in range(1, 11)],\n",
    "            [int(x)/1000 for x in range(1, 11)],\n",
    "            [int(x)/100 for x in range(1, 11)],\n",
    "            [int(x)/10 for x in range(1, 11)],\n",
    "            [1 * x for x in range(1, 11)],\n",
    "            [10 * x for x in range(1, 11)],\n",
    "            [100 * x for x in range(1, 11)],\n",
    "            [1000 * x for x in range(1, 11)]]:\n",
    "    orders_of_magnitude += lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2122121",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# LOGISTIC REGRESSION\n",
    "\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning setup with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'f1'\n",
    "param_grid = {}\n",
    "param_grid['logisticregression__penalty'] = ['l1', 'l2']\n",
    "param_grid['logisticregression__C'] = orders_of_magnitude\n",
    "\n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    LogisticRegression(solver='liblinear')\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "lr_grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "lr_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "lr_grid.best_params_, lr_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8ebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't seem like tuning is doing anything\n",
    "(\n",
    "    lr_grid.cv_results_['mean_test_score'].mean(), \n",
    "    lr_grid.cv_results_['mean_test_score'].min(), \n",
    "    lr_grid.cv_results_['mean_test_score'].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65432a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# DECISION TREE\n",
    "\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning setup with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'f1'\n",
    "param_grid = {}\n",
    "param_grid['decisiontreeclassifier__max_depth'] = [3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 40, 50, 100, None]\n",
    "param_grid['decisiontreeclassifier__min_samples_leaf'] = [5, 10, 50, 100, 1000]\n",
    "param_grid['decisiontreeclassifier__criterion'] = ['gini', 'entropy']\n",
    "\n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    DecisionTreeClassifier()\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "dt_grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "dt_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "dt_grid.best_params_, dt_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44700709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning isn't useful here either...\n",
    "(\n",
    "    dt_grid.cv_results_['mean_test_score'].mean(), \n",
    "    dt_grid.cv_results_['mean_test_score'].min(), \n",
    "    dt_grid.cv_results_['mean_test_score'].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a4489",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# KNN\n",
    "\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning setup with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'f1'\n",
    "param_grid = {}\n",
    "param_grid['kneighborsclassifier__n_neighbors'] = [x for x in range(2,20)]+[x for x in range(20,101,5)]\n",
    "param_grid['kneighborsclassifier__weights'] = ['uniform', 'distance']\n",
    "param_grid['kneighborsclassifier__metric'] = ['minkowski', 'euclidean', 'manhattan']\n",
    "\n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    KNeighborsClassifier()\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "knn_grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "knn_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "knn_grid.best_params_, knn_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89a1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check min mean and max\n",
    "(\n",
    "    knn_grid.cv_results_['mean_test_score'].mean(), \n",
    "    knn_grid.cv_results_['mean_test_score'].min(), \n",
    "    knn_grid.cv_results_['mean_test_score'].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd6dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# random forest\n",
    "\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning setup with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'f1'\n",
    "param_grid = {}\n",
    "param_grid['randomforestclassifier__n_estimators'] = [5, 10, 20, 50, 100, 200, 500, 1000, 2000]\n",
    "param_grid['randomforestclassifier__max_features'] = ['sqrt', 'log2']\n",
    "param_grid['randomforestclassifier__max_depth'] = [3, 5, 7, 10, 15, 20, 30, 50, 100, None]\n",
    "param_grid['randomforestclassifier__min_samples_leaf'] = [5, 10, 50, 100, 1000]\n",
    "param_grid['randomforestclassifier__bootstrap'] = [True, False]\n",
    "\n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    RandomForestClassifier()\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "rf_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "rf_grid.best_params_, rf_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b30af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also didn't do great...\n",
    "(\n",
    "    rf_grid.cv_results_['mean_test_score'].mean(), \n",
    "    rf_grid.cv_results_['mean_test_score'].min(), \n",
    "    rf_grid.cv_results_['mean_test_score'].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca9c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# adaboost\n",
    "\n",
    "# choose dataset\n",
    "am_testing = False  # test tuning setup with small dataset\n",
    "if am_testing:\n",
    "    X_, y_ = X_small, y_small\n",
    "else:\n",
    "    X_, y_ = clusters['Adult_Standard']  # has the best classification results from STEP 5\n",
    "\n",
    "# params\n",
    "scoring = 'f1'\n",
    "param_grid = {}\n",
    "param_grid['adaboostclassifier__n_estimators'] = [10, 50, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "param_grid['adaboostclassifier__n_learning_rate'] = [0.0001, 0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 1.5, 2.0]\n",
    "param_grid['adaboostclassifier__n_algorithm'] = ['SAMME', 'SAMME.R']\n",
    "        \n",
    "# pipeline\n",
    "pipe = make_pipeline(\n",
    "    RandomUnderSampler(sampling_strategy='majority'), \n",
    "    AdaBoostClassifier()\n",
    ")\n",
    "\n",
    "# gridsearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "ab_grid = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid = param_grid,\n",
    "    cv = cv,\n",
    "    scoring = scoring, \n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "# calculate best parameters\n",
    "ab_grid.fit(X_, y_)\n",
    "\n",
    "# results\n",
    "ab_grid.best_params_, ab_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b255a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check min mean and max\n",
    "(\n",
    "    ab_grid.cv_results_['mean_test_score'].mean(), \n",
    "    ab_grid.cv_results_['mean_test_score'].min(), \n",
    "    ab_grid.cv_results_['mean_test_score'].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893ad126",
   "metadata": {},
   "source": [
    "### Test Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059b7339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a65e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12613bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7548d980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8bdf80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
